---
title: "mentése a Windows RDMA fürt toorun MPI alkalmazások aaaSet |} Microsoft Docs"
description: "Ismerje meg, hogyan toocreate mérete H16r, H16mr, A8 és A9 virtuális gépek toouse Windows HPC Pack fürt hello Azure RDMA hálózati toorun MPI alkalmazásokat."
services: virtual-machines-windows
documentationcenter: 
author: dlepow
manager: timlt
editor: 
tags: azure-service-management,hpc-pack
ms.assetid: 7d9f5bc8-012f-48dd-b290-db81c7592215
ms.service: virtual-machines-windows
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: big-compute
ms.date: 06/01/2017
ms.author: danlep
ms.openlocfilehash: 23bc8740dbd05a7c7ab3f998489a41d0df4520a2
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 10/06/2017
---
# <a name="set-up-a-windows-rdma-cluster-with-hpc-pack-toorun-mpi-applications"></a><span data-ttu-id="39f5d-103">HPC Pack toorun MPI alkalmazásokkal Windows RDMA fürt beállítása</span><span class="sxs-lookup"><span data-stu-id="39f5d-103">Set up a Windows RDMA cluster with HPC Pack toorun MPI applications</span></span>
<span data-ttu-id="39f5d-104">Az Azure-ban Windows RDMA fürt beállítása [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) és [nagy teljesítményű számítási Virtuálisgép-méretek](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) toorun párhuzamos Message Passing Interface (MPI) alkalmazások.</span><span class="sxs-lookup"><span data-stu-id="39f5d-104">Set up a Windows RDMA cluster in Azure with [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) and [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) toorun parallel Message Passing Interface (MPI) applications.</span></span> <span data-ttu-id="39f5d-105">Az RDMA-kompatibilis, a Windows Server-alapú HPC Pack-fürtben lévő csomópontok beállításakor MPI alkalmazások hatékonyan kis késéssel, a távoli közvetlen memória-hozzáférés (RDMA) technológia alapuló Azure magas teljesítmény hálózati protokollt használó kommunikációra.</span><span class="sxs-lookup"><span data-stu-id="39f5d-105">When you set up RDMA-capable, Windows Server-based nodes in an HPC Pack cluster, MPI applications communicate efficiently over a low latency, high throughput network in Azure that is based on remote direct memory access (RDMA) technology.</span></span>

<span data-ttu-id="39f5d-106">Ha azt szeretné, hogy hozzáférési hello Azure RDMA hálózati Linux virtuális gépeken toorun MPI terhelések, lásd: [állítson be egy Linux RDMA fürt toorun MPI alkalmazások](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="39f5d-106">If you want toorun MPI workloads on Linux VMs that access hello Azure RDMA network, see [Set up a Linux RDMA cluster toorun MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

## <a name="hpc-pack-cluster-deployment-options"></a><span data-ttu-id="39f5d-107">HPC Pack fürt üzembe helyezési lehetőségei</span><span class="sxs-lookup"><span data-stu-id="39f5d-107">HPC Pack cluster deployment options</span></span>
<span data-ttu-id="39f5d-108">A Microsoft HPC Pack egy olyan eszköz, feltéve, nem jelent többletköltséget toocreate HPC-fürtök a helyszíni vagy Azure toorun Windows vagy Linux HPC-alkalmazásokhoz.</span><span class="sxs-lookup"><span data-stu-id="39f5d-108">Microsoft HPC Pack is a tool provided at no additional cost toocreate HPC clusters on-premises or in Azure toorun Windows or Linux HPC applications.</span></span> <span data-ttu-id="39f5d-109">HPC Pack hello Microsoft általi implementációja hello üzenet átadásakor felület for Windows (MS-MPI) futtatókörnyezetének tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="39f5d-109">HPC Pack includes a runtime environment for hello Microsoft implementation of hello Message Passing Interface for Windows (MS-MPI).</span></span> <span data-ttu-id="39f5d-110">Ha használja az RDMA-kompatibilis osztályt egy támogatott Windows Server operációs rendszert futtató, HPC Pack lehetővé teszi egy hatékony beállítás toorun Windows MPI, hogy hozzáférési hello Azure RDMA hálózati.</span><span class="sxs-lookup"><span data-stu-id="39f5d-110">When used with RDMA-capable instances running a supported Windows Server operating system, HPC Pack provides an efficient option toorun Windows MPI applications that access hello Azure RDMA network.</span></span> 

<span data-ttu-id="39f5d-111">Ez a cikk két forgatókönyv bemutatja, és hivatkozásokat tartalmaz a Microsoft HPC Pack Windows RDMA fürt toodetailed útmutatást tooset.</span><span class="sxs-lookup"><span data-stu-id="39f5d-111">This article introduces two scenarios and links toodetailed guidance tooset up a Windows RDMA cluster with Microsoft HPC Pack.</span></span> 

* <span data-ttu-id="39f5d-112">1. forgatókönyv.</span><span class="sxs-lookup"><span data-stu-id="39f5d-112">Scenario 1.</span></span> <span data-ttu-id="39f5d-113">Számítási igényű feldolgozói szerepkör-példányok (PaaS) telepítése</span><span class="sxs-lookup"><span data-stu-id="39f5d-113">Deploy compute-intensive worker role instances (PaaS)</span></span>
* <span data-ttu-id="39f5d-114">2. forgatókönyv.</span><span class="sxs-lookup"><span data-stu-id="39f5d-114">Scenario 2.</span></span> <span data-ttu-id="39f5d-115">Telepítse a számítási igényű VMs (IaaS) számítási csomópontokat</span><span class="sxs-lookup"><span data-stu-id="39f5d-115">Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>

<span data-ttu-id="39f5d-116">Általános Előfeltételek toouse számítási igényű példányok Windows, lásd: [nagy teljesítményű számítási Virtuálisgép-méretek](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="39f5d-116">For general prerequisites toouse compute-intensive instances with Windows, see [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>

## <a name="scenario-1-deploy-compute-intensive-worker-role-instances-paas"></a><span data-ttu-id="39f5d-117">1. forgatókönyv: Központi telepítése a számítási igényű munkavégző szerepkörpéldányokat (PaaS)</span><span class="sxs-lookup"><span data-stu-id="39f5d-117">Scenario 1: Deploy compute-intensive worker role instances (PaaS)</span></span>
<span data-ttu-id="39f5d-118">HPC Pack meglévő fürtök adjon hozzá további számítási erőforrásokat Azure feldolgozói szerepkör példányát (Azure-csomópontok) (PaaS) felhőszolgáltatásban fut.</span><span class="sxs-lookup"><span data-stu-id="39f5d-118">From an existing HPC Pack cluster, add extra compute resources in Azure worker role instances (Azure nodes) running in a cloud service (PaaS).</span></span> <span data-ttu-id="39f5d-119">Ez a szolgáltatás, más néven "kapacitásnövelés tooAzure" HPC Pack számos különböző méretű hello szerepkör feldolgozópéldányok támogatja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-119">This feature, also called “burst tooAzure” from HPC Pack, supports a range of sizes for hello worker role instances.</span></span> <span data-ttu-id="39f5d-120">Ha Azure-csomópontok hozzáadása hello, adjon meg egy RDMA-kompatibilis hello méretű.</span><span class="sxs-lookup"><span data-stu-id="39f5d-120">When adding hello Azure nodes, specify one of hello RDMA-capable sizes.</span></span>

<span data-ttu-id="39f5d-121">Az alábbiakban szempontjait és lépéseit tooburst tooRDMA-kompatibilis Azure-példányokon a meglévő (jellemzően helyszíni) fürthöz.</span><span class="sxs-lookup"><span data-stu-id="39f5d-121">Following are considerations and steps tooburst tooRDMA-capable Azure instances from an existing (typically on-premises) cluster.</span></span> <span data-ttu-id="39f5d-122">Hasonló eljárások tooadd feldolgozói szerepkör példányok tooan HPC Pack átjárócsomópont, amely telepítve van egy Azure virtuális gép használja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-122">Use similar procedures tooadd worker role instances tooan HPC Pack head node that is deployed in an Azure VM.</span></span>

> [!NOTE]
> <span data-ttu-id="39f5d-123">A HPC Pack oktatóanyag tooburst tooAzure, lásd: [HPC Pack hibrid fürt beállítása](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="39f5d-123">For a tutorial tooburst tooAzure with HPC Pack, see [Set up a hybrid cluster with HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span></span> <span data-ttu-id="39f5d-124">A lépéseket, amelyek érvényesek a kifejezetten tooRDMA-kompatibilis Azure-csomópontok hello hello-érdemes figyelembe venni.</span><span class="sxs-lookup"><span data-stu-id="39f5d-124">Note hello considerations in hello following steps that apply specifically tooRDMA-capable Azure nodes.</span></span>
> 
> 

![Kapacitásnövelés tooAzure][burst]

### <a name="steps"></a><span data-ttu-id="39f5d-126">Lépések</span><span class="sxs-lookup"><span data-stu-id="39f5d-126">Steps</span></span>
1. <span data-ttu-id="39f5d-127">**Telepíthet és konfigurálhat egy átjáró HPC Pack 2012 R2-csomóponti**</span><span class="sxs-lookup"><span data-stu-id="39f5d-127">**Deploy and configure an HPC Pack 2012 R2 head node**</span></span>
   
    <span data-ttu-id="39f5d-128">Hello legújabb HPC Pack telepítési csomag letöltését hello [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="39f5d-128">Download hello latest HPC Pack installation package from hello [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span> <span data-ttu-id="39f5d-129">Követelmények és utasításokat tooprepare egy Azure-kapacitásnövelés a telepítést, lásd: [tooAzure Worker-példány és a Microsoft HPC Pack kapacitásnövelés](https://technet.microsoft.com/library/gg481749.aspx).</span><span class="sxs-lookup"><span data-stu-id="39f5d-129">For requirements and instructions tooprepare for an Azure burst deployment, see [Burst tooAzure Worker Instances with Microsoft HPC Pack](https://technet.microsoft.com/library/gg481749.aspx).</span></span>
2. <span data-ttu-id="39f5d-130">**Felügyeleti tanúsítvány konfigurálása az Azure-előfizetés hello**</span><span class="sxs-lookup"><span data-stu-id="39f5d-130">**Configure a management certificate in hello Azure subscription**</span></span>
   
    <span data-ttu-id="39f5d-131">Egy tanúsítvány-toosecure hello hello átjárócsomópont és az Azure közötti kapcsolat konfigurálása.</span><span class="sxs-lookup"><span data-stu-id="39f5d-131">Configure a certificate toosecure hello connection between hello head node and Azure.</span></span> <span data-ttu-id="39f5d-132">Beállítások és eljárások: [forgatókönyvek tooConfigure hello Azure felügyeleti tanúsítvány a HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span><span class="sxs-lookup"><span data-stu-id="39f5d-132">For options and procedures, see [Scenarios tooConfigure hello Azure Management Certificate for HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span></span> <span data-ttu-id="39f5d-133">Tesztelési célú telepítések esetén a HPC Pack alapértelmezett Microsoft HPC Azure felügyeleti tanúsítvánnyal gyorsan feltöltheti az Azure-előfizetés tooyour telepíti.</span><span class="sxs-lookup"><span data-stu-id="39f5d-133">For test deployments, HPC Pack installs a Default Microsoft HPC Azure Management Certificate you can quickly upload tooyour Azure subscription.</span></span>
3. <span data-ttu-id="39f5d-134">**Új felhőalapú szolgáltatás és a storage-fiók létrehozása**</span><span class="sxs-lookup"><span data-stu-id="39f5d-134">**Create a new cloud service and a storage account**</span></span>
   
    <span data-ttu-id="39f5d-135">Az Azure portál toocreate hello egy felhőalapú szolgáltatás és a storage-fiókok hello telepítéshez használni egy régióban, ahol az RDMA-kompatibilis hello példányok elérhetők.</span><span class="sxs-lookup"><span data-stu-id="39f5d-135">Use hello Azure portal toocreate a cloud service and a storage account for hello deployment in a region where hello RDMA-capable instances are available.</span></span>
4. <span data-ttu-id="39f5d-136">**Egy Azure csomópont-sablon létrehozása**</span><span class="sxs-lookup"><span data-stu-id="39f5d-136">**Create an Azure node template**</span></span>
   
    <span data-ttu-id="39f5d-137">Hello létrehozása csomópont sablon varázsló használata a HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="39f5d-137">Use hello Create Node Template Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-138">Útmutató: [hozzon létre egy Azure csomópont sablont](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) az "Azure-csomópontok és a Microsoft HPC Pack lépéseket tooDeploy".</span><span class="sxs-lookup"><span data-stu-id="39f5d-138">For steps, see [Create an Azure node template](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) in “Steps tooDeploy Azure Nodes with Microsoft HPC Pack”.</span></span>
   
    <span data-ttu-id="39f5d-139">A kezdeti tesztek javasoljuk, hogy manuális rendelkezésre állási házirend beállítása hello sablonban.</span><span class="sxs-lookup"><span data-stu-id="39f5d-139">For initial tests, we suggest configuring a manual availability policy in hello template.</span></span>
5. <span data-ttu-id="39f5d-140">**Csomópontok toohello fürt hozzáadása**</span><span class="sxs-lookup"><span data-stu-id="39f5d-140">**Add nodes toohello cluster**</span></span>
   
    <span data-ttu-id="39f5d-141">Hello hozzáadása csomópont varázslóját használja a HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="39f5d-141">Use hello Add Node Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-142">További információkért lásd: [Azure csomópontok hozzáadása toohello Windows HPC-fürt](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span><span class="sxs-lookup"><span data-stu-id="39f5d-142">For more information, see [Add Azure Nodes toohello Windows HPC Cluster](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span></span>
   
    <span data-ttu-id="39f5d-143">Hello csomópontok hello méretének megadása esetén válasszon ki egy hello RDMA-kompatibilisek-e példány mérete.</span><span class="sxs-lookup"><span data-stu-id="39f5d-143">When specifying hello size of hello nodes, select one of hello RDMA-capable instance sizes.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="39f5d-144">Minden egyes kapacitásnövelés tooAzure központi telepítés hello számítási igényű osztályt HPC Pack automatikusan telepíti a legalább két RDMA-kompatibilisek-példányok (például A8) proxy csomópontként, továbbá toohello Azure feldolgozói szerepkör-példányok megadása.</span><span class="sxs-lookup"><span data-stu-id="39f5d-144">In each burst tooAzure deployment with hello compute-intensive instances, HPC Pack automatically deploys a minimum of two RDMA-capable instances (such as A8) as proxy nodes, in addition toohello Azure worker role instances you specify.</span></span> <span data-ttu-id="39f5d-145">hello proxy csomópontok toohello előfizetés foglal le, és költségek mellett hello Azure feldolgozói szerepkör példányok magok használja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-145">hello proxy nodes use cores that are allocated toohello subscription and incur charges along with hello Azure worker role instances.</span></span>
   > 
   > 
6. <span data-ttu-id="39f5d-146">**Indítsa el a (kiépíteni) hello csomópontok és azok online toorun feladatok**</span><span class="sxs-lookup"><span data-stu-id="39f5d-146">**Start (provision) hello nodes and bring them online toorun jobs**</span></span>
   
    <span data-ttu-id="39f5d-147">Jelöljön ki hello csomópontokat, és hello **Start** HPC-Fürtkezelőben művelet.</span><span class="sxs-lookup"><span data-stu-id="39f5d-147">Select hello nodes and use hello **Start** action in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-148">Ha kiépítése befejeződött, válasszon hello csomópontot, majd használja a hello **online állapotba hozás** HPC-Fürtkezelőben művelet.</span><span class="sxs-lookup"><span data-stu-id="39f5d-148">When provisioning is complete, select hello nodes and use hello **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-149">hello csomópontok készen toorun feladatok.</span><span class="sxs-lookup"><span data-stu-id="39f5d-149">hello nodes are ready toorun jobs.</span></span>
7. <span data-ttu-id="39f5d-150">**Küldje el a feladatok toohello fürt**</span><span class="sxs-lookup"><span data-stu-id="39f5d-150">**Submit jobs toohello cluster**</span></span>
   
   <span data-ttu-id="39f5d-151">HPC Pack feladat elküldése eszközök toorun fürt feladatok használja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-151">Use HPC Pack job submission tools toorun cluster jobs.</span></span> <span data-ttu-id="39f5d-152">Lásd: [Microsoft HPC Pack: feladatkezelés](http://technet.microsoft.com/library/jj899585.aspx).</span><span class="sxs-lookup"><span data-stu-id="39f5d-152">See [Microsoft HPC Pack: Job Management](http://technet.microsoft.com/library/jj899585.aspx).</span></span>
8. <span data-ttu-id="39f5d-153">**Állítsa le a (deprovision) hello csomópontok**</span><span class="sxs-lookup"><span data-stu-id="39f5d-153">**Stop (deprovision) hello nodes**</span></span>
   
   <span data-ttu-id="39f5d-154">Futó feladat befejezése, hello csomópontok offline állapotba, és használja a hello **leállítása** HPC-Fürtkezelőben művelet.</span><span class="sxs-lookup"><span data-stu-id="39f5d-154">When you are done running jobs, take hello nodes offline and use hello **Stop** action in HPC Cluster Manager.</span></span>

## <a name="scenario-2-deploy-compute-nodes-in-compute-intensive-vms-iaas"></a><span data-ttu-id="39f5d-155">2. forgatókönyv: Központi telepítése a számítási csomópontok számítási igényű VMs (IaaS)</span><span class="sxs-lookup"><span data-stu-id="39f5d-155">Scenario 2: Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>
<span data-ttu-id="39f5d-156">Ebben a forgatókönyvben telepít hello HPC Pack átjárócsomópont és számítási fürtcsomópontok virtuális gépeken egy Azure virtuális hálózatban.</span><span class="sxs-lookup"><span data-stu-id="39f5d-156">In this scenario, you deploy hello HPC Pack head node and cluster compute nodes on VMs in an Azure virtual network.</span></span> <span data-ttu-id="39f5d-157">HPC Pack biztosít több [az Azure virtuális gépeken a központi telepítési beállítások](../../linux/hpcpack-cluster-options.md)automatikus telepítési parancsfájl és Azure gyors üzembe helyezési sablonokat is beleértve.</span><span class="sxs-lookup"><span data-stu-id="39f5d-157">HPC Pack provides several [deployment options in Azure VMs](../../linux/hpcpack-cluster-options.md), including automated deployment scripts and Azure quickstart templates.</span></span> <span data-ttu-id="39f5d-158">Például hello a következő szempontok és lépések útmutató toouse hello [HPC Pack IaaS telepítési parancsfájl](hpcpack-cluster-powershell-script.md) hello telepítése az Azure-ban HPC Pack 2012 R2 fürt automatizálásához.</span><span class="sxs-lookup"><span data-stu-id="39f5d-158">As an example, hello following considerations and steps guide you toouse hello [HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md) to automate hello deployment of an HPC Pack 2012 R2 cluster in Azure.</span></span>

![Az Azure virtuális gépeken fürt][iaas]

### <a name="steps"></a><span data-ttu-id="39f5d-160">Lépések</span><span class="sxs-lookup"><span data-stu-id="39f5d-160">Steps</span></span>
1. <span data-ttu-id="39f5d-161">**Hozzon létre egy fürt átjárócsomópontjába, és a számítási csomópont virtuális gépek egy ügyfélszámítógépen hello HPC Pack IaaS telepítési parancsfájl futtatásával**</span><span class="sxs-lookup"><span data-stu-id="39f5d-161">**Create a cluster head node and compute node VMs by running hello HPC Pack IaaS deployment script on a client computer**</span></span>
   
    <span data-ttu-id="39f5d-162">Hello HPC Pack IaaS telepítési parancsfájl csomag letöltését hello [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span><span class="sxs-lookup"><span data-stu-id="39f5d-162">Download hello HPC Pack IaaS Deployment Script package from hello [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span>
   
    <span data-ttu-id="39f5d-163">tooprepare hello ügyfélszámítógép hello parancsfájl konfigurációs fájlja és futtatási hello parancsfájl létrehozása című [HPC-fürt létrehozása hello HPC Pack IaaS telepítési parancsfájl](hpcpack-cluster-powershell-script.md).</span><span class="sxs-lookup"><span data-stu-id="39f5d-163">tooprepare hello client computer, create hello script configuration file, and run hello script, see [Create an HPC Cluster with hello HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md).</span></span> 
   
    <span data-ttu-id="39f5d-164">az RDMA-kompatibilis toodeploy számítási csomópontokat, Megjegyzés hello további szempontokról a következő:</span><span class="sxs-lookup"><span data-stu-id="39f5d-164">toodeploy RDMA-capable compute nodes, note hello following additional considerations:</span></span>
   
   * <span data-ttu-id="39f5d-165">**Virtuális hálózati**: Adjon meg egy új virtuális hálózatot, mely hello RDMA-kompatibilis példányméretének a régióban szeretné toouse érhető el.</span><span class="sxs-lookup"><span data-stu-id="39f5d-165">**Virtual network**: Specify a new virtual network in a region in which hello RDMA-capable instance size you want toouse is available.</span></span>
   * <span data-ttu-id="39f5d-166">**Windows Server operációs rendszer**: toosupport RDMA-kapcsolatot, adjon meg egy Windows Server 2012 R2 vagy Windows Server 2012 operációs rendszert hello számítási csomópont virtuális gépeket.</span><span class="sxs-lookup"><span data-stu-id="39f5d-166">**Windows Server operating system**: toosupport RDMA connectivity, specify a Windows Server 2012 R2 or Windows Server 2012 operating system for hello compute node VMs.</span></span>
   * <span data-ttu-id="39f5d-167">**A felhőalapú szolgáltatások**: javasoljuk, hogy az átjárócsomópont egy felhőalapú szolgáltatás és a másik felhőalapú szolgáltatást a számítási csomópontok telepítésével.</span><span class="sxs-lookup"><span data-stu-id="39f5d-167">**Cloud services**: We recommend deploying your head node in one cloud service and your compute nodes in a different cloud service.</span></span>
   * <span data-ttu-id="39f5d-168">**Csomópont méretének HEAD**: A jelen esetben fontolja meg egy méretének legalább A4 (Extra nagy) hello központi csomópont.</span><span class="sxs-lookup"><span data-stu-id="39f5d-168">**Head node size**: For this scenario, consider a size of at least A4 (Extra Large) for hello head node.</span></span>
   * <span data-ttu-id="39f5d-169">**HpcVmDrivers bővítmény**: hello telepítési parancsfájl hello Azure Virtuálisgép-ügynök és hello HpcVmDrivers bővítmény automatikusan telepíti mérete A8 és A9 számítási csomópontok a Windows Server operációs rendszer központi telepítésekor.</span><span class="sxs-lookup"><span data-stu-id="39f5d-169">**HpcVmDrivers extension**: hello deployment script installs hello Azure VM Agent and hello HpcVmDrivers extension automatically when you deploy size A8 or A9 compute nodes with a Windows Server operating system.</span></span> <span data-ttu-id="39f5d-170">HpcVmDrivers, hogy csatlakozhassanak a toohello RDMA hálózati hello számítási csomópont virtuális gépeket telepít illesztőprogramokat.</span><span class="sxs-lookup"><span data-stu-id="39f5d-170">HpcVmDrivers installs drivers on hello compute node VMs so they can connect toohello RDMA network.</span></span> <span data-ttu-id="39f5d-171">Az RDMA-kompatibilis H sorozatú virtuális gépeken manuálisan kell telepítenie a hello HpcVmDrivers bővítmény.</span><span class="sxs-lookup"><span data-stu-id="39f5d-171">On RDMA-capable H-series VMs, you must manually install hello HpcVmDrivers extension.</span></span> <span data-ttu-id="39f5d-172">Lásd: [nagy teljesítményű számítási Virtuálisgép-méretek](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="39f5d-172">See [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
   * <span data-ttu-id="39f5d-173">**Fürthálózat-konfiguráció**: hello telepítési parancsfájl automatikusan beállítja a hello HPC Pack fürt topológia 5 (hello vállalati hálózaton található összes csomópontra).</span><span class="sxs-lookup"><span data-stu-id="39f5d-173">**Cluster network configuration**: hello deployment script automatically sets up hello HPC Pack cluster in Topology 5 (all nodes on hello Enterprise network).</span></span> <span data-ttu-id="39f5d-174">Ez a topológia összes HPC Pack fürtök telepítésének a virtuális gépek szükség.</span><span class="sxs-lookup"><span data-stu-id="39f5d-174">This topology is required for all HPC Pack cluster deployments in VMs.</span></span> <span data-ttu-id="39f5d-175">Ne változtassa meg később hello fürt hálózati topológia.</span><span class="sxs-lookup"><span data-stu-id="39f5d-175">Do not change hello cluster network topology later.</span></span>
2. <span data-ttu-id="39f5d-176">**Kapcsolja a számítási csomópontok hello online toorun feladatok**</span><span class="sxs-lookup"><span data-stu-id="39f5d-176">**Bring hello compute nodes online toorun jobs**</span></span>
   
    <span data-ttu-id="39f5d-177">Jelöljön ki hello csomópontokat, és hello **online állapotba hozás** HPC-Fürtkezelőben művelet.</span><span class="sxs-lookup"><span data-stu-id="39f5d-177">Select hello nodes and use hello **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-178">hello csomópontok készen toorun feladatok.</span><span class="sxs-lookup"><span data-stu-id="39f5d-178">hello nodes are ready toorun jobs.</span></span>
3. <span data-ttu-id="39f5d-179">**Küldje el a feladatok toohello fürt**</span><span class="sxs-lookup"><span data-stu-id="39f5d-179">**Submit jobs toohello cluster**</span></span>
   
    <span data-ttu-id="39f5d-180">Toohello átjárócsomópont toosubmit feladatok csatlakoztassa, vagy állítson be egy helyi számítógép toodo ez.</span><span class="sxs-lookup"><span data-stu-id="39f5d-180">Connect toohello head node toosubmit jobs, or set up an on-premises computer toodo this.</span></span> <span data-ttu-id="39f5d-181">További információ: [nyújt feladatok tooan HPC cluster az Azure-ban](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span><span class="sxs-lookup"><span data-stu-id="39f5d-181">For information, see [Submit Jobs tooan HPC cluster in Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
4. <span data-ttu-id="39f5d-182">**Hajtsa végre a megfelelő hello csomópontok offline és leállíthatja (felszabadítása) őket**</span><span class="sxs-lookup"><span data-stu-id="39f5d-182">**Take hello nodes offline and stop (deallocate) them**</span></span>
   
    <span data-ttu-id="39f5d-183">Futó feladatok befejezése után vegye offline hello csomópontok HPC Cluster Manager.</span><span class="sxs-lookup"><span data-stu-id="39f5d-183">When you are done running jobs, take hello nodes offline in HPC Cluster Manager.</span></span> <span data-ttu-id="39f5d-184">Ezután használja az Azure felügyeleti eszközök tooshut le őket.</span><span class="sxs-lookup"><span data-stu-id="39f5d-184">Then, use Azure management tools tooshut them down.</span></span>

## <a name="run-mpi-applications-on-hello-cluster"></a><span data-ttu-id="39f5d-185">MPI-alkalmazások futtatása hello fürtön</span><span class="sxs-lookup"><span data-stu-id="39f5d-185">Run MPI applications on hello cluster</span></span>
### <a name="example-run-mpipingpong-on-an-hpc-pack-cluster"></a><span data-ttu-id="39f5d-186">Példa: Mpipingpong futtatása HPC Pack fürtökön</span><span class="sxs-lookup"><span data-stu-id="39f5d-186">Example: Run mpipingpong on an HPC Pack cluster</span></span>
<span data-ttu-id="39f5d-187">egy RDMA-kompatibilis hello példányok futtatása HPC Pack telepítését tooverify hello HPC Pack **mpipingpong** hello fürtön parancsot.</span><span class="sxs-lookup"><span data-stu-id="39f5d-187">tooverify an HPC Pack deployment of hello RDMA-capable instances, run hello HPC Pack **mpipingpong** command on hello cluster.</span></span> <span data-ttu-id="39f5d-188">**mpipingpong** küld csomagokat párosított csomópontok közötti ismételten toocalculate késést és átviteli mérések és hello RDMA-kompatibilis alkalmazások hálózati statisztikája.</span><span class="sxs-lookup"><span data-stu-id="39f5d-188">**mpipingpong** sends packets of data between paired nodes repeatedly toocalculate latency and throughput measurements and statistics for hello RDMA-enabled application network.</span></span> <span data-ttu-id="39f5d-189">Ez a példa bemutatja egy tipikus mintája egy MPI feladat fut (ebben az esetben **mpipingpong**) hello fürttel **mpiexec** parancsot.</span><span class="sxs-lookup"><span data-stu-id="39f5d-189">This example shows a typical pattern for running an MPI job (in this case, **mpipingpong**) by using hello cluster **mpiexec** command.</span></span>

<span data-ttu-id="39f5d-190">Ebben a példában feltételezzük, hogy a "kapacitásnövelés tooAzure" konfigurációs hozzáadott Azure-csomópontok ([1. forgatókönyv](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span><span class="sxs-lookup"><span data-stu-id="39f5d-190">This example assumes you added Azure nodes in a “burst tooAzure” configuration ([Scenario 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span></span> <span data-ttu-id="39f5d-191">Ha Azure virtuális gépek fürt telepített HPC Pack, akkor lesz toomodify hello parancs szintaxisát toospecify egy másik csomópont csoportot kell, és további környezeti változók toodirect hálózati forgalom toohello RDMA hálózati.</span><span class="sxs-lookup"><span data-stu-id="39f5d-191">If you deployed HPC Pack on a cluster of Azure VMs, you’ll need toomodify hello command syntax toospecify a different node group and set additional environment variables toodirect network traffic toohello RDMA network.</span></span>

<span data-ttu-id="39f5d-192">toorun mpipingpong hello fürtön:</span><span class="sxs-lookup"><span data-stu-id="39f5d-192">toorun mpipingpong on hello cluster:</span></span>

1. <span data-ttu-id="39f5d-193">Hello központi csomóponton, vagy egy megfelelően konfigurált ügyfélszámítógépen nyisson meg egy parancssort.</span><span class="sxs-lookup"><span data-stu-id="39f5d-193">On hello head node or on a properly configured client computer, open a Command Prompt.</span></span>
2. <span data-ttu-id="39f5d-194">a négy csomópont közül parancs toosubmit egy feladat toorun mpipingpong kis csomagméret és sok a közelítés a következő típus hello egy Azure-kapacitásnövelés telepítési csomópontok közötti késés tooestimate:</span><span class="sxs-lookup"><span data-stu-id="39f5d-194">tooestimate latency between pairs of nodes in an Azure burst deployment of four nodes, type hello following command toosubmit a job toorun mpipingpong with a small packet size and many iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 1:100000 -op -s nul
    ```
   
    <span data-ttu-id="39f5d-195">hello parancs hello feladat elküldött hello Azonosítóját adja vissza.</span><span class="sxs-lookup"><span data-stu-id="39f5d-195">hello command returns hello ID of hello job that is submitted.</span></span>
   
    <span data-ttu-id="39f5d-196">Ha telepítette az Azure virtuális gépeken telepített hello HPC Pack fürtöt, adjon meg egy csomópont csoportot tartalmazó számítási csomópont virtuális gépek telepítve egyetlen felhőszolgáltatás, és módosítsa a hello **mpiexec** parancsot a következőképpen:</span><span class="sxs-lookup"><span data-stu-id="39f5d-196">If you deployed hello HPC Pack cluster deployed on Azure VMs, specify a node group that contains compute node VMs deployed in a single cloud service, and modify hello **mpiexec** command as follows:</span></span>
   
    ```Command
    job submit /nodegroup:vmcomputenodes /numnodes:4 mpiexec -c 1 -affinity -env MSMPI_DISABLE_SOCK 1 -env MSMPI_PRECONNECT all -env MPICH_NETMASK 172.16.0.0/255.255.0.0 mpipingpong -p 1:100000 -op -s nul
    ```
3. <span data-ttu-id="39f5d-197">Hello feladat befejezése után tooview hello kimeneti (ebben az esetben az 1. feladat hello feladat kimenetének hello), a következő típus hello</span><span class="sxs-lookup"><span data-stu-id="39f5d-197">When hello job completes, tooview hello output (in this case, hello output of task 1 of hello job), type hello following</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
    <span data-ttu-id="39f5d-198">Ha &lt; *JobID* &gt; hello azonosító hello feladat, amely el lett küldve.</span><span class="sxs-lookup"><span data-stu-id="39f5d-198">where &lt;*JobID*&gt; is hello ID of hello job that was submitted.</span></span>
   
    <span data-ttu-id="39f5d-199">hello kimeneti késés eredmények hasonló toohello következőket tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="39f5d-199">hello output includes latency results similar toohello following.</span></span>
   
    ![Ping pong késés][pingpong1]
4. <span data-ttu-id="39f5d-201">az Azure közötti tooestimate átviteli kapacitásnövelés csomópontok, típus hello következő parancsot a toosubmit egy feladat toorun **mpipingpong** a csomagok nagy méretű és néhány ismétlési:</span><span class="sxs-lookup"><span data-stu-id="39f5d-201">tooestimate throughput between pairs of Azure burst nodes, type hello following command toosubmit a job toorun **mpipingpong** with a large packet size and a few iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 4000000:1000 -op -s nul
    ```
   
    <span data-ttu-id="39f5d-202">hello parancs hello feladat elküldött hello Azonosítóját adja vissza.</span><span class="sxs-lookup"><span data-stu-id="39f5d-202">hello command returns hello ID of hello job that is submitted.</span></span>
   
    <span data-ttu-id="39f5d-203">Egy Azure virtuális gépeken telepített HPC Pack fürt módosítsa a hello parancs, a 2.</span><span class="sxs-lookup"><span data-stu-id="39f5d-203">On an HPC Pack cluster deployed on Azure VMs, modify hello command as noted in step 2.</span></span>
5. <span data-ttu-id="39f5d-204">Hello feladat befejezése után tooview hello kimeneti (ebben az esetben az 1. feladat hello feladat kimenetének hello), a következő típus hello:</span><span class="sxs-lookup"><span data-stu-id="39f5d-204">When hello job completes, tooview hello output (in this case, hello output of task 1 of hello job), type hello following:</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
   <span data-ttu-id="39f5d-205">hello kimeneti átviteli eredmények hasonló toohello következőket tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="39f5d-205">hello output includes throughput results similar toohello following.</span></span>
   
   ![Ping pong átviteli sebesség][pingpong2]

### <a name="mpi-application-considerations"></a><span data-ttu-id="39f5d-207">MPI alkalmazás kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="39f5d-207">MPI application considerations</span></span>
<span data-ttu-id="39f5d-208">Az alábbiakban szempontok az Azure-ban HPC Pack MPI-alkalmazások futtatására.</span><span class="sxs-lookup"><span data-stu-id="39f5d-208">Following are considerations for running MPI applications with HPC Pack in Azure.</span></span> <span data-ttu-id="39f5d-209">Néhány alkalmazása csak toodeployments Azure csomópontok (szerepkör feldolgozópéldányok "kapacitásnövelés tooAzure" konfigurációban hozzá).</span><span class="sxs-lookup"><span data-stu-id="39f5d-209">Some apply only toodeployments of Azure nodes (worker role instances added in a “burst tooAzure” configuration).</span></span>

* <span data-ttu-id="39f5d-210">Szerepkör feldolgozópéldányok felhőszolgáltatásban vannak rendszeresen újra kiépíteni minden külön értesítés nélkül az Azure-ban (például karbantartási, és a példány sikertelen).</span><span class="sxs-lookup"><span data-stu-id="39f5d-210">Worker role instances in a cloud service are periodically reprovisioned without notice by Azure (for example, for system maintenance, or in case an instance fails).</span></span> <span data-ttu-id="39f5d-211">Egy példány van újra kiépíteni, egy MPI-feladat futtatása, ha a hello példány elveszíti az adatokat, és toohello állapotba tér vissza, ha először telepítették, ami hello MPI feladat toofail okozhat.</span><span class="sxs-lookup"><span data-stu-id="39f5d-211">If an instance is reprovisioned while it is running an MPI job, hello instance loses its data and returns toohello state when it was first deployed, which can cause hello MPI job toofail.</span></span> <span data-ttu-id="39f5d-212">hello több olyan csomópontot, amely egyetlen MPI feladat használja, és hello már hello feladat fut, hello nagyobb a valószínűsége annak, hogy hello példányok egyik újra van kiépíteni a feladat futása közben.</span><span class="sxs-lookup"><span data-stu-id="39f5d-212">hello more nodes that you use for a single MPI job, and hello longer hello job runs, hello more likely that one of hello instances is reprovisioned while a job is running.</span></span> <span data-ttu-id="39f5d-213">Is megfontolandó szempontok hello telepítésben egyetlen csomópont fájlkiszolgálóként megadásakor.</span><span class="sxs-lookup"><span data-stu-id="39f5d-213">Also consider this if you designate a single node in hello deployment as a file server.</span></span>
* <span data-ttu-id="39f5d-214">toorun MPI-feladatok az Azure-ban, nincs toouse hello RDMA-kompatibilis példányok.</span><span class="sxs-lookup"><span data-stu-id="39f5d-214">toorun MPI jobs in Azure, you don't have toouse hello RDMA-capable instances.</span></span> <span data-ttu-id="39f5d-215">HPC Pack által támogatott bármely példányméretének is használhatja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-215">You can use any instance size that is supported by HPC Pack.</span></span> <span data-ttu-id="39f5d-216">Azonban a hello RDMA-kompatibilis példányok ajánlott, amelyek bizalmas toohello késés és a hello csomópontok csatlakozó hello hálózati sávszélesség hello viszonylag nagy méretű MPI-feladatok futtatásához.</span><span class="sxs-lookup"><span data-stu-id="39f5d-216">However, hello RDMA-capable instances are recommended for running relatively large-scale MPI jobs that are sensitive toohello latency and hello bandwidth of hello network that connects hello nodes.</span></span> <span data-ttu-id="39f5d-217">Ha használ egyéb méretek toorun és sávszélesség-késésérzékeny MPI-feladatok, ajánlott futó kis feladatok, amelyben fut egy feladat csak néhány csomópont.</span><span class="sxs-lookup"><span data-stu-id="39f5d-217">If you use other sizes toorun latency- and bandwidth-sensitive MPI jobs, we recommend running small jobs, in which a single task runs on only a few nodes.</span></span>
* <span data-ttu-id="39f5d-218">Központilag telepített alkalmazások tooAzure példányok rendszer licencelési időszakonként hello alkalmazáshoz kapcsolódó tulajdonos toohello.</span><span class="sxs-lookup"><span data-stu-id="39f5d-218">Applications deployed tooAzure instances are subject toohello licensing terms associated with hello application.</span></span> <span data-ttu-id="39f5d-219">Ellenőrizze minden kereskedelmi alkalmazás licenckezelési vagy más korlátozásokat hello felhőben futó hello gyártójánál.</span><span class="sxs-lookup"><span data-stu-id="39f5d-219">Check with hello vendor of any commercial application for licensing or other restrictions for running in hello cloud.</span></span> <span data-ttu-id="39f5d-220">Nem minden szállító kínál használatalapú licencet.</span><span class="sxs-lookup"><span data-stu-id="39f5d-220">Not all vendors offer pay-as-you-go licensing.</span></span>
* <span data-ttu-id="39f5d-221">Azure-példányokon további kell beállítani, tooaccess helyszíni csomópontok, megosztásokon és licenckiszolgálókat.</span><span class="sxs-lookup"><span data-stu-id="39f5d-221">Azure instances need further setup tooaccess on-premises nodes, shares, and license servers.</span></span> <span data-ttu-id="39f5d-222">Például a tooenable hello Azure-csomópontok tooaccess helyszíni licenckiszolgáló, konfigurálhatja a pont-pont Azure virtuális hálózat.</span><span class="sxs-lookup"><span data-stu-id="39f5d-222">For example, tooenable hello Azure nodes tooaccess an on-premises license server, you can configure a site-to-site Azure virtual network.</span></span>
* <span data-ttu-id="39f5d-223">Azure-példányokon toorun MPI alkalmazások minden MPI alkalmazás regisztrálása a Windows tűzfal hello példányokon hello futtatásával **hpcfwutil** parancsot.</span><span class="sxs-lookup"><span data-stu-id="39f5d-223">toorun MPI applications on Azure instances, register each MPI application with Windows Firewall on hello instances by running hello **hpcfwutil** command.</span></span> <span data-ttu-id="39f5d-224">Ez lehetővé teszi a MPI kommunikációs tootake hely hello tűzfal által dinamikusan hozzárendelt porton.</span><span class="sxs-lookup"><span data-stu-id="39f5d-224">This allows MPI communications tootake place on a port that is assigned dynamically by hello firewall.</span></span>
  
  > [!NOTE]
  > <span data-ttu-id="39f5d-225">Kapacitásnövelés tooAzure telepítések esetén is beállíthatja egy tűzfal kivétel parancs toorun automatikusan minden csomóponton új Azure tooyour fürt hozzáadott.</span><span class="sxs-lookup"><span data-stu-id="39f5d-225">For burst tooAzure deployments, you can also configure a firewall exception command toorun automatically on all new Azure nodes that are added tooyour cluster.</span></span> <span data-ttu-id="39f5d-226">Miután lefuttatta a hello **hpcfwutil** parancsot, és győződjön meg arról, hogy az alkalmazás akkor működik, hello parancs tooa indítási parancsfájl az Azure csomópontok hozzáadása.</span><span class="sxs-lookup"><span data-stu-id="39f5d-226">After you run hello **hpcfwutil** command and verify that your application works, add hello command tooa startup script for your Azure nodes.</span></span> <span data-ttu-id="39f5d-227">További információkért lásd: [indítási parancsfájl használata Azure csomópontok](https://technet.microsoft.com/library/jj899632.aspx).</span><span class="sxs-lookup"><span data-stu-id="39f5d-227">For more information, see [Use a Startup Script for Azure Nodes](https://technet.microsoft.com/library/jj899632.aspx).</span></span>
  > 
  > 
* <span data-ttu-id="39f5d-228">HPC Pack hello CCP_MPI_NETMASK fürt környezeti változó toospecify elfogadható címtartományt MPI kommunikációhoz használ.</span><span class="sxs-lookup"><span data-stu-id="39f5d-228">HPC Pack uses hello CCP_MPI_NETMASK cluster environment variable toospecify a range of acceptable addresses for MPI communication.</span></span> <span data-ttu-id="39f5d-229">A HPC Pack 2012 R2-től kezdődően hello CCP_MPI_NETMASK fürt környezeti változó csak MPI kommunikációt érinti a tartományhoz csatlakoztatott számítási fürtcsomópontok közötti (helyi vagy az Azure virtuális gépeken).</span><span class="sxs-lookup"><span data-stu-id="39f5d-229">Starting in HPC Pack 2012 R2, hello CCP_MPI_NETMASK cluster environment variable only affects MPI communication between domain-joined cluster compute nodes (either on-premises or in Azure VMs).</span></span> <span data-ttu-id="39f5d-230">hello változó kapacitásnövelés tooAzure konfigurációban hozzáadott csomópontok figyelmen kívül hagyja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-230">hello variable is ignored by nodes added in a burst tooAzure configuration.</span></span>
* <span data-ttu-id="39f5d-231">MPI-feladatok futtatása nem Azure-példányokon különböző felhőszolgáltatások (például kapacitásnövelés tooAzure telepítések esetén másik csomópont sablonok vagy Azure virtuális gép számítási csomópontok több felhőszolgáltatásra telepítése) üzembe helyezett.</span><span class="sxs-lookup"><span data-stu-id="39f5d-231">MPI jobs can't run across Azure instances that are deployed in different cloud services (for example, in burst tooAzure deployments with different node templates, or Azure VM compute nodes deployed in multiple cloud services).</span></span> <span data-ttu-id="39f5d-232">Ha több Azure csomópont-telepítés másik csomópont sablonok kezdődnek, csak egy Azure-csomópontok készlete hello MPI feladatot kell futtatnia.</span><span class="sxs-lookup"><span data-stu-id="39f5d-232">If you have multiple Azure node deployments that are started with different node templates, hello MPI job must run on only one set of Azure nodes.</span></span>
* <span data-ttu-id="39f5d-233">Ha Azure-csomópontok tooyour fürt hozzáadása és vetheti online, hello HPC Job Feladatütemező szolgáltatás azonnal megpróbál toostart feladatok hello csomópontján.</span><span class="sxs-lookup"><span data-stu-id="39f5d-233">When you add Azure nodes tooyour cluster and bring them online, hello HPC Job Scheduler Service immediately tries toostart jobs on hello nodes.</span></span> <span data-ttu-id="39f5d-234">Ha csak egy részét a számítási feladatok Azure futtathatja, győződjön meg arról, frissítésekor vagy feladat sablonok toodefine milyen típusú futtatható Azure feladat létrehozása.</span><span class="sxs-lookup"><span data-stu-id="39f5d-234">If only a portion of your workload can run on Azure, ensure that you update or create job templates toodefine what job types can run on Azure.</span></span> <span data-ttu-id="39f5d-235">Például, hogy a feladat sablon csak az Azure csomóponton, futtassa az elküldött feladatok hello csomópont csoportok tulajdonság toohello feladat sablon hozzáadása és a AzureNodes hello tooensure szükséges érték.</span><span class="sxs-lookup"><span data-stu-id="39f5d-235">For example, tooensure that jobs submitted with a job template only run on Azure nodes, add hello Node Groups property toohello job template and select AzureNodes as hello required value.</span></span> <span data-ttu-id="39f5d-236">az Azure-csomópontok toocreate egyéni csoportok hello Add-HpcGroup HPC PowerShell-parancsmagot használhatja.</span><span class="sxs-lookup"><span data-stu-id="39f5d-236">toocreate custom groups for your Azure nodes, use hello Add-HpcGroup HPC PowerShell cmdlet.</span></span>

## <a name="next-steps"></a><span data-ttu-id="39f5d-237">Következő lépések</span><span class="sxs-lookup"><span data-stu-id="39f5d-237">Next steps</span></span>
* <span data-ttu-id="39f5d-238">Alternatív toousing HPC Pack, mint a hello Azure Batch szolgáltatás toorun MPI alkalmazások fejlesztéséhez a számítási csomópontok az Azure-készlethez.</span><span class="sxs-lookup"><span data-stu-id="39f5d-238">As an alternative toousing HPC Pack, develop with hello Azure Batch service toorun MPI applications on managed pools of compute nodes in Azure.</span></span> <span data-ttu-id="39f5d-239">Lásd: [használata többpéldányos feladatok toorun Message Passing Interface (MPI) alkalmazások az Azure Batch](../../../batch/batch-mpi.md).</span><span class="sxs-lookup"><span data-stu-id="39f5d-239">See [Use multi-instance tasks toorun Message Passing Interface (MPI) applications in Azure Batch](../../../batch/batch-mpi.md).</span></span>
* <span data-ttu-id="39f5d-240">Ha azt szeretné, hogy toorun Linux MPI hello Azure RDMA hálózati, elérhető alkalmazásokat lásd: [állítson be egy Linux RDMA fürt toorun MPI alkalmazások](../../linux/classic/rdma-cluster.md).</span><span class="sxs-lookup"><span data-stu-id="39f5d-240">If you want toorun Linux MPI applications that access hello Azure RDMA network, see [Set up a Linux RDMA cluster toorun MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

<!--Image references-->
[burst]:media/hpcpack-rdma-cluster/burst.png
[iaas]:media/hpcpack-rdma-cluster/iaas.png
[pingpong1]:media/hpcpack-rdma-cluster/pingpong1.png
[pingpong2]:media/hpcpack-rdma-cluster/pingpong2.png
