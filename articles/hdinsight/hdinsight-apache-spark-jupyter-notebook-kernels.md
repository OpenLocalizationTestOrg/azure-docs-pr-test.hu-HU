---
title: aaaKernels Jupyter notebookokhoz a Spark on Azure hdinsight clusters |} Microsoft Docs
description: "További információk a Jupyter notebookokhoz elérhető Azure hdinsight Spark-fürtjei PySpark PySpark3 és Spark mag hello."
keywords: a spark, jupyter spark jupyter notebook
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="b2854-104">Az Azure hdinsight Spark-fürtjei Jupyter notebookokhoz kernelek</span><span class="sxs-lookup"><span data-stu-id="b2854-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="b2854-105">HDInsight Spark-fürtjei használata hello Jupyter notebook a Spark on az alkalmazások teszteléséhez kernelt biztosítanak.</span><span class="sxs-lookup"><span data-stu-id="b2854-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="b2854-106">A rendszermag egy olyan program, fut, és a kód értelmezi.</span><span class="sxs-lookup"><span data-stu-id="b2854-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="b2854-107">hello három kernelek a következők:</span><span class="sxs-lookup"><span data-stu-id="b2854-107">hello three kernels are:</span></span>

- <span data-ttu-id="b2854-108">**PySpark** – a Python2 írt alkalmazások esetén</span><span class="sxs-lookup"><span data-stu-id="b2854-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="b2854-109">**PySpark3** – a Python3 írt alkalmazások esetén</span><span class="sxs-lookup"><span data-stu-id="b2854-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="b2854-110">**Spark** - scalában írt alkalmazások esetén</span><span class="sxs-lookup"><span data-stu-id="b2854-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="b2854-111">Ebből a cikkből megismerheti, hogyan toouse ezek kernelek és a használatuk hello előnyeit.</span><span class="sxs-lookup"><span data-stu-id="b2854-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="b2854-112">Előfeltételek</span><span class="sxs-lookup"><span data-stu-id="b2854-112">Prerequisites</span></span>

* <span data-ttu-id="b2854-113">Apache Spark-fürt hdinsightban.</span><span class="sxs-lookup"><span data-stu-id="b2854-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="b2854-114">Útmutatásért lásd: [létrehozása az Apache Spark on Azure hdinsight clusters](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="b2854-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="b2854-115">A Spark on HDInsight Jupyter notebook létrehozása</span><span class="sxs-lookup"><span data-stu-id="b2854-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="b2854-116">A hello [Azure-portálon](https://portal.azure.com/), nyissa meg a fürt.</span><span class="sxs-lookup"><span data-stu-id="b2854-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="b2854-117">Lásd: [listája és megjelenítése fürtök](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) hello utasításokat.</span><span class="sxs-lookup"><span data-stu-id="b2854-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="b2854-118">egy új portálpanelen hello fürt nyílik meg.</span><span class="sxs-lookup"><span data-stu-id="b2854-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="b2854-119">A hello **Gyorshivatkozások** területén kattintson **irányítópultok fürt** tooopen hello **irányítópultok fürt** panelen.</span><span class="sxs-lookup"><span data-stu-id="b2854-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="b2854-120">Ha nem lát **Gyorshivatkozások**, kattintson a **áttekintése** hello panelen hello bal oldali menüből.</span><span class="sxs-lookup"><span data-stu-id="b2854-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="b2854-121">![A Spark Jupyter notebook](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Spark a Jupyter notebook")</span><span class="sxs-lookup"><span data-stu-id="b2854-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="b2854-122">Kattintson a **Jupyter Notebook**.</span><span class="sxs-lookup"><span data-stu-id="b2854-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="b2854-123">Ha a rendszer kéri, adja meg hello fürt hello rendszergazdai hitelesítő adataival.</span><span class="sxs-lookup"><span data-stu-id="b2854-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="b2854-124">Előfordulhat, hogy is elérni a Spark-fürt URL-címet a böngészőben a következő megnyitásakor hello hello Jupyter notebook.</span><span class="sxs-lookup"><span data-stu-id="b2854-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="b2854-125">Cserélje le **CLUSTERNAME** hello néven a fürt:</span><span class="sxs-lookup"><span data-stu-id="b2854-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="b2854-126">Kattintson a **új**, majd a **Pyspark**, **PySpark3**, vagy **Spark** toocreate jegyzetfüzet.</span><span class="sxs-lookup"><span data-stu-id="b2854-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="b2854-127">Használja a hello Spark kernel Scala-alkalmazások, a PySpark kernel Python2 alkalmazások és a PySpark3 kernel Python3 alkalmazásokhoz.</span><span class="sxs-lookup"><span data-stu-id="b2854-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="b2854-128">![Jupyter notebookokhoz a Spark mag](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Jupyter notebookokhoz a Spark mag")</span><span class="sxs-lookup"><span data-stu-id="b2854-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="b2854-129">A notebook kiválasztott hello kernel nyílik meg.</span><span class="sxs-lookup"><span data-stu-id="b2854-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="b2854-130">Hello kernelek használatának előnyei</span><span class="sxs-lookup"><span data-stu-id="b2854-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="b2854-131">Az alábbiakban néhány használatának előnyei egy hello új kernelek a Jupyter notebook a Spark HDInsight-fürtökön.</span><span class="sxs-lookup"><span data-stu-id="b2854-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="b2854-132">**Az adott néven beállítás környezetek**.</span><span class="sxs-lookup"><span data-stu-id="b2854-132">**Preset contexts**.</span></span> <span data-ttu-id="b2854-133">A **PySpark**, **PySpark3**, vagy hello **Spark** mag, nem kell tooset hello Spark- vagy Hive-környezeteket explicit módon az alkalmazások használatának megkezdése előtt.</span><span class="sxs-lookup"><span data-stu-id="b2854-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="b2854-134">Ezek a alapértelmezés szerint elérhető.</span><span class="sxs-lookup"><span data-stu-id="b2854-134">These are available by default.</span></span> <span data-ttu-id="b2854-135">Ezek a környezetek a következők:</span><span class="sxs-lookup"><span data-stu-id="b2854-135">These contexts are:</span></span>
   
   * <span data-ttu-id="b2854-136">**sc** - Spark-környezet</span><span class="sxs-lookup"><span data-stu-id="b2854-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="b2854-137">**az sqlContext** - struktúra környezet</span><span class="sxs-lookup"><span data-stu-id="b2854-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="b2854-138">Igen nincs toorun utasítások, mint például a következő tooset hello környezetek hello:</span><span class="sxs-lookup"><span data-stu-id="b2854-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="b2854-139">sc SparkContext('yarn-client') az sqlContext = = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="b2854-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="b2854-140">Ehelyett közvetlenül használható hello beállított környezetek az alkalmazásban.</span><span class="sxs-lookup"><span data-stu-id="b2854-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="b2854-141">**A cella magics**.</span><span class="sxs-lookup"><span data-stu-id="b2854-141">**Cell magics**.</span></span> <span data-ttu-id="b2854-142">hello PySpark kernel tartalmaz néhány előre definiált "magics", amelyeket speciális meghívhatja a parancsok `%%` (például `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="b2854-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="b2854-143">hello magic parancs hello első szótól kód cella legyen, és lehetővé teszik a tartalom több sornyi.</span><span class="sxs-lookup"><span data-stu-id="b2854-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="b2854-144">hello magic word hello első szótól hello cellában kell lennie.</span><span class="sxs-lookup"><span data-stu-id="b2854-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="b2854-145">Hozzáadás semmit hello magic, még akkor is, a megjegyzéseket, mielőtt hibát okoz.</span><span class="sxs-lookup"><span data-stu-id="b2854-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="b2854-146">A magics további információkért lásd: [Itt](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="b2854-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="b2854-147">hello következő táblázat különböző magics hello hello kernelek keresztül érhető el.</span><span class="sxs-lookup"><span data-stu-id="b2854-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="b2854-148">Varázsszám</span><span class="sxs-lookup"><span data-stu-id="b2854-148">Magic</span></span> | <span data-ttu-id="b2854-149">Példa</span><span class="sxs-lookup"><span data-stu-id="b2854-149">Example</span></span> | <span data-ttu-id="b2854-150">Leírás</span><span class="sxs-lookup"><span data-stu-id="b2854-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="b2854-151">segítség</span><span class="sxs-lookup"><span data-stu-id="b2854-151">help</span></span> |`%%help` |<span data-ttu-id="b2854-152">Létrehoz egy táblát az összes hello elérhető magics példa és leírása</span><span class="sxs-lookup"><span data-stu-id="b2854-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="b2854-153">információ</span><span class="sxs-lookup"><span data-stu-id="b2854-153">info</span></span> |`%%info` |<span data-ttu-id="b2854-154">Munkamenet-információk kimenetek hello aktuális Livy végpont</span><span class="sxs-lookup"><span data-stu-id="b2854-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="b2854-155">Konfigurálása</span><span class="sxs-lookup"><span data-stu-id="b2854-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="b2854-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="b2854-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="b2854-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="b2854-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="b2854-158">Konfigurálja a hello paramétereit a munkamenet létrehozásához.</span><span class="sxs-lookup"><span data-stu-id="b2854-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="b2854-159">hello force jelzést (-f) megadása kötelező, ha már létrehozott egy munkamenetet, amely biztosítja, hogy hello munkamenet eldobott és ismételt létrehozása megtörtént.</span><span class="sxs-lookup"><span data-stu-id="b2854-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="b2854-160">Nézze meg [Livy a FELADÁS egy vagy több /sessions kérelem törzse](https://github.com/cloudera/livy#request-body) érvényes paraméterek listáját.</span><span class="sxs-lookup"><span data-stu-id="b2854-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="b2854-161">Paraméterek a JSON karakterláncként kell átadnia, és későbbinek kell lennie hello következő sorban hello magic hello példa oszlopban látható.</span><span class="sxs-lookup"><span data-stu-id="b2854-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="b2854-162">SQL</span><span class="sxs-lookup"><span data-stu-id="b2854-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="b2854-163">Végrehajtja a Hive-lekérdezések hello az sqlContext ellen.</span><span class="sxs-lookup"><span data-stu-id="b2854-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="b2854-164">Ha hello `-o` paramétert, a hello megőrződjenek hello hello lekérdezés eredménye %% helyi Python-környezetben, egy [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="b2854-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="b2854-165">helyi</span><span class="sxs-lookup"><span data-stu-id="b2854-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="b2854-166">Az egymás utáni sorok összes hello kód végrehajtása helyileg.</span><span class="sxs-lookup"><span data-stu-id="b2854-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="b2854-167">Kód hello kernel módjától függetlenül is érvényes Python2 kódot kell lennie.</span><span class="sxs-lookup"><span data-stu-id="b2854-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="b2854-168">Igen, akkor is, ha a kiválasztott **PySpark3** vagy **Spark** kernelek hello notebook létrehozásakor, ha hello `%%local` magic cellába, ezt a cellát csak rendelkeznie kell érvényes Python2 kódot...</span><span class="sxs-lookup"><span data-stu-id="b2854-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="b2854-169">naplók</span><span class="sxs-lookup"><span data-stu-id="b2854-169">logs</span></span> |`%%logs` |<span data-ttu-id="b2854-170">Kimenetek hello aktuális Livy munkamenet hello naplókat.</span><span class="sxs-lookup"><span data-stu-id="b2854-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="b2854-171">törlése</span><span class="sxs-lookup"><span data-stu-id="b2854-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="b2854-172">Egy adott munkamenet hello aktuális Livy végpont törlése.</span><span class="sxs-lookup"><span data-stu-id="b2854-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="b2854-173">Vegye figyelembe, hogy hello munkamenet indításának hello kernel maga nem törölhető.</span><span class="sxs-lookup"><span data-stu-id="b2854-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="b2854-174">Tisztítás</span><span class="sxs-lookup"><span data-stu-id="b2854-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="b2854-175">Törli az összes hello munkamenet hello aktuális Livy végpont, beleértve a jegyzetfüzet munkamenet.</span><span class="sxs-lookup"><span data-stu-id="b2854-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="b2854-176">hello kényszerített jelző -f megadása kötelező.</span><span class="sxs-lookup"><span data-stu-id="b2854-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="b2854-177">Ezenkívül toohello magics által hozzáadott hello PySpark kernel, használhatja a hello [beépített IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), többek között a következőket `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="b2854-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="b2854-178">Használhatja a hello `%%sh` magic toorun parancsfájlok és a fürt headnode hello kódblokkot.</span><span class="sxs-lookup"><span data-stu-id="b2854-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="b2854-179">**A képi megjelenítés automatikus**.</span><span class="sxs-lookup"><span data-stu-id="b2854-179">**Auto visualization**.</span></span> <span data-ttu-id="b2854-180">Hello **Pyspark** kernel automatikusan visualizes hello kimeneti struktúra és az SQL-lekérdezéseket.</span><span class="sxs-lookup"><span data-stu-id="b2854-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="b2854-181">Számos különféle típusú képi megjelenítések, beleértve a tábla, torta, vonal, terület, sáv választhat.</span><span class="sxs-lookup"><span data-stu-id="b2854-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="b2854-182">Hello támogatott paraméterek %% sql varázsszám</span><span class="sxs-lookup"><span data-stu-id="b2854-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="b2854-183">Hello `%%sql` magic támogatja a különböző paraméterek közül választhat, hogy lekérdezések futtatásakor kapó kimeneti toocontrol hello típusú.</span><span class="sxs-lookup"><span data-stu-id="b2854-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="b2854-184">a következő táblázat hello hello kimeneti sorolja fel.</span><span class="sxs-lookup"><span data-stu-id="b2854-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="b2854-185">Paraméter</span><span class="sxs-lookup"><span data-stu-id="b2854-185">Parameter</span></span> | <span data-ttu-id="b2854-186">Példa</span><span class="sxs-lookup"><span data-stu-id="b2854-186">Example</span></span> | <span data-ttu-id="b2854-187">Leírás</span><span class="sxs-lookup"><span data-stu-id="b2854-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="b2854-188">-o</span><span class="sxs-lookup"><span data-stu-id="b2854-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="b2854-189">Használja a hello lekérdezés paraméter toopersist hello eredménye hello %% helyi Python-környezetben, mint egy [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="b2854-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="b2854-190">hello hello dataframe változó értéke hello változó nevét, adja meg.</span><span class="sxs-lookup"><span data-stu-id="b2854-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="b2854-191">-k</span><span class="sxs-lookup"><span data-stu-id="b2854-191">-q</span></span> |`-q` |<span data-ttu-id="b2854-192">A képi megjelenítések ki tooturn hello cella használja.</span><span class="sxs-lookup"><span data-stu-id="b2854-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="b2854-193">Ha nem szeretné, hogy tooauto-megjelenítheti hello egy cella tartalmát, és csak szeretné, hogy toocapture azt egy dataframe, majd használja `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="b2854-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="b2854-194">Ha azt szeretné, ki képi megjelenítések tooturn hello eredmények rögzítése nélkül (, például egy SQL-lekérdezést, például fut egy `CREATE TABLE` utasítás), használjon `-q` megadása nélkül egy `-o` argumentum.</span><span class="sxs-lookup"><span data-stu-id="b2854-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="b2854-195">-m</span><span class="sxs-lookup"><span data-stu-id="b2854-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="b2854-196">Ha **METÓDUS** vagy **érvénybe** vagy **minta** (alapértelmezett érték a **érvénybe**).</span><span class="sxs-lookup"><span data-stu-id="b2854-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="b2854-197">Ha hello módszer **igénybe**, hello kernel szerzi a hello felső hello adatok eredményhalmaz MAXROWS (később a táblázatban ismertetett) által meghatározott elemek.</span><span class="sxs-lookup"><span data-stu-id="b2854-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="b2854-198">Ha hello módszer **minta**, hello kernel véletlenszerűen minták szerint túl hello adatkészlet elemeinek`-r` paramétert, a következő táblázatban leírt.</span><span class="sxs-lookup"><span data-stu-id="b2854-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="b2854-199">-r</span><span class="sxs-lookup"><span data-stu-id="b2854-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="b2854-200">Itt **mért** 0,0 és 1,0 közötti lebegőpontos szám.</span><span class="sxs-lookup"><span data-stu-id="b2854-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="b2854-201">Ha hello minta hello SQL-lekérdezés módja `sample`, majd hello kernel véletlenszerűen minták hello hello elemeinek hello eredménykészlet, hogy a megadott mekkora részét.</span><span class="sxs-lookup"><span data-stu-id="b2854-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="b2854-202">Például, ha futtatja az SQL-lekérdezést hello argumentumokkal `-m sample -r 0.01`, majd véletlenszerűen lekérdező hello sorok 1 %-át.</span><span class="sxs-lookup"><span data-stu-id="b2854-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="b2854-203">**MAXROWS** egész érték.</span><span class="sxs-lookup"><span data-stu-id="b2854-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="b2854-204">hello kernel korlátozza hello kimeneti sorok száma túl**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="b2854-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="b2854-205">Ha **MAXROWS** például van egy negatív szám **-1**, majd hello hello eredménykészlet sorainak száma nincs korlátozva.</span><span class="sxs-lookup"><span data-stu-id="b2854-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="b2854-206">**Példa**</span><span class="sxs-lookup"><span data-stu-id="b2854-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="b2854-207">a fenti hello utasítás hello a következő:</span><span class="sxs-lookup"><span data-stu-id="b2854-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="b2854-208">Kiválasztja az összes rekordot **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="b2854-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="b2854-209">Használjuk a - q, mert automatikus-képi megjelenítés kikapcsolása.</span><span class="sxs-lookup"><span data-stu-id="b2854-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="b2854-210">Mivel használjuk `-m sample -r 0.1 -n 500` véletlenszerűen – minták 10 % hello hivesampletable hello sorok és korlátai hello hello beállítása too500 sorok méretét.</span><span class="sxs-lookup"><span data-stu-id="b2854-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="b2854-211">Végül mert használtuk `-o query2` is hello kimeneti menti azokat a dataframe nevű **lekérdezés2**.</span><span class="sxs-lookup"><span data-stu-id="b2854-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="b2854-212">Új kernelek hello használata során kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="b2854-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="b2854-213">Használja, amelyik kernel hello fürterőforrások futtató hello notebookok elhagyása igényel.</span><span class="sxs-lookup"><span data-stu-id="b2854-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="b2854-214">Ezek kernelek hello környezetek előre van állítva, mert egyszerűen Kilépés hello notebookok nem kill hello környezetben, és ezért hello fürterőforrások továbbra is toobe használja.</span><span class="sxs-lookup"><span data-stu-id="b2854-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="b2854-215">Bevált gyakorlat az toouse hello **zárja be és Halt** hello notebook kapcsolót **fájl** használhatatlanná teszi hello környezetben hello notebook használatának befejezése után, és majd kilépés hello notebook menü.</span><span class="sxs-lookup"><span data-stu-id="b2854-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="b2854-216">Néhány példa megjelenítése</span><span class="sxs-lookup"><span data-stu-id="b2854-216">Show me some examples</span></span>

<span data-ttu-id="b2854-217">Jupyter notebook megnyitásakor látni hello gyökérszinten elérhető két mappát.</span><span class="sxs-lookup"><span data-stu-id="b2854-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="b2854-218">Hello **PySpark** mappa rendelkezik minta notebookok adott használata hello új **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="b2854-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="b2854-219">Hello **Scala** mappa rendelkezik minta notebookok adott használata hello új **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="b2854-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="b2854-220">Megnyithatja a hello **Spark Magic 00 - [OLVASHATÓ első] Kernel szolgáltatások** hello a notebook **PySpark** vagy **Spark** mappa toolearn kapcsolatos hello különböző magics érhető el.</span><span class="sxs-lookup"><span data-stu-id="b2854-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="b2854-221">Is használhatja más minta notebookok hello két mappák toolearn alapján hogyan hello tooachieve Jupyter notebookok használata a HDInsight Spark-fürtjei különböző helyzetekben.</span><span class="sxs-lookup"><span data-stu-id="b2854-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="b2854-222">Hello notebookok tároló?</span><span class="sxs-lookup"><span data-stu-id="b2854-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="b2854-223">Jupyter notebookok menti a hello hello-fürthöz tartozó toohello tárfiók **/HdiNotebooks** mappa.</span><span class="sxs-lookup"><span data-stu-id="b2854-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="b2854-224">Notebookok, szöveges fájlt és mappát hoz létre a Jupyter belül hello tárfiókból érhetők el.</span><span class="sxs-lookup"><span data-stu-id="b2854-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="b2854-225">Például, ha a Jupyter toocreate mappa használata **SajátMappa** egy hordozható **myfolder/mynotebook.ipynb**, érheti el, hogy a notebook `/HdiNotebooks/myfolder/mynotebook.ipynb` hello tárfiókon belül.</span><span class="sxs-lookup"><span data-stu-id="b2854-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="b2854-226">fordított hello akkor is igaz értéke esetén ez azt jelenti, ha közvetlen tooyour tárolási fiókot a töltse fel a notebook `/HdiNotebooks/mynotebook1.ipynb`, valamint Jupyterről származó látható hello notebook.</span><span class="sxs-lookup"><span data-stu-id="b2854-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="b2854-227">Notebookok maradni hello tárfiók hello fürtök törlése után is.</span><span class="sxs-lookup"><span data-stu-id="b2854-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="b2854-228">hello notebookok mentett toohello tárfiók módja kompatibilis a HDFS.</span><span class="sxs-lookup"><span data-stu-id="b2854-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="b2854-229">Így, ha az SSH-ból is használhat hello fürt fájl parancsok ahogy az alábbi részlet hello:</span><span class="sxs-lookup"><span data-stu-id="b2854-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="b2854-230">Abban az esetben hello fürt hello tárfiók elérése problémák vannak, hello notebookok is tárolja hello headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="b2854-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="b2854-231">Támogatott böngésző</span><span class="sxs-lookup"><span data-stu-id="b2854-231">Supported browser</span></span>

<span data-ttu-id="b2854-232">A Spark HDInsight-fürtökön Jupyter notebookok csak Google Chrome támogatottak.</span><span class="sxs-lookup"><span data-stu-id="b2854-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="b2854-233">Visszajelzés</span><span class="sxs-lookup"><span data-stu-id="b2854-233">Feedback</span></span>
<span data-ttu-id="b2854-234">hello új kernelek szakasz fejlődnek, és adott idő alatt számos lesz.</span><span class="sxs-lookup"><span data-stu-id="b2854-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="b2854-235">Ez is jelentheti, hogy API-k módosulhatnak, mivel ezek kernelek számos.</span><span class="sxs-lookup"><span data-stu-id="b2854-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="b2854-236">Köszönjük volna olyan visszajelzést, hogy rendelkezik, ezek új kernelek használata során.</span><span class="sxs-lookup"><span data-stu-id="b2854-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="b2854-237">Ez akkor hasznos, hello kiadásban ezek kernelek kialakításában.</span><span class="sxs-lookup"><span data-stu-id="b2854-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="b2854-238">A megjegyzések/visszajelzések alapján hello hagyhatja **megjegyzések** szakasz ebben a cikkben hello alján.</span><span class="sxs-lookup"><span data-stu-id="b2854-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="b2854-239"><a name="seealso"></a>Lásd még:</span><span class="sxs-lookup"><span data-stu-id="b2854-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="b2854-240">Overview: Apache Spark on Azure HDInsight (Áttekintés: Apache Spark on Azure HDInsight)</span><span class="sxs-lookup"><span data-stu-id="b2854-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="b2854-241">Forgatókönyvek</span><span class="sxs-lookup"><span data-stu-id="b2854-241">Scenarios</span></span>
* [<span data-ttu-id="b2854-242">Spark és BI: Interaktív adatelemzés végrehajtása a Spark on HDInsight használatával, BI-eszközökkel</span><span class="sxs-lookup"><span data-stu-id="b2854-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="b2854-243">Spark és Machine Learning: A Spark on HDInsight használata az épület-hőmérséklet elemzésére HVAC-adatok alapján</span><span class="sxs-lookup"><span data-stu-id="b2854-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="b2854-244">Spark és Machine Learning: használja a Spark on HDInsight toopredict élelmiszervizsgálati eredmények</span><span class="sxs-lookup"><span data-stu-id="b2854-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="b2854-245">Spark Streaming: A Spark on HDInsight használata valós idejű streamelési alkalmazások összeállítására</span><span class="sxs-lookup"><span data-stu-id="b2854-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="b2854-246">A webhelynapló elemzése a Spark on HDInsight használatával</span><span class="sxs-lookup"><span data-stu-id="b2854-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="b2854-247">Alkalmazások létrehozása és futtatása</span><span class="sxs-lookup"><span data-stu-id="b2854-247">Create and run applications</span></span>
* [<span data-ttu-id="b2854-248">Önálló alkalmazás létrehozása a Scala használatával</span><span class="sxs-lookup"><span data-stu-id="b2854-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="b2854-249">Feladatok távoli futtatása Spark-fürtön a Livy használatával</span><span class="sxs-lookup"><span data-stu-id="b2854-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="b2854-250">Eszközök és bővítmények</span><span class="sxs-lookup"><span data-stu-id="b2854-250">Tools and extensions</span></span>
* [<span data-ttu-id="b2854-251">Toocreate IntelliJ IDEA HDInsight-eszközei beépülő használja, és küldje el a Spark Scala-alkalmazások</span><span class="sxs-lookup"><span data-stu-id="b2854-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="b2854-252">IntelliJ IDEA toodebug Spark-alkalmazások HDInsight-eszközei beépülő távolról használni</span><span class="sxs-lookup"><span data-stu-id="b2854-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="b2854-253">Zeppelin notebookok használata Spark-fürttel HDInsighton</span><span class="sxs-lookup"><span data-stu-id="b2854-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="b2854-254">Külső csomagok használata Jupyter notebookokkal</span><span class="sxs-lookup"><span data-stu-id="b2854-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="b2854-255">Jupyter telepítse a számítógépre, és csatlakozzon a HDInsight Spark-fürt tooan</span><span class="sxs-lookup"><span data-stu-id="b2854-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="b2854-256">Erőforrások kezelése</span><span class="sxs-lookup"><span data-stu-id="b2854-256">Manage resources</span></span>
* [<span data-ttu-id="b2854-257">Az Azure HDInsight hello Apache Spark-fürt erőforrásainak kezelése</span><span class="sxs-lookup"><span data-stu-id="b2854-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="b2854-258">Apache Spark-fürtön futó feladatok nyomon követése és hibakeresése a HDInsightban</span><span class="sxs-lookup"><span data-stu-id="b2854-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
