---
title: "Az Azure HDInsight az Apache Spark-fürt erőforrásainak kezelése |} Microsoft Docs"
description: "Megtudhatja, hogyan használja a jobb teljesítmény érdekében az Azure HDInsight Spark-fürtjei erőforrásainak kezelése."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: 952fa15162a40bccb3f8c7a88508556757ca6675
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 08/03/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="382f5-103">Az Azure HDInsight az Apache Spark-fürt erőforrásainak kezelése</span><span class="sxs-lookup"><span data-stu-id="382f5-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="382f5-104">Ebben a cikkben megtudhatja, hogyan Ambari felhasználói felületén YARN felhasználói felületen, például csatolók eléréséhez, és a Spark-előzmények kiszolgáló a Spark-fürthöz társított.</span><span class="sxs-lookup"><span data-stu-id="382f5-104">In this article you will learn how to access the interfaces like Ambari UI, YARN UI, and the Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="382f5-105">Is megtudhatja, hogyan az optimális teljesítmény érdekében a fürt konfigurálásának hangolását.</span><span class="sxs-lookup"><span data-stu-id="382f5-105">You will also learn about how to tune the cluster configuration for optimal performance.</span></span>

<span data-ttu-id="382f5-106">**Előfeltételek:**</span><span class="sxs-lookup"><span data-stu-id="382f5-106">**Prerequisites:**</span></span>

<span data-ttu-id="382f5-107">Az alábbiakkal kell rendelkeznie:</span><span class="sxs-lookup"><span data-stu-id="382f5-107">You must have the following:</span></span>

* <span data-ttu-id="382f5-108">Azure-előfizetés.</span><span class="sxs-lookup"><span data-stu-id="382f5-108">An Azure subscription.</span></span> <span data-ttu-id="382f5-109">Lásd: [Ingyenes Azure-fiók létrehozása](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="382f5-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="382f5-110">A HDInsight az Apache Spark-fürt.</span><span class="sxs-lookup"><span data-stu-id="382f5-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="382f5-111">Útmutatásért lásd: [létrehozása az Apache Spark on Azure hdinsight clusters](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="382f5-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-the-ambari-web-ui"></a><span data-ttu-id="382f5-112">Hogyan indítsa el az Ambari webes felhasználói felületén?</span><span class="sxs-lookup"><span data-stu-id="382f5-112">How do I launch the Ambari Web UI?</span></span>
1. <span data-ttu-id="382f5-113">Az [Azure portál](https://portal.azure.com/) kezdőpultján kattintson a Spark-fürthöz tartozó csempére (ha rögzítette azt a kezdőpulton).</span><span class="sxs-lookup"><span data-stu-id="382f5-113">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span> <span data-ttu-id="382f5-114">A fürtöt a következő helyről is megkeresheti: **Browse All (Összes tallózása)** > **HDInsight Clusters** (HDInsight-fürtök).</span><span class="sxs-lookup"><span data-stu-id="382f5-114">You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="382f5-115">A Spark-fürt panelén kattintson **irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="382f5-115">From the Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="382f5-116">Amikor a rendszer kéri, adja meg a rendszergazdai hitelesítő adatokat a Spark-fürtön.</span><span class="sxs-lookup"><span data-stu-id="382f5-116">When prompted, enter the admin credentials for the Spark cluster.</span></span>

    <span data-ttu-id="382f5-117">![Indítsa el az Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "erőforrás-kezelő indítása")</span><span class="sxs-lookup"><span data-stu-id="382f5-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="382f5-118">Az Ambari webes felhasználói felületén ez kell elindítani, alább látható módon.</span><span class="sxs-lookup"><span data-stu-id="382f5-118">This should launch the Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="382f5-119">![Ambari webes felhasználói felület](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari webes felhasználói felület")</span><span class="sxs-lookup"><span data-stu-id="382f5-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-the-spark-history-server"></a><span data-ttu-id="382f5-120">Hogyan indítsa el a Spark-előzmények kiszolgáló?</span><span class="sxs-lookup"><span data-stu-id="382f5-120">How do I launch the Spark History Server?</span></span>
1. <span data-ttu-id="382f5-121">Az [Azure portál](https://portal.azure.com/) kezdőpultján kattintson a Spark-fürthöz tartozó csempére (ha rögzítette azt a kezdőpulton).</span><span class="sxs-lookup"><span data-stu-id="382f5-121">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span>
2. <span data-ttu-id="382f5-122">A fürt paneljén alatt **Gyorshivatkozások**, kattintson a **fürt irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="382f5-122">From the cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="382f5-123">Az a **fürt irányítópult** panelen kattintson a **Spark előzmények Server**.</span><span class="sxs-lookup"><span data-stu-id="382f5-123">In the **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="382f5-124">![Spark előzmények Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark előzmények kiszolgáló")</span><span class="sxs-lookup"><span data-stu-id="382f5-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="382f5-125">Amikor a rendszer kéri, adja meg a rendszergazdai hitelesítő adatokat a Spark-fürtön.</span><span class="sxs-lookup"><span data-stu-id="382f5-125">When prompted, enter the admin credentials for the Spark cluster.</span></span>

## <a name="how-do-i-launch-the-yarn-ui"></a><span data-ttu-id="382f5-126">Hogyan indítsa el a Yarn felhasználói felületen?</span><span class="sxs-lookup"><span data-stu-id="382f5-126">How do I launch the Yarn UI?</span></span>
<span data-ttu-id="382f5-127">A Spark-fürtön a jelenleg futó alkalmazások figyeléséhez használhatja a YARN felhasználói felületen.</span><span class="sxs-lookup"><span data-stu-id="382f5-127">You can use the YARN UI to monitor applications that are currently running on the Spark cluster.</span></span>

1. <span data-ttu-id="382f5-128">A fürt paneljén kattintson **fürt irányítópult**, és kattintson a **YARN**.</span><span class="sxs-lookup"><span data-stu-id="382f5-128">From the cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Indítsa el a YARN felhasználói felületen](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="382f5-130">Másik lehetőségként is indítja el a YARN felhasználói felületen a az Ambari felhasználói Felületéről.</span><span class="sxs-lookup"><span data-stu-id="382f5-130">Alternatively, you can also launch the YARN UI from the Ambari UI.</span></span> <span data-ttu-id="382f5-131">Indítsa el az Ambari felhasználói felületén, a fürt paneljén kattintson a **fürt irányítópult**, és kattintson a **HDInsight fürt irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="382f5-131">To launch the Ambari UI, from the cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="382f5-132">Az Ambari felhasználói felületén kattintson **YARN**, kattintson a **Gyorshivatkozások**, kattintson az aktív erőforrás-kezelő, majd **erőforrás-kezelő felhasználói felületén**.</span><span class="sxs-lookup"><span data-stu-id="382f5-132">From the Ambari UI, click **YARN**, click **Quick Links**, click the active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-the-optimum-cluster-configuration-to-run-spark-applications"></a><span data-ttu-id="382f5-133">Mi az optimális fürtkonfiguráció Spark-alkalmazások futtatásához?</span><span class="sxs-lookup"><span data-stu-id="382f5-133">What is the optimum cluster configuration to run Spark applications?</span></span>
<span data-ttu-id="382f5-134">A három legfontosabb paraméterek alkalmazás követelményeitől függően a Spark-konfigurációhoz használható `spark.executor.instances`, `spark.executor.cores`, és `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="382f5-134">The three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="382f5-135">Egy művelettípus végrehajtója az a folyamat egy Spark-alkalmazáshoz elindítva.</span><span class="sxs-lookup"><span data-stu-id="382f5-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="382f5-136">A munkavégző csomópont fut, és az alkalmazás feladatokat hajthat végre felelős.</span><span class="sxs-lookup"><span data-stu-id="382f5-136">It runs on the worker node and is responsible to carry out the tasks for the application.</span></span> <span data-ttu-id="382f5-137">Az alapértelmezett számú végrehajtója és a végrehajtó használatos egyes fürtök a feldolgozó csomópontok és a munkavégző csomópont méretének száma alapján van kiszámítva.</span><span class="sxs-lookup"><span data-stu-id="382f5-137">The default number of executors and the executor sizes for each cluster is calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="382f5-138">Ezek tárolják `spark-defaults.conf` központi fürtcsomópontokon.</span><span class="sxs-lookup"><span data-stu-id="382f5-138">These are stored in `spark-defaults.conf` on the cluster head nodes.</span></span>

<span data-ttu-id="382f5-139">A három konfigurációs paraméterek beállítható, hogy a fürt szintjén (az a fürtön futó összes alkalmazást), vagy minden egyes alkalmazáshoz adható meg.</span><span class="sxs-lookup"><span data-stu-id="382f5-139">The three configuration parameters can be configured at the cluster level (for all applications that run on the cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-the-parameters-using-ambari-ui"></a><span data-ttu-id="382f5-140">Az Ambari felületen paraméterek módosítása</span><span class="sxs-lookup"><span data-stu-id="382f5-140">Change the parameters using Ambari UI</span></span>
1. <span data-ttu-id="382f5-141">Az Ambari felhasználói felületén kattintson a **Spark**, kattintson a **Configs**, majd bontsa ki a **egyéni spark-alapértelmezett**.</span><span class="sxs-lookup"><span data-stu-id="382f5-141">From the Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![A megadott paraméterek Ambari használatával](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="382f5-143">Az alapértelmezett értékek megfelelőek 4 Spark-alkalmazások egyidejű futtatását a fürt hozzá.</span><span class="sxs-lookup"><span data-stu-id="382f5-143">The default values are good to have 4 Spark applications run concurrently on the cluster.</span></span> <span data-ttu-id="382f5-144">Is módosítások ezeket az értékeket a felhasználói felület, a lent látható módon.</span><span class="sxs-lookup"><span data-stu-id="382f5-144">You can changes these values from the user interface, as shown below.</span></span>

    ![A megadott paraméterek Ambari használatával](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="382f5-146">Kattintson a **mentése** menteni a konfigurációs módosításait.</span><span class="sxs-lookup"><span data-stu-id="382f5-146">Click **Save** to save the configuration changes.</span></span> <span data-ttu-id="382f5-147">A lap tetején kérni fogja az érintett szolgáltatások újraindítására.</span><span class="sxs-lookup"><span data-stu-id="382f5-147">At the top of the page, you will be prompted to restart all the affected services.</span></span> <span data-ttu-id="382f5-148">Kattintson a **indítsa újra a**.</span><span class="sxs-lookup"><span data-stu-id="382f5-148">Click **Restart**.</span></span>

    ![Szolgáltatások újraindítása](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-the-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="382f5-150">Jupyter notebook alkalmazás paramétereinek módosítása</span><span class="sxs-lookup"><span data-stu-id="382f5-150">Change the parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="382f5-151">Az alkalmazások a Jupyter notebook, használhatja a `%%configure` magic a konfigurációs módosításokat.</span><span class="sxs-lookup"><span data-stu-id="382f5-151">For applications running in the Jupyter notebook, you can use the `%%configure` magic to make the configuration changes.</span></span> <span data-ttu-id="382f5-152">Ideális esetben meg kell nyitnia a változások az alkalmazást, mielőtt újra lefuttatja az első kódcella elején.</span><span class="sxs-lookup"><span data-stu-id="382f5-152">Ideally, you must make such changes at the beginning of the application, before you run your first code cell.</span></span> <span data-ttu-id="382f5-153">Ez biztosítja, hogy a konfiguráció alkalmazása a Livy munkamenethez, ha végrehajtásakor létrejön.</span><span class="sxs-lookup"><span data-stu-id="382f5-153">This ensures that the configuration is applied to the Livy session, when it gets created.</span></span> <span data-ttu-id="382f5-154">Ha módosítani szeretné a konfigurációt az alkalmazásban egy későbbi időpontban szeretné, használnia kell a `-f` paraméter.</span><span class="sxs-lookup"><span data-stu-id="382f5-154">If you want to change the configuration at a later stage in the application, you must use the `-f` parameter.</span></span> <span data-ttu-id="382f5-155">Azonban, ennek során az alkalmazás az összes folyamatban lévő el fog veszni.</span><span class="sxs-lookup"><span data-stu-id="382f5-155">However, by doing so all progress in the application will be lost.</span></span>

<span data-ttu-id="382f5-156">Az alábbi kódrészletben láthatja, Jupyter alkalmazás konfigurációjának módosítása.</span><span class="sxs-lookup"><span data-stu-id="382f5-156">The snippet below shows how to change the configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="382f5-157">Konfigurációs paraméterek a JSON karakterláncként kell átadnia, és későbbinek kell lennie a következő sorban a Bűvös példa oszlopában látható módon.</span><span class="sxs-lookup"><span data-stu-id="382f5-157">Configuration parameters must be passed in as a JSON string and must be on the next line after the magic, as shown in the example column.</span></span>

### <a name="change-the-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="382f5-158">A paraméterekkel rendelkező kérelem használata spark-nyújt módosítása</span><span class="sxs-lookup"><span data-stu-id="382f5-158">Change the parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="382f5-159">A következő parancs a példa bemutatja, hogyan módosíthatja a konfigurációs paraméterek használatával küldött kötegelt alkalmazások `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="382f5-159">Following command is an example of how to change the configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <the application class to execute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-the-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="382f5-160">A cURL használatával kérelem paramétereinek módosítása</span><span class="sxs-lookup"><span data-stu-id="382f5-160">Change the parameters for an application submitted using cURL</span></span>
<span data-ttu-id="382f5-161">A következő parancs a példa bemutatja, hogyan módosíthatja a konfigurációs paraméterek használata cURL használatával küldött kötegelt alkalmazáshoz.</span><span class="sxs-lookup"><span data-stu-id="382f5-161">Following command is an example of how to change the configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<the application class to execute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="382f5-162">Hogyan változtathatom meg ezeket a paramétereket a Spark Thrift-kiszolgáló?</span><span class="sxs-lookup"><span data-stu-id="382f5-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="382f5-163">A Spark Thrift-kiszolgáló JDBC-/ ODBC hozzáférést biztosít a Spark-fürt és Spark SQL-lekérdezések használatával.</span><span class="sxs-lookup"><span data-stu-id="382f5-163">Spark Thrift Server provides JDBC/ODBC access to a Spark cluster and is used to service Spark SQL queries.</span></span> <span data-ttu-id="382f5-164">Eszközök, például a Power BI-ban Tableau stb.</span><span class="sxs-lookup"><span data-stu-id="382f5-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="382f5-165">ODBC protokoll segítségével kommunikálnak a Spark Thrift-kiszolgáló Spark SQL-lekérdezések végrehajtása a Spark-alkalmazásként.</span><span class="sxs-lookup"><span data-stu-id="382f5-165">use ODBC protocol to communicate with Spark Thrift Server to execute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="382f5-166">Spark-fürt létrehozásakor a Spark Thrift-kiszolgáló két példánya indulnak el, egy központi a csomópontokra.</span><span class="sxs-lookup"><span data-stu-id="382f5-166">When a Spark cluster is created, two instances of the Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="382f5-167">Minden egyes Spark Thrift-kiszolgáló a Spark-alkalmazásként a YARN felhasználói felületen látható.</span><span class="sxs-lookup"><span data-stu-id="382f5-167">Each Spark Thrift Server is visible as a Spark application in the YARN UI.</span></span>

<span data-ttu-id="382f5-168">A Spark Thrift-kiszolgáló használ a Spark dinamikus végrehajtó foglalási, így a `spark.executor.instances` nem használatos.</span><span class="sxs-lookup"><span data-stu-id="382f5-168">Spark Thrift Server uses Spark dynamic executor allocation and hence the `spark.executor.instances` is not used.</span></span> <span data-ttu-id="382f5-169">Ehelyett használja a Spark Thrift-kiszolgáló `spark.dynamicAllocation.minExecutors` és `spark.dynamicAllocation.maxExecutors` a végrehajtó számának megadásához.</span><span class="sxs-lookup"><span data-stu-id="382f5-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` to specify the executor count.</span></span> <span data-ttu-id="382f5-170">A konfigurációs paraméterek `spark.executor.cores` és `spark.executor.memory` végrehajtó méretének szolgál.</span><span class="sxs-lookup"><span data-stu-id="382f5-170">The configuration parameters `spark.executor.cores` and `spark.executor.memory` is used to modify the executor size.</span></span> <span data-ttu-id="382f5-171">Ezek a paraméterek módosíthatja a lent látható módon.</span><span class="sxs-lookup"><span data-stu-id="382f5-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="382f5-172">Bontsa ki a **spark-thrift-sparkconf speciális** a paraméterek frissítéséhez kategória `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, és `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="382f5-172">Expand the **Advanced spark-thrift-sparkconf** category to update the parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![A Spark thrift-kiszolgáló konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="382f5-174">Bontsa ki a **spark-thrift-sparkconf egyéni** frissíteni a paraméter kategória `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="382f5-174">Expand the **Custom spark-thrift-sparkconf** category to update the parameter `spark.executor.cores`.</span></span>

    ![A Spark thrift-kiszolgáló konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-the-driver-memory-of-the-spark-thrift-server"></a><span data-ttu-id="382f5-176">Hogyan változtathatom meg a illesztőprogram memóriát a Spark Thrift-kiszolgáló?</span><span class="sxs-lookup"><span data-stu-id="382f5-176">How do I change the driver memory of the Spark Thrift Server?</span></span>
<span data-ttu-id="382f5-177">A Spark Thrift-kiszolgáló illesztőprogram memória van konfigurálva 25 %-át az átjárócsomópont RAM memória méretét, feltéve, az átjárócsomópont összesített RAM mérete 14GB-nál nagyobb.</span><span class="sxs-lookup"><span data-stu-id="382f5-177">Spark Thrift Server driver memory is configured to 25% of the head node RAM size, provided the total RAM size of the head node is greater than 14GB.</span></span> <span data-ttu-id="382f5-178">Az Ambari felhasználói felület segítségével módosíthatja az illesztőprogram memóriakövetelménye alább látható módon.</span><span class="sxs-lookup"><span data-stu-id="382f5-178">You can use the Ambari UI to change the driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="382f5-179">Az Ambari felhasználói felületén kattintson a **Spark**, kattintson a **Configs**, bontsa ki a **spark-env speciális**, és adja meg a következő **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="382f5-179">From the Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide the value for **spark_thrift_cmd_opts**.</span></span>

    ![A Spark thrift-kiszolgáló RAM konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-the-resources-back"></a><span data-ttu-id="382f5-181">BI nem Spark-fürt használata.</span><span class="sxs-lookup"><span data-stu-id="382f5-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="382f5-182">Hogyan tudom vissza igénybe az erőforrásokat?</span><span class="sxs-lookup"><span data-stu-id="382f5-182">How do I take the resources back?</span></span>
<span data-ttu-id="382f5-183">Spark dinamikus foglalási használjuk, mert az csak thrift-kiszolgáló által felhasznált erőforrások a két alkalmazás főkiszolgálók erőforrásokat.</span><span class="sxs-lookup"><span data-stu-id="382f5-183">Since we use Spark dynamic allocation, the only resources that are consumed by thrift server are the resources for the two application masters.</span></span> <span data-ttu-id="382f5-184">Ezeket az erőforrásokat visszaigénylésének le kell állítania a Thrift-kiszolgáló szolgáltatás fut a fürtön.</span><span class="sxs-lookup"><span data-stu-id="382f5-184">To reclaim these resources you must stop the Thrift Server services running on the cluster.</span></span>

1. <span data-ttu-id="382f5-185">Az Ambari felhasználói felületén, a bal oldali ablaktáblán kattintson **Spark**.</span><span class="sxs-lookup"><span data-stu-id="382f5-185">From the Ambari UI, from the left pane, click **Spark**.</span></span>
2. <span data-ttu-id="382f5-186">A következő oldalon kattintson **Spark Thrift kiszolgálók**.</span><span class="sxs-lookup"><span data-stu-id="382f5-186">In the next page, click **Spark Thrift Servers**.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="382f5-188">Meg kell jelennie a két headnodes, amelyen fut a Spark Thrift-kiszolgáló.</span><span class="sxs-lookup"><span data-stu-id="382f5-188">You should see the two headnodes on which the Spark Thrift Server is running.</span></span> <span data-ttu-id="382f5-189">Kattintson a headnodes.</span><span class="sxs-lookup"><span data-stu-id="382f5-189">Click one of the headnodes.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="382f5-191">A következő lap felsorolja az adott headnode futó összes szolgáltatás.</span><span class="sxs-lookup"><span data-stu-id="382f5-191">The next page lists all the services running on that headnode.</span></span> <span data-ttu-id="382f5-192">A listában kattintson a legördítő gomb melletti Spark Thrift-kiszolgáló, majd **leállítása**.</span><span class="sxs-lookup"><span data-stu-id="382f5-192">From the list click the drop-down button next to Spark Thrift Server, and then click **Stop**.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="382f5-194">Ismételje meg ezeket a lépéseket a más headnode, valamint a.</span><span class="sxs-lookup"><span data-stu-id="382f5-194">Repeat these steps on the other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-the-service"></a><span data-ttu-id="382f5-195">A Jupyter notebookok nem elvárt módon futnak.</span><span class="sxs-lookup"><span data-stu-id="382f5-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="382f5-196">Hogyan újraindíthatja a szolgáltatást?</span><span class="sxs-lookup"><span data-stu-id="382f5-196">How can I restart the service?</span></span>
<span data-ttu-id="382f5-197">Indítsa el az Ambari webes felhasználói felületén, ahogy fent látható.</span><span class="sxs-lookup"><span data-stu-id="382f5-197">Launch the Ambari Web UI as shown above.</span></span> <span data-ttu-id="382f5-198">Kattintson a bal oldali navigációs ablak **Jupyter**, kattintson a **szolgáltatás műveletek**, és kattintson a **indítsa újra az összes**.</span><span class="sxs-lookup"><span data-stu-id="382f5-198">From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="382f5-199">A Jupyter szolgáltatás elindítja az összes headnodes.</span><span class="sxs-lookup"><span data-stu-id="382f5-199">This will start the Jupyter service on all the headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="382f5-200">Hogyan állapítható meg, hogy ha erőforrások fut-e?</span><span class="sxs-lookup"><span data-stu-id="382f5-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="382f5-201">A Yarn felhasználói felületének indítása, a fentiek szerint.</span><span class="sxs-lookup"><span data-stu-id="382f5-201">Launch the Yarn UI as shown above.</span></span> <span data-ttu-id="382f5-202">Fürt metrikáinak tábla a képernyő fölött, ellenőrizze az értékeket **használt memória** és **memória teljes** oszlopok.</span><span class="sxs-lookup"><span data-stu-id="382f5-202">In Cluster Metrics table on top of the screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="382f5-203">Ha a 2 érték rendkívül szoros, a nem feltétlenül elegendő erőforrás a következő alkalmazás indításához.</span><span class="sxs-lookup"><span data-stu-id="382f5-203">If the 2 values are very close, there might not be enough resources to start the next application.</span></span> <span data-ttu-id="382f5-204">Ugyanez érvényes a **VCores használt** és **VCores összesen** oszlopok.</span><span class="sxs-lookup"><span data-stu-id="382f5-204">The same applies to the **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="382f5-205">Is, a fő nézetben, ha egy alkalmazás tartózkodott a **elfogadott** állapotát, és nem változik a **futtató** sem **sikertelen** állapotba kerül, ennek oka is lehet utal, hogy nem sikerül elindítani erőforrásokkal.</span><span class="sxs-lookup"><span data-stu-id="382f5-205">Also, in the main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources to start.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-to-free-up-resource"></a><span data-ttu-id="382f5-206">Hogyan kill a szabadítson fel erőforrás egy futó alkalmazást?</span><span class="sxs-lookup"><span data-stu-id="382f5-206">How do I kill a running application to free up resource?</span></span>
1. <span data-ttu-id="382f5-207">A Yarn felhasználói felületen, a bal oldali panelen kattintson a **futtató**.</span><span class="sxs-lookup"><span data-stu-id="382f5-207">In the Yarn UI, from the left panel, click **Running**.</span></span> <span data-ttu-id="382f5-208">Határozza meg az alkalmazás szakítva, és kattintson a futó alkalmazások listájában, a **azonosító**.</span><span class="sxs-lookup"><span data-stu-id="382f5-208">From the list of running applications, determine the application to be killed and click on the **ID**.</span></span>

    <span data-ttu-id="382f5-209">![Az App1 Kill](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "App1 leállítása")</span><span class="sxs-lookup"><span data-stu-id="382f5-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="382f5-210">Kattintson a **Kill alkalmazás** jobb felső sarokban, majd kattintson **OK**.</span><span class="sxs-lookup"><span data-stu-id="382f5-210">Click **Kill Application** on the top right corner, then click **OK**.</span></span>

    <span data-ttu-id="382f5-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "App2 leállítása")</span><span class="sxs-lookup"><span data-stu-id="382f5-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="382f5-212">Lásd még:</span><span class="sxs-lookup"><span data-stu-id="382f5-212">See also</span></span>
* [<span data-ttu-id="382f5-213">Apache Spark-fürtön futó feladatok nyomon követése és hibakeresése a HDInsightban</span><span class="sxs-lookup"><span data-stu-id="382f5-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="382f5-214">Az adatok elemző</span><span class="sxs-lookup"><span data-stu-id="382f5-214">For data analysts</span></span>

* [<span data-ttu-id="382f5-215">Spark és Machine Learning: A Spark on HDInsight használata az épület-hőmérséklet elemzésére HVAC-adatok alapján</span><span class="sxs-lookup"><span data-stu-id="382f5-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="382f5-216">Spark és Machine Learning: A Spark on HDInsight használata az élelmiszervizsgálati eredmények előrejelzésére</span><span class="sxs-lookup"><span data-stu-id="382f5-216">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="382f5-217">A webhelynapló elemzése a Spark on HDInsight használatával</span><span class="sxs-lookup"><span data-stu-id="382f5-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="382f5-218">Az Application Insights telemetriai adatainak elemzése a Spark on HDInsight használatával</span><span class="sxs-lookup"><span data-stu-id="382f5-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="382f5-219">Az Azure HDInsight Spark Caffe elosztott mély tanulási használata</span><span class="sxs-lookup"><span data-stu-id="382f5-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="382f5-220">A Spark-fejlesztőknek</span><span class="sxs-lookup"><span data-stu-id="382f5-220">For Spark developers</span></span>

* [<span data-ttu-id="382f5-221">Önálló alkalmazás létrehozása a Scala használatával</span><span class="sxs-lookup"><span data-stu-id="382f5-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="382f5-222">Feladatok távoli futtatása Spark-fürtön a Livy használatával</span><span class="sxs-lookup"><span data-stu-id="382f5-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="382f5-223">Az IntelliJ IDEA HDInsight-eszközei beépülő moduljának használata Spark Scala-alkalmazások létrehozásához és elküldéséhez</span><span class="sxs-lookup"><span data-stu-id="382f5-223">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="382f5-224">Spark Streaming: A Spark on HDInsight használata valós idejű streamelési alkalmazások összeállítására</span><span class="sxs-lookup"><span data-stu-id="382f5-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="382f5-225">Az IntelliJ IDEA HDInsight-eszközei beépülő moduljának használata Spark-alkalmazások távoli hibaelhárításához</span><span class="sxs-lookup"><span data-stu-id="382f5-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="382f5-226">Zeppelin notebookok használata Spark-fürttel HDInsighton</span><span class="sxs-lookup"><span data-stu-id="382f5-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="382f5-227">Jupyter notebookokhoz elérhető kernelek a HDInsight Spark-fürtjében</span><span class="sxs-lookup"><span data-stu-id="382f5-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="382f5-228">Külső csomagok használata Jupyter notebookokkal</span><span class="sxs-lookup"><span data-stu-id="382f5-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="382f5-229">A Jupyter telepítése a számítógépre, majd csatlakozás egy HDInsight Spark-fürthöz</span><span class="sxs-lookup"><span data-stu-id="382f5-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
