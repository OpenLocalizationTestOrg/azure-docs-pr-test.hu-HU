---
title: "aaaManage erőforrásokat az Apache Spark on Azure HDInsight fürt |} Microsoft Docs"
description: "Ismerje meg, hogyan toouse a jobb teljesítmény érdekében az Azure HDInsight Spark-fürtjei erőforrásainak kezelése."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="cb9be-103">Az Azure HDInsight az Apache Spark-fürt erőforrásainak kezelése</span><span class="sxs-lookup"><span data-stu-id="cb9be-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="cb9be-104">Ebben a cikkben megtudhatja, hogyan tooaccess hello felületek, például a Ambari felhasználói felület, a YARN felhasználói felületen és a Spark előzmények Server hello a Spark-fürthöz kapcsolódó.</span><span class="sxs-lookup"><span data-stu-id="cb9be-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="cb9be-105">Azt is megtudhatja, hogyan tootune hello fürtkonfiguráció az optimális teljesítmény kapcsolatos.</span><span class="sxs-lookup"><span data-stu-id="cb9be-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="cb9be-106">**Előfeltételek:**</span><span class="sxs-lookup"><span data-stu-id="cb9be-106">**Prerequisites:**</span></span>

<span data-ttu-id="cb9be-107">Hello következő kell rendelkeznie:</span><span class="sxs-lookup"><span data-stu-id="cb9be-107">You must have hello following:</span></span>

* <span data-ttu-id="cb9be-108">Azure-előfizetés.</span><span class="sxs-lookup"><span data-stu-id="cb9be-108">An Azure subscription.</span></span> <span data-ttu-id="cb9be-109">Lásd: [Ingyenes Azure-fiók létrehozása](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="cb9be-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="cb9be-110">A HDInsight az Apache Spark-fürt.</span><span class="sxs-lookup"><span data-stu-id="cb9be-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="cb9be-111">Útmutatásért lásd: [létrehozása az Apache Spark on Azure hdinsight clusters](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="cb9be-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="cb9be-112">Hogyan indítsa el az Ambari webes felhasználói felületén hello?</span><span class="sxs-lookup"><span data-stu-id="cb9be-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="cb9be-113">A hello [Azure Portal](https://portal.azure.com/), hello kezdőpulton, kattintson a Spark-fürt hello csempére (ha toohello kezdőpulton rögzítette azt).</span><span class="sxs-lookup"><span data-stu-id="cb9be-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="cb9be-114">Tooyour fürt alapján is megtalálhatja **összes tallózása** > **a HDInsight-fürtök**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="cb9be-115">Hello Spark-fürt panelén kattintson **irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="cb9be-116">Amikor a rendszer kéri, adja meg hello Spark-fürt hello rendszergazdai hitelesítő adataival.</span><span class="sxs-lookup"><span data-stu-id="cb9be-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="cb9be-117">![Indítsa el az Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "erőforrás-kezelő indítása")</span><span class="sxs-lookup"><span data-stu-id="cb9be-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="cb9be-118">Ez kell hello Ambari webes felhasználói felületén, nyissa meg alább látható módon.</span><span class="sxs-lookup"><span data-stu-id="cb9be-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="cb9be-119">![Ambari webes felhasználói felület](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari webes felhasználói felület")</span><span class="sxs-lookup"><span data-stu-id="cb9be-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="cb9be-120">Hogyan indítsa el a Spark előzmények Server hello?</span><span class="sxs-lookup"><span data-stu-id="cb9be-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="cb9be-121">A hello [Azure Portal](https://portal.azure.com/), hello kezdőpulton, kattintson a Spark-fürt hello csempére (ha toohello kezdőpulton rögzítette azt).</span><span class="sxs-lookup"><span data-stu-id="cb9be-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="cb9be-122">Hello a fürt paneljén a **Gyorshivatkozások**, kattintson a **fürt irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="cb9be-123">A hello **fürt irányítópult** panelen kattintson a **Spark előzmények Server**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="cb9be-124">![Spark előzmények Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark előzmények kiszolgáló")</span><span class="sxs-lookup"><span data-stu-id="cb9be-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="cb9be-125">Amikor a rendszer kéri, adja meg hello Spark-fürt hello rendszergazdai hitelesítő adataival.</span><span class="sxs-lookup"><span data-stu-id="cb9be-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="cb9be-126">Hogyan indítsa el a Yarn felhasználói felületen hello?</span><span class="sxs-lookup"><span data-stu-id="cb9be-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="cb9be-127">Hello YARN felhasználói felületen toomonitor alkalmazások hello Spark-fürt a jelenleg futó is használhatja.</span><span class="sxs-lookup"><span data-stu-id="cb9be-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="cb9be-128">Hello-fürt panelén kattintson **fürt irányítópult**, és kattintson a **YARN**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Indítsa el a YARN felhasználói felületen](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="cb9be-130">Másik lehetőségként is elindíthatja a hello YARN felhasználói felületen a hello Ambari felhasználói felület.</span><span class="sxs-lookup"><span data-stu-id="cb9be-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="cb9be-131">toolaunch hello Ambari felhasználói felületén, a hello-fürt panelén kattintson **fürt irányítópult**, és kattintson a **HDInsight fürt irányítópult**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="cb9be-132">A hello Ambari felhasználói felület, kattintson az **YARN**, kattintson a **Gyorshivatkozások**, kattintson hello aktív erőforrás-kezelő, majd **erőforrás-kezelő felhasználói felületén**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="cb9be-133">Mi az a hello optimális fürt konfigurációs toorun Spark-alkalmazások?</span><span class="sxs-lookup"><span data-stu-id="cb9be-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="cb9be-134">hello három fő, amely nem használható alkalmazás követelményeitől függően Spark konfigurációs paraméterei `spark.executor.instances`, `spark.executor.cores`, és `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="cb9be-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="cb9be-135">Egy művelettípus végrehajtója az a folyamat egy Spark-alkalmazáshoz elindítva.</span><span class="sxs-lookup"><span data-stu-id="cb9be-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="cb9be-136">Hello munkavégző csomóponton fut, és hello feladatokat hello alkalmazás felelős toocarry.</span><span class="sxs-lookup"><span data-stu-id="cb9be-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="cb9be-137">hello alapértelmezett száma végrehajtója és az egyes fürtökön hello végrehajtó mérete alapján van kiszámítva munkavégző csomópontokhoz és hello munkavégző csomópont méretének hello száma.</span><span class="sxs-lookup"><span data-stu-id="cb9be-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="cb9be-138">Ezek tárolják `spark-defaults.conf` hello központi fürtcsomóponton.</span><span class="sxs-lookup"><span data-stu-id="cb9be-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="cb9be-139">hello három konfigurációs paraméterek konfigurálható szintjén hello fürt (hello fürtön futó összes alkalmazást), vagy minden egyes alkalmazáshoz adható meg.</span><span class="sxs-lookup"><span data-stu-id="cb9be-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="cb9be-140">Ambari felületen hello paraméterek módosítása</span><span class="sxs-lookup"><span data-stu-id="cb9be-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="cb9be-141">Hello Ambari felhasználói felületén kattintson **Spark**, kattintson a **Configs**, majd bontsa ki a **egyéni spark-alapértelmezett**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![A megadott paraméterek Ambari használatával](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="cb9be-143">hello alapértelmezett értékei jó toohave 4 Spark-alkalmazások hello fürt egyidejű futtatását.</span><span class="sxs-lookup"><span data-stu-id="cb9be-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="cb9be-144">Is módosítások ezeket az értékeket hello felhasználói felület, a lent látható módon.</span><span class="sxs-lookup"><span data-stu-id="cb9be-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![A megadott paraméterek Ambari használatával](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="cb9be-146">Kattintson a **mentése** toosave hello konfigurációs módosításokat.</span><span class="sxs-lookup"><span data-stu-id="cb9be-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="cb9be-147">Hello hello oldal tetején, kérni fogja az összes hello toorestart érintett szolgáltatások.</span><span class="sxs-lookup"><span data-stu-id="cb9be-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="cb9be-148">Kattintson a **indítsa újra a**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-148">Click **Restart**.</span></span>

    ![Szolgáltatások újraindítása](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="cb9be-150">Jupyter notebook alkalmazás hello paramétereinek módosítása</span><span class="sxs-lookup"><span data-stu-id="cb9be-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="cb9be-151">Az alkalmazások hello Jupyter notebook, hello használhatja `%%configure` magic toomake hello konfigurációs módosításokat.</span><span class="sxs-lookup"><span data-stu-id="cb9be-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="cb9be-152">Ideális esetben meg kell nyitnia a változások hello alkalmazást, mielőtt újra lefuttatja az első kódcella hello elején.</span><span class="sxs-lookup"><span data-stu-id="cb9be-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="cb9be-153">Ez biztosítja, hogy a hello konfigurálása alkalmazott toohello Livy munkamenet, amikor lekérdezi a létrehozott.</span><span class="sxs-lookup"><span data-stu-id="cb9be-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="cb9be-154">Ha azt szeretné, hogy toochange hello konfigurációs hello alkalmazásban egy későbbi időpontban, használnia kell a hello `-f` paraméter.</span><span class="sxs-lookup"><span data-stu-id="cb9be-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="cb9be-155">Azonban így minden hello az előrehaladás végrehajtásával alkalmazás elvesznek.</span><span class="sxs-lookup"><span data-stu-id="cb9be-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="cb9be-156">az alábbi hello kódrészletben láthatja, hogyan toochange hello Jupyter egy alkalmazáskészlet konfigurációját.</span><span class="sxs-lookup"><span data-stu-id="cb9be-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="cb9be-157">Konfigurációs paraméterek a JSON karakterláncként kell átadnia, és későbbinek kell lennie hello következő sorban hello magic hello példa oszlopban látható.</span><span class="sxs-lookup"><span data-stu-id="cb9be-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="cb9be-158">Változás hello paramétereinek használatával kérelem spark-elküldése</span><span class="sxs-lookup"><span data-stu-id="cb9be-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="cb9be-159">A következő parancs példája hogyan toochange hello konfigurációs paraméterek használatával küldött kötegelt alkalmazások `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="cb9be-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="cb9be-160">Hello használata cURL használatával kérelem paramétereinek módosítása</span><span class="sxs-lookup"><span data-stu-id="cb9be-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="cb9be-161">A következő parancs példája hogyan toochange hello konfigurációs paraméterek használata cURL használatával küldött kötegelt alkalmazáshoz.</span><span class="sxs-lookup"><span data-stu-id="cb9be-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="cb9be-162">Hogyan változtathatom meg ezeket a paramétereket a Spark Thrift-kiszolgáló?</span><span class="sxs-lookup"><span data-stu-id="cb9be-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="cb9be-163">A Spark Thrift-kiszolgáló JDBC-/ ODBC hozzáférés tooa Spark-fürt és használt tooservice Spark SQL-lekérdezések.</span><span class="sxs-lookup"><span data-stu-id="cb9be-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="cb9be-164">Eszközök, például a Power BI-ban Tableau stb.</span><span class="sxs-lookup"><span data-stu-id="cb9be-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="cb9be-165">ODBC protokoll toocommunicate használata Spark Thrift-kiszolgáló tooexecute Spark SQL-lekérdezések a Spark-alkalmazásként.</span><span class="sxs-lookup"><span data-stu-id="cb9be-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="cb9be-166">Spark-fürt létrehozásakor hello Spark Thrift-kiszolgáló indulnak el, egy minden átjárócsomópont két példánya.</span><span class="sxs-lookup"><span data-stu-id="cb9be-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="cb9be-167">Minden egyes Spark Thrift-kiszolgáló látható hello YARN felhasználói felületen a Spark-alkalmazásként.</span><span class="sxs-lookup"><span data-stu-id="cb9be-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="cb9be-168">A Spark Thrift-kiszolgáló által használt dinamikus végrehajtó foglalási Spark, és ezért hello `spark.executor.instances` nem használatos.</span><span class="sxs-lookup"><span data-stu-id="cb9be-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="cb9be-169">Ehelyett használja a Spark Thrift-kiszolgáló `spark.dynamicAllocation.minExecutors` és `spark.dynamicAllocation.maxExecutors` toospecify hello végrehajtó száma.</span><span class="sxs-lookup"><span data-stu-id="cb9be-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="cb9be-170">konfigurációs paraméterek hello `spark.executor.cores` és `spark.executor.memory` van használt toomodify hello végrehajtó méretét.</span><span class="sxs-lookup"><span data-stu-id="cb9be-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="cb9be-171">Ezek a paraméterek módosíthatja a lent látható módon.</span><span class="sxs-lookup"><span data-stu-id="cb9be-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="cb9be-172">Bontsa ki a hello **spark-thrift-sparkconf speciális** kategória tooupdate hello paraméterek `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, és `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="cb9be-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![A Spark thrift-kiszolgáló konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="cb9be-174">Bontsa ki a hello **spark-thrift-sparkconf egyéni** kategória tooupdate hello paraméter `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="cb9be-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![A Spark thrift-kiszolgáló konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="cb9be-176">Hogyan változtathatom meg a Spark Thrift-kiszolgáló hello hello illesztőprogram memória?</span><span class="sxs-lookup"><span data-stu-id="cb9be-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="cb9be-177">A Spark Thrift-kiszolgáló illesztőprogram memóriát hello teljes RAM hello átjárócsomópont mérete 14GB-nál nagyobb hello átjárócsomópont RAM mérete, a konfigurált too25 % kerül.</span><span class="sxs-lookup"><span data-stu-id="cb9be-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="cb9be-178">Hello Ambari felhasználói felület toochange hello illesztőprogram memóriakövetelménye, használhatja a lent látható módon.</span><span class="sxs-lookup"><span data-stu-id="cb9be-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="cb9be-179">Hello Ambari felhasználói felületén kattintson **Spark**, kattintson **Configs**, bontsa ki **spark-env speciális**, és adja meg a hello érték **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![A Spark thrift-kiszolgáló RAM konfigurálása](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="cb9be-181">BI nem Spark-fürt használata.</span><span class="sxs-lookup"><span data-stu-id="cb9be-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="cb9be-182">Hogyan tudom vissza igénybe hello erőforrásokat?</span><span class="sxs-lookup"><span data-stu-id="cb9be-182">How do I take hello resources back?</span></span>
<span data-ttu-id="cb9be-183">Spark dinamikus foglalási használjuk, mivel hello csak thrift-kiszolgáló által felhasznált erőforrások hello két alkalmazás főkiszolgálók hello erőforrásait.</span><span class="sxs-lookup"><span data-stu-id="cb9be-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="cb9be-184">Ezeket az erőforrásokat le kell állítania hello hello fürt Thrift-kiszolgáló szolgáltatás tooreclaim.</span><span class="sxs-lookup"><span data-stu-id="cb9be-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="cb9be-185">Hello Ambari UI hello bal oldali ablaktáblában kattintson **Spark**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="cb9be-186">A következő lapon hello kattintson **Spark Thrift kiszolgálók**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="cb9be-188">Hello két headnodes mely hello Spark Thrift-kiszolgáló fut. kell megjelennie.</span><span class="sxs-lookup"><span data-stu-id="cb9be-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="cb9be-189">Kattintson az egyik hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="cb9be-189">Click one of hello headnodes.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="cb9be-191">hello következő lap felsorolja az adott headnode futó összes hello szolgáltatást.</span><span class="sxs-lookup"><span data-stu-id="cb9be-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="cb9be-192">Hello listából kattintson hello legördülő gomb következő tooSpark Thrift-kiszolgáló, majd **leállítása**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Indítsa újra a thrift-kiszolgáló](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="cb9be-194">Ismételje meg ezeket a lépéseket a hello más headnode is.</span><span class="sxs-lookup"><span data-stu-id="cb9be-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="cb9be-195">A Jupyter notebookok nem elvárt módon futnak.</span><span class="sxs-lookup"><span data-stu-id="cb9be-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="cb9be-196">Hogyan újraindíthatja hello szolgáltatást?</span><span class="sxs-lookup"><span data-stu-id="cb9be-196">How can I restart hello service?</span></span>
<span data-ttu-id="cb9be-197">Indítsa el a hello Ambari webes felhasználói felületén, ahogy fent látható.</span><span class="sxs-lookup"><span data-stu-id="cb9be-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="cb9be-198">Hello bal oldali navigációs ablaktáblán kattintson **Jupyter**, kattintson a **szolgáltatás műveletek**, és kattintson a **indítsa újra az összes**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="cb9be-199">Hello Jupyter szolgáltatás elindítja az összes hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="cb9be-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="cb9be-200">Hogyan állapítható meg, hogy ha erőforrások fut-e?</span><span class="sxs-lookup"><span data-stu-id="cb9be-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="cb9be-201">Indítsa el a hello Yarn felhasználói felületen, a fentiek szerint.</span><span class="sxs-lookup"><span data-stu-id="cb9be-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="cb9be-202">Fürt metrikáinak tábla fölött üdvözlő képernyőt, ellenőrizze az értékeket **használt memória** és **memória teljes** oszlopok.</span><span class="sxs-lookup"><span data-stu-id="cb9be-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="cb9be-203">Hello 2 értékei rendkívül szoros, ha a nem feltétlenül elegendő erőforrást toostart hello tovább alkalmazás.</span><span class="sxs-lookup"><span data-stu-id="cb9be-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="cb9be-204">hello Ugyanez vonatkozik toohello **VCores használt** és **VCores összesen** oszlopok.</span><span class="sxs-lookup"><span data-stu-id="cb9be-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="cb9be-205">Is, hello fő nézetben, ha egy alkalmazás tartózkodott a **elfogadott** állapotát, és nem változik a **futtató** sem **sikertelen** állapotba kerül, ez arra utal, hogy is lehet hogy nem elég erőforrások toostart kap.</span><span class="sxs-lookup"><span data-stu-id="cb9be-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="cb9be-206">Hogyan kill futó alkalmazás toofree erőforrást?</span><span class="sxs-lookup"><span data-stu-id="cb9be-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="cb9be-207">A Yarn felhasználói felületen, hello hello bal oldali panelen, kattintson **futtató**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="cb9be-208">A futó alkalmazások hello listában határozza meg a hello alkalmazás toobe leállítása, majd kattintson a hello **azonosító**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="cb9be-209">![Az App1 Kill](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "App1 leállítása")</span><span class="sxs-lookup"><span data-stu-id="cb9be-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="cb9be-210">Kattintson a **Kill alkalmazás** hello jobb felső sarokban, majd kattintson **OK**.</span><span class="sxs-lookup"><span data-stu-id="cb9be-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="cb9be-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "App2 leállítása")</span><span class="sxs-lookup"><span data-stu-id="cb9be-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="cb9be-212">Lásd még:</span><span class="sxs-lookup"><span data-stu-id="cb9be-212">See also</span></span>
* [<span data-ttu-id="cb9be-213">Apache Spark-fürtön futó feladatok nyomon követése és hibakeresése a HDInsightban</span><span class="sxs-lookup"><span data-stu-id="cb9be-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="cb9be-214">Az adatok elemző</span><span class="sxs-lookup"><span data-stu-id="cb9be-214">For data analysts</span></span>

* [<span data-ttu-id="cb9be-215">Spark és Machine Learning: A Spark on HDInsight használata az épület-hőmérséklet elemzésére HVAC-adatok alapján</span><span class="sxs-lookup"><span data-stu-id="cb9be-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="cb9be-216">Spark és Machine Learning: használja a Spark on HDInsight toopredict élelmiszervizsgálati eredmények</span><span class="sxs-lookup"><span data-stu-id="cb9be-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="cb9be-217">A webhelynapló elemzése a Spark on HDInsight használatával</span><span class="sxs-lookup"><span data-stu-id="cb9be-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="cb9be-218">Az Application Insights telemetriai adatainak elemzése a Spark on HDInsight használatával</span><span class="sxs-lookup"><span data-stu-id="cb9be-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="cb9be-219">Az Azure HDInsight Spark Caffe elosztott mély tanulási használata</span><span class="sxs-lookup"><span data-stu-id="cb9be-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="cb9be-220">A Spark-fejlesztőknek</span><span class="sxs-lookup"><span data-stu-id="cb9be-220">For Spark developers</span></span>

* [<span data-ttu-id="cb9be-221">Önálló alkalmazás létrehozása a Scala használatával</span><span class="sxs-lookup"><span data-stu-id="cb9be-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="cb9be-222">Feladatok távoli futtatása Spark-fürtön a Livy használatával</span><span class="sxs-lookup"><span data-stu-id="cb9be-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="cb9be-223">Toocreate IntelliJ IDEA HDInsight-eszközei beépülő használja, és küldje el a Spark Scala-alkalmazások</span><span class="sxs-lookup"><span data-stu-id="cb9be-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="cb9be-224">Spark Streaming: A Spark on HDInsight használata valós idejű streamelési alkalmazások összeállítására</span><span class="sxs-lookup"><span data-stu-id="cb9be-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="cb9be-225">IntelliJ IDEA toodebug Spark-alkalmazások HDInsight-eszközei beépülő távolról használni</span><span class="sxs-lookup"><span data-stu-id="cb9be-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="cb9be-226">Zeppelin notebookok használata Spark-fürttel HDInsighton</span><span class="sxs-lookup"><span data-stu-id="cb9be-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="cb9be-227">Jupyter notebookokhoz elérhető kernelek a HDInsight Spark-fürtjében</span><span class="sxs-lookup"><span data-stu-id="cb9be-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="cb9be-228">Külső csomagok használata Jupyter notebookokkal</span><span class="sxs-lookup"><span data-stu-id="cb9be-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="cb9be-229">Jupyter telepítse a számítógépre, és csatlakozzon a HDInsight Spark-fürt tooan</span><span class="sxs-lookup"><span data-stu-id="cb9be-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
