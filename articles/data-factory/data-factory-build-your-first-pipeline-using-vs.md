---
title: "Az első data factory létrehozása (Visual Studio) | Microsoft Docs"
description: "Az oktatóanyag során létrehoz egy mintául szolgáló Azure Data Factory-folyamatot a Visual Studio használatával."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: 7398c0c9-7a03-4628-94b3-f2aaef4a72c5
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: hero-article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 77042219cbe698a33ab9447aa952586772897241
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 08/29/2017
---
# <a name="tutorial-create-a-data-factory-by-using-visual-studio"></a><span data-ttu-id="aabe6-103">Oktatóanyag: adat-előállító létrehozása a Visual Studióval</span><span class="sxs-lookup"><span data-stu-id="aabe6-103">Tutorial: Create a data factory by using Visual Studio</span></span>
> [!div class="op_single_selector" title="Tools/SDKs"]
> * [<span data-ttu-id="aabe6-104">Áttekintés és előfeltételek</span><span class="sxs-lookup"><span data-stu-id="aabe6-104">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="aabe6-105">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="aabe6-105">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="aabe6-106">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="aabe6-106">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="aabe6-107">PowerShell</span><span class="sxs-lookup"><span data-stu-id="aabe6-107">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="aabe6-108">Resource Manager-sablon</span><span class="sxs-lookup"><span data-stu-id="aabe6-108">Resource Manager Template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="aabe6-109">REST API</span><span class="sxs-lookup"><span data-stu-id="aabe6-109">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="aabe6-110">Ebből az oktatóanyagból megtudhatja, hogyan hozhat létre Azure Data Factoryt a Visual Studióval.</span><span class="sxs-lookup"><span data-stu-id="aabe6-110">This tutorial shows you how to create an Azure data factory by using Visual Studio.</span></span> <span data-ttu-id="aabe6-111">Létrehozhat egy Visual Studio projektet a Data Factory projektsablon használatával, definiálhatja a Data Factory entitásokat (társított szolgáltatásokat, adatkészleteket és folyamatot) JSON formátumban, majd közzéteheti/üzembe helyezheti az entitásokat a felhőben.</span><span class="sxs-lookup"><span data-stu-id="aabe6-111">You create a Visual Studio project using the Data Factory project template, define Data Factory entities (linked services, datasets, and pipeline) in JSON format, and then publish/deploy these entities to the cloud.</span></span> 

<span data-ttu-id="aabe6-112">A jelen oktatóanyagban szereplő folyamat egyetlen tevékenységet tartalmaz: ez a **HDInsight Hive-tevékenység**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-112">The pipeline in this tutorial has one activity: **HDInsight Hive activity**.</span></span> <span data-ttu-id="aabe6-113">A tevékenység egy hive-szkriptet futtat egy Azure HDInsight fürtön, amely a bemeneti adatokat átalakítja a kimeneti adatok előállításához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-113">This activity runs a hive script on an Azure HDInsight cluster that transforms input data to produce output data.</span></span> <span data-ttu-id="aabe6-114">A folyamat úgy van ütemezve, hogy havonta egyszer fusson a megadott kezdő és befejező időpontok közt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-114">The pipeline is scheduled to run once a month between the specified start and end times.</span></span> 

> [!NOTE]
> <span data-ttu-id="aabe6-115">Ez az oktatóanyag nem tartalmazza az adatok Azure Data Factory használatával történő másolásának leírását.</span><span class="sxs-lookup"><span data-stu-id="aabe6-115">This tutorial does not show how copy data by using Azure Data Factory.</span></span> <span data-ttu-id="aabe6-116">Az adatok Azure Data Factory használatával történő másolásának útmutatásáért olvassa el [az adatok Blob Storage-ból SQL Database-be történő másolását ismertető oktatóanyagot](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="aabe6-116">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="aabe6-117">Egy folyamathoz több tevékenység is tartozhat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-117">A pipeline can have more than one activity.</span></span> <span data-ttu-id="aabe6-118">Ezenkívül össze is fűzhet két tevékenységet (egymás után futtathatja őket), ha az egyik tevékenység kimeneti adatkészletét a másik tevékenység bemeneti adatkészleteként állítja be.</span><span class="sxs-lookup"><span data-stu-id="aabe6-118">And, you can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="aabe6-119">További tudnivalókért lásd: [Ütemezés és végrehajtás a Data Factoryban](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span><span class="sxs-lookup"><span data-stu-id="aabe6-119">For more information, see [scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span></span>


## <a name="walkthrough-create-and-publish-data-factory-entities"></a><span data-ttu-id="aabe6-120">Útmutató: Data Factory-entitások létrehozása és közzététele</span><span class="sxs-lookup"><span data-stu-id="aabe6-120">Walkthrough: Create and publish Data Factory entities</span></span>
<span data-ttu-id="aabe6-121">Az útmutató során a következő lépéseket fogja elvégezni:</span><span class="sxs-lookup"><span data-stu-id="aabe6-121">Here are the steps you perform as part of this walkthrough:</span></span>

1. <span data-ttu-id="aabe6-122">Létrehozza a következő két társított szolgáltatást: **AzureStorageLinkedService1** és **HDInsightOnDemandLinkedService1**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-122">Create two linked services: **AzureStorageLinkedService1** and **HDInsightOnDemandLinkedService1**.</span></span> 
   
    <span data-ttu-id="aabe6-123">Ebben az oktatóanyagban a hive-tevékenység bemeneti és kimeneti adatai ugyanabban az Azure Blob Storage-tárolóban vannak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-123">In this tutorial, both input and output data for the hive activity are in the same Azure Blob Storage.</span></span> <span data-ttu-id="aabe6-124">A meglévő bemeneti adatokat egy igény szerinti HDInsight-fürt használatával dolgozhatja fel a kimeneti adatok előállításához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-124">You use an on-demand HDInsight cluster to process existing input data to produce output data.</span></span> <span data-ttu-id="aabe6-125">Az igény szerinti HDInsight-fürtöt az Azure Data Factory automatikusan hozza létre futásidőben, amikor a bemeneti adatok készen állnak a feldolgozásra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-125">The on-demand HDInsight cluster is automatically created for you by Azure Data Factory at run time when the input data is ready to be processed.</span></span> <span data-ttu-id="aabe6-126">Az adattárakat vagy számítási erőforrásokat társítani kell a data factoryhoz, hogy a Data Factory szolgáltatás futásidőben képes legyen csatlakozni hozzájuk.</span><span class="sxs-lookup"><span data-stu-id="aabe6-126">You need to link your data stores or computes to your data factory so that the Data Factory service can connect to them at runtime.</span></span> <span data-ttu-id="aabe6-127">Ezért az AzureStorageLinkedService1 használatával társíthatja az Azure Storage-fiókját a data factoryhoz, a HDInsightOnDemandLinkedService1 használatával pedig egy igény szerinti HDInsight-fürtöt társíthat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-127">Therefore, you link your Azure Storage Account to the data factory by using the AzureStorageLinkedService1, and link an on-demand HDInsight cluster by using the HDInsightOnDemandLinkedService1.</span></span> <span data-ttu-id="aabe6-128">A közzétételkor adja meg a létrehozni kívánt vagy egy meglévő data factory nevét.</span><span class="sxs-lookup"><span data-stu-id="aabe6-128">When publishing, you specify the name for the data factory to be created or an existing data factory.</span></span>  
2. <span data-ttu-id="aabe6-129">Létrehoz két adatkészletet: az **InputDataset** és az **OutputDataset** adatkészletet, amelyek az Azure Blob Storage-tárolóban tárolt bemeneti/kimeneti adatokat képviselik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-129">Create two datasets: **InputDataset** and **OutputDataset**, which represent the input/output data that is stored in the Azure blob storage.</span></span> 
   
    <span data-ttu-id="aabe6-130">Ezek az adatkészlet-definíciók az előző lépésben létrehozott Azure Storage társított szolgáltatásra vonatkoznak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-130">These dataset definitions refer to the Azure Storage linked service you created in the previous step.</span></span> <span data-ttu-id="aabe6-131">Az InputDataset adatkészlethez megadja a blobtárolót (adfgetstarted) és a bemeneti adatokkal rendelkező blobot tároló mappát (inputdata).</span><span class="sxs-lookup"><span data-stu-id="aabe6-131">For the InputDataset, you specify the blob container (adfgetstarted) and the folder (inptutdata) that contains a blob with the input data.</span></span> <span data-ttu-id="aabe6-132">Az OutputDataset adatkészlethez megadja a blobtárolót (adfgetstarted) és a kimeneti adatokat tároló mappát (partitioneddata).</span><span class="sxs-lookup"><span data-stu-id="aabe6-132">For the OutputDataset, you specify the blob container (adfgetstarted) and the folder (partitioneddata) that holds the output data.</span></span> <span data-ttu-id="aabe6-133">Egyéb tulajdonságokat is megad, például a szerkezetet, rendelkezésre állást és a szabályzatot.</span><span class="sxs-lookup"><span data-stu-id="aabe6-133">You also specify other properties such as structure, availability, and policy.</span></span>
3. <span data-ttu-id="aabe6-134">Hozzon létre egy folyamatot **MyFirstPipeline** néven.</span><span class="sxs-lookup"><span data-stu-id="aabe6-134">Create a pipeline named **MyFirstPipeline**.</span></span> 
  
    <span data-ttu-id="aabe6-135">A jelen útmutatóban a folyamat egyetlen tevékenységet tartalmaz: ez a **HDInsight Hive-tevékenység**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-135">In this walkthrough, the pipeline has only one activity: **HDInsight Hive Activity**.</span></span> <span data-ttu-id="aabe6-136">A tevékenység a bemeneti adatokat átalakítja a kimeneti adatok előállításához, amihez egy hive-szkriptet futtat egy igény szerinti HDInsight-fürtön.</span><span class="sxs-lookup"><span data-stu-id="aabe6-136">This activity transform input data to produce output data by running a hive script on an on-demand HDInsight cluster.</span></span> <span data-ttu-id="aabe6-137">A hive-tevékenységgel kapcsolatos további információk: [Hive-tevékenység](data-factory-hive-activity.md)</span><span class="sxs-lookup"><span data-stu-id="aabe6-137">To learn more about hive activity, see [Hive Activity](data-factory-hive-activity.md)</span></span> 
4. <span data-ttu-id="aabe6-138">Létrehoz egy **DataFactoryUsingVS** nevű data factoryt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-138">Create a data factory named **DataFactoryUsingVS**.</span></span> <span data-ttu-id="aabe6-139">Üzembe helyezi a data factoryt és a Data Factory-entitásokat (társított szolgáltatások, táblák és a folyamat).</span><span class="sxs-lookup"><span data-stu-id="aabe6-139">Deploy the data factory and all Data Factory entities (linked services, tables, and the pipeline).</span></span>
5. <span data-ttu-id="aabe6-140">A közzététel után az Azure Portal paneljei és a Figyelés + felügyelet alkalmazás használatával figyelheti a folyamatot.</span><span class="sxs-lookup"><span data-stu-id="aabe6-140">After you publish, you use Azure portal blades and Monitoring & Management App to monitor the pipeline.</span></span> 
  
### <a name="prerequisites"></a><span data-ttu-id="aabe6-141">Előfeltételek</span><span class="sxs-lookup"><span data-stu-id="aabe6-141">Prerequisites</span></span>
1. <span data-ttu-id="aabe6-142">Olvassa el [Az oktatóanyag áttekintése](data-factory-build-your-first-pipeline.md) című részt, és hajtsa végre az **előfeltételként** felsorolt lépéseket.</span><span class="sxs-lookup"><span data-stu-id="aabe6-142">Read through [Tutorial Overview](data-factory-build-your-first-pipeline.md) article and complete the **prerequisite** steps.</span></span> <span data-ttu-id="aabe6-143">Választhatja az **Áttekintés és előfeltételek** lehetőséget is a felül lévő legördülő listában, ha a cikkre szeretne váltani.</span><span class="sxs-lookup"><span data-stu-id="aabe6-143">You can also select the **Overview and prerequisites** option in the drop-down list at the top to switch to the article.</span></span> <span data-ttu-id="aabe6-144">Miután végzett az előfeltételekkel, váltson vissza erre a cikkre a **Visual Studio** lehetőség kiválasztásával a legördülő listában.</span><span class="sxs-lookup"><span data-stu-id="aabe6-144">After you complete the prerequisites, switch back to this article by selecting **Visual Studio** option in the drop-down list.</span></span>
2. <span data-ttu-id="aabe6-145">Data Factory-példány létrehozásához a [Data Factory közreműködője](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) szerepkör tagjának kell lennie az előfizetés/erőforráscsoport szintjén.</span><span class="sxs-lookup"><span data-stu-id="aabe6-145">To create Data Factory instances, you must be a member of the [Data Factory Contributor](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) role at the subscription/resource group level.</span></span>  
3. <span data-ttu-id="aabe6-146">A számítógépre a következőket kell telepíteni:</span><span class="sxs-lookup"><span data-stu-id="aabe6-146">You must have the following installed on your computer:</span></span>
   * <span data-ttu-id="aabe6-147">Visual Studio 2013 vagy Visual Studio 2015</span><span class="sxs-lookup"><span data-stu-id="aabe6-147">Visual Studio 2013 or Visual Studio 2015</span></span>
   * <span data-ttu-id="aabe6-148">Töltse le az Azure SDK-t a Visual Studio 2013-hoz vagy a Visual Studio 2015-höz.</span><span class="sxs-lookup"><span data-stu-id="aabe6-148">Download Azure SDK for Visual Studio 2013 or Visual Studio 2015.</span></span> <span data-ttu-id="aabe6-149">Nyissa meg az [Azure letöltési oldalát](https://azure.microsoft.com/downloads/), és kattintson a **VS 2013** vagy a **VS 2015** elemre a **.NET** szakaszban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-149">Navigate to [Azure Download Page](https://azure.microsoft.com/downloads/) and click **VS 2013** or **VS 2015** in the **.NET** section.</span></span>
   * <span data-ttu-id="aabe6-150">Töltse le a legújabb Azure Data Factory beépülő modult a Visual Studióhoz: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) vagy [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005).</span><span class="sxs-lookup"><span data-stu-id="aabe6-150">Download the latest Azure Data Factory plugin for Visual Studio: [VS 2013](https://visualstudiogallery.msdn.microsoft.com/754d998c-8f92-4aa7-835b-e89c8c954aa5) or [VS 2015](https://visualstudiogallery.msdn.microsoft.com/371a4cf9-0093-40fa-b7dd-be3c74f49005).</span></span> <span data-ttu-id="aabe6-151">A beépülő modult a következőképpen is frissítheti: A menüben kattintson a **Tools** -> **Extensions and Updates** -> **Online** -> **Visual Studio Gallery** -> **Microsoft Azure Data Factory Tools for Visual Studio** -> **Update** (Eszközök > Bővítmények és frissítések > Online > Visual Studio-gyűjtemény > Microsoft Azure Data Factory-eszközök a Visual Studióhoz > Frissítés) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-151">You can also update the plugin by doing the following steps: On the menu, click **Tools** -> **Extensions and Updates** -> **Online** -> **Visual Studio Gallery** -> **Microsoft Azure Data Factory Tools for Visual Studio** -> **Update**.</span></span>

<span data-ttu-id="aabe6-152">Most hozzunk létre egy Azure data factoryt a Visual Studióval.</span><span class="sxs-lookup"><span data-stu-id="aabe6-152">Now, let's use Visual Studio to create an Azure data factory.</span></span>

### <a name="create-visual-studio-project"></a><span data-ttu-id="aabe6-153">Visual Studio-projekt létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-153">Create Visual Studio project</span></span>
1. <span data-ttu-id="aabe6-154">Indítsa el a **Visual Studio 2013-at** vagy a **Visual Studio 2015-öt**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-154">Launch **Visual Studio 2013** or **Visual Studio 2015**.</span></span> <span data-ttu-id="aabe6-155">Kattintson a **File** (Fájl) menüre, mutasson a **New** (Új) elemre, és kattintson a **Project** (Projekt) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-155">Click **File**, point to **New**, and click **Project**.</span></span> <span data-ttu-id="aabe6-156">Meg kell jelennie a **New project** (Új projekt) párbeszédpanelnek.</span><span class="sxs-lookup"><span data-stu-id="aabe6-156">You should see the **New Project** dialog box.</span></span>  
2. <span data-ttu-id="aabe6-157">A **New project** (Új projekt) párbeszédpanelen jelölje ki a **DataFactory** sablont, és kattintson az **Empty Data Factory Project** (Üres Data Factory-projekt) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-157">In the **New Project** dialog, select the **DataFactory** template, and click **Empty Data Factory Project**.</span></span>   

    ![A New project (Új projekt) párbeszédpanel](./media/data-factory-build-your-first-pipeline-using-vs/new-project-dialog.png)
3. <span data-ttu-id="aabe6-159">Adja meg a projekt **nevét**, a **helyet**, valamint a **megoldás** nevét, és kattintson az **OK** gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-159">Enter a **name** for the project, **location**, and a name for the **solution**, and click **OK**.</span></span>

    ![Megoldáskezelő](./media/data-factory-build-your-first-pipeline-using-vs/solution-explorer.png)

### <a name="create-linked-services"></a><span data-ttu-id="aabe6-161">Társított szolgáltatások létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-161">Create linked services</span></span>
<span data-ttu-id="aabe6-162">Ebben a lépésben létrehozza a következő két társított szolgáltatást: **Azure Storage** és **igény szerinti HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-162">In this step, you create two linked services: **Azure Storage** and **HDInsight on-demand**.</span></span> 

<span data-ttu-id="aabe6-163">Az Azure Storage társított szolgáltatás a kapcsolódási adatok megadásával társítja Azure Storage-fiókját a data factoryhoz.</span><span class="sxs-lookup"><span data-stu-id="aabe6-163">The Azure Storage linked service links your Azure Storage account to the data factory by providing the connection information.</span></span> <span data-ttu-id="aabe6-164">A Data Factory szolgáltatás a társított szolgáltatás beállításából származó kapcsolati sztringet használja az Azure-tárolóhoz való csatlakozáshoz futásidőben.</span><span class="sxs-lookup"><span data-stu-id="aabe6-164">Data Factory service uses the connection string from the linked service setting to connect to the Azure storage at runtime.</span></span> <span data-ttu-id="aabe6-165">Ez a tároló tárolja a folyamat bemeneti és kimeneti adatait, valamint a hive-tevékenység által használt hive-szkriptet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-165">This storage holds input and output data for the pipeline, and the hive script file used by the hive activity.</span></span> 

<span data-ttu-id="aabe6-166">Az igény szerinti HDInsight társított szolgáltatással a HDInsight-fürt automatikusan jön létre futásidőben, amikor a bemeneti adatok készen állnak a feldolgozásra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-166">With on-demand HDInsight linked service, The HDInsight cluster is automatically created at runtime when the input data is ready to processed.</span></span> <span data-ttu-id="aabe6-167">A fürtöt a rendszer törli a feldolgozás befejezését követően, miután egy adott ideig tétlen volt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-167">The cluster is deleted after it is done processing and idle for the specified amount of time.</span></span> 

> [!NOTE]
> <span data-ttu-id="aabe6-168">A data factory létrehozásához meg kell adni annak nevét és beállításait a Data Factory megoldás közzétételekor.</span><span class="sxs-lookup"><span data-stu-id="aabe6-168">You create a data factory by specifying its name and settings at the time of publishing your Data Factory solution.</span></span>

#### <a name="create-azure-storage-linked-service"></a><span data-ttu-id="aabe6-169">Azure Storage társított szolgáltatás létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-169">Create Azure Storage linked service</span></span>
1. <span data-ttu-id="aabe6-170">A Solution Explorerben (Megoldáskezelőben) kattintson a jobb gombbal a **Linked Services** (Társított szolgáltatások) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson a **New Item** (Új elem) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-170">Right-click **Linked Services** in the solution explorer, point to **Add**, and click **New Item**.</span></span>      
2. <span data-ttu-id="aabe6-171">Az **Add New Item** (Új elem hozzáadása) párbeszédpanelen válassza ki a listából az **Azure Storage Linked Service** (Azure Storage társított szolgáltatás) elemet, és kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-171">In the **Add New Item** dialog box, select **Azure Storage Linked Service** from the list, and click **Add**.</span></span>
    <span data-ttu-id="aabe6-172">![Azure Storage társított szolgáltatás](./media/data-factory-build-your-first-pipeline-using-vs/new-azure-storage-linked-service.png)</span><span class="sxs-lookup"><span data-stu-id="aabe6-172">![Azure Storage Linked Service](./media/data-factory-build-your-first-pipeline-using-vs/new-azure-storage-linked-service.png)</span></span>
3. <span data-ttu-id="aabe6-173">Cserélje le az `<accountname>` és az `<accountkey>` kifejezést az Azure Storage-tárfiókja nevére, illetve kulcsára.</span><span class="sxs-lookup"><span data-stu-id="aabe6-173">Replace `<accountname>` and `<accountkey>` with the name of your Azure storage account and its key.</span></span> <span data-ttu-id="aabe6-174">A tárelérési kulcs lekéréséről többet is megtudhat, ha elolvassa a tárelérési kulcsok megtekintésével, másolásával és újragenerálásával kapcsolatos információkat [A tárfiók kezelése](../storage/common/storage-create-storage-account.md#manage-your-storage-account) című részben.</span><span class="sxs-lookup"><span data-stu-id="aabe6-174">To learn how to get your storage access key, see the information about how to view, copy, and regenerate storage access keys in [Manage your storage account](../storage/common/storage-create-storage-account.md#manage-your-storage-account).</span></span>
    <span data-ttu-id="aabe6-175">![Azure Storage társított szolgáltatás](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)</span><span class="sxs-lookup"><span data-stu-id="aabe6-175">![Azure Storage Linked Service](./media/data-factory-build-your-first-pipeline-using-vs/azure-storage-linked-service.png)</span></span>
4. <span data-ttu-id="aabe6-176">Mentse az **AzureStorageLinkedService1.json** fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-176">Save the **AzureStorageLinkedService1.json** file.</span></span>

#### <a name="create-azure-hdinsight-linked-service"></a><span data-ttu-id="aabe6-177">Azure HDInsight társított szolgáltatás létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-177">Create Azure HDInsight linked service</span></span>
1. <span data-ttu-id="aabe6-178">A **Solution Explorerben** (Megoldáskezelőben) kattintson a jobb gombbal a **Linked Services** (Társított szolgáltatások) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson a **New Item** (Új elem) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-178">In the **Solution Explorer**, right-click **Linked Services**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="aabe6-179">Válassza a **HDInsight On Demand Linked Service** (HDInsight igény szerinti társított szolgáltatás) lehetőséget, és kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-179">Select **HDInsight On Demand Linked Service**, and click **Add**.</span></span>
3. <span data-ttu-id="aabe6-180">Cserélje le a **JSON-t** a következő JSON-ra:</span><span class="sxs-lookup"><span data-stu-id="aabe6-180">Replace the **JSON** with the following JSON:</span></span>

     ```json
    {
        "name": "HDInsightOnDemandLinkedService",
        "properties": {
        "type": "HDInsightOnDemand",
            "typeProperties": {
                "version": "3.5",
                "clusterSize": 1,
                "timeToLive": "00:05:00",
                "osType": "Linux",
                "linkedServiceName": "AzureStorageLinkedService1"
            }
        }
    }
    ```

    <span data-ttu-id="aabe6-181">Az alábbi táblázat ismerteti a kódrészletben használt JSON-tulajdonságokat:</span><span class="sxs-lookup"><span data-stu-id="aabe6-181">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    <span data-ttu-id="aabe6-182">Tulajdonság</span><span class="sxs-lookup"><span data-stu-id="aabe6-182">Property</span></span> | <span data-ttu-id="aabe6-183">Leírás</span><span class="sxs-lookup"><span data-stu-id="aabe6-183">Description</span></span>
    -------- | ----------- 
    <span data-ttu-id="aabe6-184">ClusterSize</span><span class="sxs-lookup"><span data-stu-id="aabe6-184">ClusterSize</span></span> | <span data-ttu-id="aabe6-185">Megadja a HDInsight Hadoop-fürt méretét.</span><span class="sxs-lookup"><span data-stu-id="aabe6-185">Specifies the size of the HDInsight Hadoop cluster.</span></span>
    <span data-ttu-id="aabe6-186">TimeToLive</span><span class="sxs-lookup"><span data-stu-id="aabe6-186">TimeToLive</span></span> | <span data-ttu-id="aabe6-187">Megadja, hogy a HDInsight-fürt mennyi ideig lehet tétlen, mielőtt törölné a rendszer.</span><span class="sxs-lookup"><span data-stu-id="aabe6-187">Specifies that the idle time for the HDInsight cluster, before it is deleted.</span></span>
    <span data-ttu-id="aabe6-188">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="aabe6-188">linkedServiceName</span></span> | <span data-ttu-id="aabe6-189">Megadja a HDInsight Hadoop-fürt által előállított naplók tárolására szolgáló tárfiókot.</span><span class="sxs-lookup"><span data-stu-id="aabe6-189">Specifies the storage account that is used to store the logs that are generated by HDInsight Hadoop cluster.</span></span> 

    > [!IMPORTANT]
    > <span data-ttu-id="aabe6-190">A HDInsight-fürt létrehoz egy **alapértelmezett tárolót** a JSON-fájlban megadott blobtárolóban (linkedServiceName).</span><span class="sxs-lookup"><span data-stu-id="aabe6-190">The HDInsight cluster creates a **default container** in the blob storage you specified in the JSON (linkedServiceName).</span></span> <span data-ttu-id="aabe6-191">A fürt törlésekor a HDInsight nem törli ezt a tárolót.</span><span class="sxs-lookup"><span data-stu-id="aabe6-191">HDInsight does not delete this container when the cluster is deleted.</span></span> <span data-ttu-id="aabe6-192">Ez a működésmód szándékos.</span><span class="sxs-lookup"><span data-stu-id="aabe6-192">This behavior is by design.</span></span> <span data-ttu-id="aabe6-193">Igény szerinti HDInsight társított szolgáltatás esetén a rendszer a szeletek feldolgozásakor mindig létrehoz egy HDInsight-fürtöt, kivéve, ha van meglévő élő fürt (timeToLive).</span><span class="sxs-lookup"><span data-stu-id="aabe6-193">With on-demand HDInsight linked service, a HDInsight cluster is created every time a slice is processed unless there is an existing live cluster (timeToLive).</span></span> <span data-ttu-id="aabe6-194">A fürt automatikusan törlődik a feldolgozás megtörténtekor.</span><span class="sxs-lookup"><span data-stu-id="aabe6-194">The cluster is automatically deleted when the processing is done.</span></span>
    > 
    > <span data-ttu-id="aabe6-195">Ahogy egyre több szelet lesz feldolgozva, egyre több tároló jelenik meg az Azure Blob Storage-tárban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-195">As more slices are processed, you see many containers in your Azure blob storage.</span></span> <span data-ttu-id="aabe6-196">Ha nincs szüksége rájuk a feladatokkal kapcsolatos hibaelhárításhoz, törölheti őket a tárolási költségek csökkentése érdekében.</span><span class="sxs-lookup"><span data-stu-id="aabe6-196">If you do not need them for troubleshooting of the jobs, you may want to delete them to reduce the storage cost.</span></span> <span data-ttu-id="aabe6-197">A tárolók neve a következő mintát követi: `adf<yourdatafactoryname>-<linkedservicename>-datetimestamp`.</span><span class="sxs-lookup"><span data-stu-id="aabe6-197">The names of these containers follow a pattern: `adf<yourdatafactoryname>-<linkedservicename>-datetimestamp`.</span></span> <span data-ttu-id="aabe6-198">Az Azure Blob Storage-tárból olyan eszközökkel törölheti a tárolókat, mint például a [Microsoft Storage Explorer](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="aabe6-198">Use tools such as [Microsoft Storage Explorer](http://storageexplorer.com/) to delete containers in your Azure blob storage.</span></span>

    <span data-ttu-id="aabe6-199">A JSON-tulajdonságokkal kapcsolatos további információkért lásd a [Társított szolgáltatások számítása](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) című cikket.</span><span class="sxs-lookup"><span data-stu-id="aabe6-199">For more information about JSON properties, see [Compute linked services](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) article.</span></span> 
4. <span data-ttu-id="aabe6-200">Mentse a **HDInsightOnDemandLinkedService1.json** fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-200">Save the **HDInsightOnDemandLinkedService1.json** file.</span></span>

### <a name="create-datasets"></a><span data-ttu-id="aabe6-201">Adatkészletek létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-201">Create datasets</span></span>
<span data-ttu-id="aabe6-202">Ebben a lépésben adatkészleteket hoz létre, amelyek a Hive-feldolgozás bemeneti és kimeneti adatait képviselik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-202">In this step, you create datasets to represent the input and output data for Hive processing.</span></span> <span data-ttu-id="aabe6-203">Ezek az adatkészletek az oktatóanyag során korábban létrehozott **AzureStorageLinkedService1** szolgáltatásra hivatkoznak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-203">These datasets refer to the **AzureStorageLinkedService1** you have created earlier in this tutorial.</span></span> <span data-ttu-id="aabe6-204">A társított szolgáltatás egy Azure Storage-fiókra mutat, az adatkészletek pedig meghatározzák a bemeneti és kimeneti adatokat tartalmazó tárban lévő tárolót, mappát és fájlnevet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-204">The linked service points to an Azure Storage account and datasets specify container, folder, file name in the storage that holds input and output data.</span></span>   

#### <a name="create-input-dataset"></a><span data-ttu-id="aabe6-205">Bemeneti adatkészlet létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-205">Create input dataset</span></span>
1. <span data-ttu-id="aabe6-206">A **Solution Explorerben** (Megoldáskezelőben) kattintson a jobb gombbal a **Tables** (Táblák) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson a **New Item** (Új elem) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-206">In the **Solution Explorer**, right-click **Tables**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="aabe6-207">Válassza ki a listából az **Azure Blob** lehetőséget, módosítsa a fájl nevét **InputDataSet.json** névre, és kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-207">Select **Azure Blob** from the list, change the name of the file to **InputDataSet.json**, and click **Add**.</span></span>
3. <span data-ttu-id="aabe6-208">A szerkesztőben cserélje le a **JSON-t** a következő JSON-kódrészletre:</span><span class="sxs-lookup"><span data-stu-id="aabe6-208">Replace the **JSON** in the editor with the following JSON snippet:</span></span>

    ```json
    {
        "name": "AzureBlobInput",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
                "fileName": "input.log",
                "folderPath": "adfgetstarted/inputdata",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": ","
                }
            },
            "availability": {
                "frequency": "Month",
                "interval": 1
            },
            "external": true,
            "policy": {}
        }
    }
    ```
    <span data-ttu-id="aabe6-209">Ez a JSON-kódrészlet definiál egy **AzureBlobInput** nevű adatkészletet, amely a folyamat hive-tevékenységének bemeneti adatait képviseli.</span><span class="sxs-lookup"><span data-stu-id="aabe6-209">This JSON snippet defines a dataset called **AzureBlobInput** that represents input data for the hive activity in the pipeline.</span></span> <span data-ttu-id="aabe6-210">Ön adja meg, hogy a bemeneti adatok az `adfgetstarted` nevű blobtárolóban és az `inputdata` nevű mappában találhatóak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-210">You specify that the input data is located in the blob container called `adfgetstarted` and the folder called `inputdata`.</span></span>

    <span data-ttu-id="aabe6-211">Az alábbi táblázat ismerteti a kódrészletben használt JSON-tulajdonságokat:</span><span class="sxs-lookup"><span data-stu-id="aabe6-211">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    <span data-ttu-id="aabe6-212">Tulajdonság</span><span class="sxs-lookup"><span data-stu-id="aabe6-212">Property</span></span> | <span data-ttu-id="aabe6-213">Leírás</span><span class="sxs-lookup"><span data-stu-id="aabe6-213">Description</span></span> |
    -------- | ----------- |
    <span data-ttu-id="aabe6-214">type</span><span class="sxs-lookup"><span data-stu-id="aabe6-214">type</span></span> |<span data-ttu-id="aabe6-215">A tulajdonság beállítása **AzureBlob**, mert az adatok az Azure Blob Storage-tárban találhatók.</span><span class="sxs-lookup"><span data-stu-id="aabe6-215">The type property is set to **AzureBlob** because data resides in Azure Blob Storage.</span></span>
    <span data-ttu-id="aabe6-216">linkedServiceName</span><span class="sxs-lookup"><span data-stu-id="aabe6-216">linkedServiceName</span></span> | <span data-ttu-id="aabe6-217">A korábban létrehozott AzureStorageLinkedService1 szolgáltatásra hivatkozik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-217">Refers to the AzureStorageLinkedService1 you created earlier.</span></span>
    <span data-ttu-id="aabe6-218">fileName</span><span class="sxs-lookup"><span data-stu-id="aabe6-218">fileName</span></span> |<span data-ttu-id="aabe6-219">Ez a tulajdonság nem kötelező.</span><span class="sxs-lookup"><span data-stu-id="aabe6-219">This property is optional.</span></span> <span data-ttu-id="aabe6-220">Ha kihagyja, az összes fájl ki lesz választva a folderPath útvonalról.</span><span class="sxs-lookup"><span data-stu-id="aabe6-220">If you omit this property, all the files from the folderPath are picked.</span></span> <span data-ttu-id="aabe6-221">Ebben az esetben csak az input.log fájl lesz feldolgozva.</span><span class="sxs-lookup"><span data-stu-id="aabe6-221">In this case, only the input.log is processed.</span></span>
    <span data-ttu-id="aabe6-222">type</span><span class="sxs-lookup"><span data-stu-id="aabe6-222">type</span></span> | <span data-ttu-id="aabe6-223">A naplófájlok szövegformátumúak, ezért a TextFormat típust használjuk.</span><span class="sxs-lookup"><span data-stu-id="aabe6-223">The log files are in text format, so we use TextFormat.</span></span> |
    <span data-ttu-id="aabe6-224">columnDelimiter</span><span class="sxs-lookup"><span data-stu-id="aabe6-224">columnDelimiter</span></span> | <span data-ttu-id="aabe6-225">A naplófájlokban vesszővel (`,`) vannak elválasztva az oszlopok</span><span class="sxs-lookup"><span data-stu-id="aabe6-225">columns in the log files are delimited by the comma character (`,`)</span></span>
    <span data-ttu-id="aabe6-226">frequency/interval</span><span class="sxs-lookup"><span data-stu-id="aabe6-226">frequency/interval</span></span> | <span data-ttu-id="aabe6-227">A frequency (gyakoriság) beállítása Month (Hónap), az interval (időköz) beállítása pedig 1, ami azt jelenti, hogy a bemeneti szeletek havonta érhetők el.</span><span class="sxs-lookup"><span data-stu-id="aabe6-227">frequency set to Month and interval is 1, which means that the input slices are available monthly.</span></span>
    <span data-ttu-id="aabe6-228">external</span><span class="sxs-lookup"><span data-stu-id="aabe6-228">external</span></span> | <span data-ttu-id="aabe6-229">Ez a tulajdonság true (igaz) értékre van állítva, ha a tevékenység bemeneti adatait nem a folyamat hozta létre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-229">This property is set to true if the input data for the activity is not generated by the pipeline.</span></span> <span data-ttu-id="aabe6-230">Ez a tulajdonság csak a bemeneti adatkészleteken van meghatározva.</span><span class="sxs-lookup"><span data-stu-id="aabe6-230">This property is only specified on input datasets.</span></span> <span data-ttu-id="aabe6-231">Az első tevékenység bemeneti adatkészlete esetében mindig állítsa igaz értékre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-231">For the input dataset of the first activity, always set it to true.</span></span>
4. <span data-ttu-id="aabe6-232">Mentse az **InputDataset.json** fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-232">Save the **InputDataset.json** file.</span></span>

#### <a name="create-output-dataset"></a><span data-ttu-id="aabe6-233">Kimeneti adatkészlet létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-233">Create output dataset</span></span>
<span data-ttu-id="aabe6-234">Most a kimeneti adatkészletet hozza létre, amely az Azure Blob Storage-tárolóban tárolt kimeneti adatokat jelöli.</span><span class="sxs-lookup"><span data-stu-id="aabe6-234">Now, you create the output dataset to represent output data stored in the Azure Blob storage.</span></span>

1. <span data-ttu-id="aabe6-235">A **Solution Explorerben** (Megoldáskezelőben) kattintson a jobb gombbal a **Tables** (Táblák) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson a **New Item** (Új elem) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-235">In the **Solution Explorer**, right-click **tables**, point to **Add**, and click **New Item**.</span></span>
2. <span data-ttu-id="aabe6-236">Válassza ki a listából az **Azure Blob** lehetőséget, módosítsa a fájl nevét **OutputDataset.json** névre, és kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-236">Select **Azure Blob** from the list, change the name of the file to **OutputDataset.json**, and click **Add**.</span></span>
3. <span data-ttu-id="aabe6-237">A szerkesztőben cserélje le a **JSON-t** a következő JSON-ra:</span><span class="sxs-lookup"><span data-stu-id="aabe6-237">Replace the **JSON** in the editor with the following JSON:</span></span>
    
    ```json
    {
        "name": "AzureBlobOutput",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService1",
            "typeProperties": {
                "folderPath": "adfgetstarted/partitioneddata",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": ","
                }
            },
            "availability": {
                "frequency": "Month",
                "interval": 1
            }
        }
    }
    ```
    <span data-ttu-id="aabe6-238">Ez a JSON-kódrészlet definiál egy **AzureBlobOutput** nevű adatkészletet, amely a folyamat hive-tevékenysége által előállított kimeneti adatokat képviseli.</span><span class="sxs-lookup"><span data-stu-id="aabe6-238">The JSON snippet defines a dataset called **AzureBlobOutput** that represents output data produced by the hive activity in the pipeline.</span></span> <span data-ttu-id="aabe6-239">Ön adja meg, hogy a hive-tevékenység által előállított kimeneti adatok az `adfgetstarted` nevű blobtárolóba és a `partitioneddata` nevű mappába kerülnek.</span><span class="sxs-lookup"><span data-stu-id="aabe6-239">You specify that the output data is produced by the hive activity is placed in the blob container called `adfgetstarted` and the folder called `partitioneddata`.</span></span> 
    
    <span data-ttu-id="aabe6-240">Az **availability** (rendelkezésre állás) szakasz meghatározza, hogy a kimeneti adatkészlet előállítása havonta történik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-240">The **availability** section specifies that the output dataset is produced on a monthly basis.</span></span> <span data-ttu-id="aabe6-241">A kimeneti adatkészlet határozza meg a folyamat ütemezését.</span><span class="sxs-lookup"><span data-stu-id="aabe6-241">The output dataset drives the schedule of the pipeline.</span></span> <span data-ttu-id="aabe6-242">A folyamat havonta egyszer fut le a kezdő és befejező időpontjai közt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-242">The pipeline runs monthly between its start and end times.</span></span> 

    <span data-ttu-id="aabe6-243">A tulajdonságok leírását a **Bemeneti adatkészlet létrehozása** című szakaszban tekintheti meg.</span><span class="sxs-lookup"><span data-stu-id="aabe6-243">See **Create the input dataset** section for descriptions of these properties.</span></span> <span data-ttu-id="aabe6-244">Külső adatkészlet esetén nem kell beállítani az external (külső) tulajdonságot, mert az adatkészletet a folyamat állítja elő.</span><span class="sxs-lookup"><span data-stu-id="aabe6-244">You do not set the external property on an output dataset as the dataset is produced by the pipeline.</span></span>
4. <span data-ttu-id="aabe6-245">Mentse az **OutputDataset.json** fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-245">Save the **OutputDataset.json** file.</span></span>

### <a name="create-pipeline"></a><span data-ttu-id="aabe6-246">Folyamat létrehozása</span><span class="sxs-lookup"><span data-stu-id="aabe6-246">Create pipeline</span></span>
<span data-ttu-id="aabe6-247">Eddig létrehozta az Azure Storage társított szolgáltatást, valamint a bemeneti és kimeneti adatkészleteket.</span><span class="sxs-lookup"><span data-stu-id="aabe6-247">You have created the Azure Storage linked service, and input and output datasets so far.</span></span> <span data-ttu-id="aabe6-248">Most létrehozhat egy folyamatot egy **HDInsightHive**-tevékenységgel.</span><span class="sxs-lookup"><span data-stu-id="aabe6-248">Now, you create a pipeline with a **HDInsightHive** activity.</span></span> <span data-ttu-id="aabe6-249">A tevékenység **bemenetének** beállítása **AzureBlobInput**, a **kimeneté** pedig **AzureBlobOutput**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-249">The **input** for the hive activity is set to **AzureBlobInput** and **output** is set to **AzureBlobOutput**.</span></span> <span data-ttu-id="aabe6-250">A bemeneti adatkészlet szelete havonta érhető el (frequency: Month, interval: 1), és a kimeneti szelet előállítása is havonta történik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-250">A slice of an input dataset is available monthly (frequency: Month, interval: 1), and the output slice is produced monthly too.</span></span> 

1. <span data-ttu-id="aabe6-251">A **Solution Explorerben** (Megoldáskezelőben) kattintson a jobb gombbal a **Pipelines** (Folyamatok) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson a **New Item** (Új elem) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-251">In the **Solution Explorer**, right-click **Pipelines**, point to **Add**, and click **New Item.**</span></span>
2. <span data-ttu-id="aabe6-252">Válassza ki a listából a **Hive Transformation Pipeline** (Hive átalakítási folyamat) lehetőséget, és kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-252">Select **Hive Transformation Pipeline** from the list, and click **Add**.</span></span>
3. <span data-ttu-id="aabe6-253">Cserélje le a **JSON-t** az alábbi kódrészlettel:</span><span class="sxs-lookup"><span data-stu-id="aabe6-253">Replace the **JSON** with the following snippet:</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="aabe6-254">Cserélje le a `<storageaccountname>` kifejezést a tárfiókja nevére.</span><span class="sxs-lookup"><span data-stu-id="aabe6-254">Replace `<storageaccountname>` with the name of your storage account.</span></span>

    ```json
    {
        "name": "MyFirstPipeline",
        "properties": {
            "description": "My first Azure Data Factory pipeline",
            "activities": [
                {
                    "type": "HDInsightHive",
                    "typeProperties": {
                        "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                        "scriptLinkedService": "AzureStorageLinkedService1",
                        "defines": {
                            "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                            "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                        }
                    },
                    "inputs": [
                        {
                            "name": "AzureBlobInput"
                        }
                    ],
                    "outputs": [
                        {
                            "name": "AzureBlobOutput"
                        }
                    ],
                    "policy": {
                        "concurrency": 1,
                        "retry": 3
                    },
                    "scheduler": {
                        "frequency": "Month",
                        "interval": 1
                    },
                    "name": "RunSampleHiveActivity",
                    "linkedServiceName": "HDInsightOnDemandLinkedService"
                }
            ],
            "start": "2016-04-01T00:00:00Z",
            "end": "2016-04-02T00:00:00Z",
            "isPaused": false
        }
    }
    ```

    > [!IMPORTANT]
    > <span data-ttu-id="aabe6-255">Cserélje le a `<storageaccountname>` kifejezést a tárfiókja nevére.</span><span class="sxs-lookup"><span data-stu-id="aabe6-255">Replace `<storageaccountname>` with the name of your storage account.</span></span>

    <span data-ttu-id="aabe6-256">A JSON-kódrészlet meghatároz egy folyamatot, amely egyetlen tevékenységből áll (Hive-tevékenység).</span><span class="sxs-lookup"><span data-stu-id="aabe6-256">The JSON snippet defines a pipeline that consists of a single activity (Hive Activity).</span></span> <span data-ttu-id="aabe6-257">A tevékenység egy Hive-szkriptet futtat a bemeneti adatok feldolgozásához és a kimeneti adatok előállításához egy igény szerinti HDInsight-fürtön.</span><span class="sxs-lookup"><span data-stu-id="aabe6-257">This activity runs a Hive script to process input data on an on-demand HDInsight cluster to produce output data.</span></span> <span data-ttu-id="aabe6-258">A folyamat JSON-fájljának tevékenységek szakaszában csak egyetlen tevékenység látható a tömbben, **HDInsightHive** típusbeállítással.</span><span class="sxs-lookup"><span data-stu-id="aabe6-258">In the activities section of the pipeline JSON, you see only one activity in the array with type set to **HDInsightHive**.</span></span> 

    <span data-ttu-id="aabe6-259">A HDInsight Hive-tevékenység specifikus típustulajdonságaiban megadja, hogy az Azure Storage társított szolgáltatás tartalmazza a hive-szkriptfájlt, a szkriptfájl útvonalát és paramétereit.</span><span class="sxs-lookup"><span data-stu-id="aabe6-259">In the type properties that are specific to HDInsight Hive activity, you specify what Azure Storage linked service has the hive script file, the path to the script file, and parameters to the script file.</span></span> 

    <span data-ttu-id="aabe6-260">A **partitionweblogs.hql** nevű Hive-szkriptfájl tárolása a (scriptLinkedService szolgáltatással megadott) Azure Storage-fiókban és az `adfgetstarted` tároló `script` mappájában történik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-260">The Hive script file, **partitionweblogs.hql**, is stored in the Azure storage account (specified by the scriptLinkedService), and in the `script` folder in the container `adfgetstarted`.</span></span>

    <span data-ttu-id="aabe6-261">A `defines` szakasz meghatározza a futásidő beállításait, amelyek Hive konfigurációs értékekként (például `${hiveconf:inputtable}`, `${hiveconf:partitionedtable})`) lesznek átadva a Hive-parancsfájlnak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-261">The `defines` section is used to specify the runtime settings that are passed to the hive script as Hive configuration values (e.g `${hiveconf:inputtable}`, `${hiveconf:partitionedtable})`.</span></span>

    <span data-ttu-id="aabe6-262">A folyamat **start** (kezdés) és **end** (befejezés) tulajdonságai a folyamat aktív időszakát határozzák meg.</span><span class="sxs-lookup"><span data-stu-id="aabe6-262">The **start** and **end** properties of the pipeline specifies the active period of the pipeline.</span></span> <span data-ttu-id="aabe6-263">Az adatkészletet úgy állította be, hogy havonta legyen előállítva, így a folyamat csak egyetlen szeletet állít elő (mivel a hónap a kezdő és a befejező dátumban egyezik).</span><span class="sxs-lookup"><span data-stu-id="aabe6-263">You configured the dataset to be produced monthly, therefore, only once slice is produced by the pipeline (because the month is same in start and end dates).</span></span>

    <span data-ttu-id="aabe6-264">A tevékenység JSON-fájljában meg van határozva, hogy a Hive-parancsfájl a **linkedServiceName** – **HDInsightOnDemandLinkedService** által meghatározott számítási szolgáltatáson fut.</span><span class="sxs-lookup"><span data-stu-id="aabe6-264">In the activity JSON, you specify that the Hive script runs on the compute specified by the **linkedServiceName** – **HDInsightOnDemandLinkedService**.</span></span>
4. <span data-ttu-id="aabe6-265">Mentse a **HiveActivity1.json** fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-265">Save the **HiveActivity1.json** file.</span></span>

### <a name="add-partitionweblogshql-and-inputlog-as-a-dependency"></a><span data-ttu-id="aabe6-266">A partitionweblogs.hql és az input.log fájl hozzáadása függőségként</span><span class="sxs-lookup"><span data-stu-id="aabe6-266">Add partitionweblogs.hql and input.log as a dependency</span></span>
1. <span data-ttu-id="aabe6-267">A **Solution Explorer** (Megoldáskezelő) ablakában kattintson a jobb gombbal a **Dependencies** (Függőségek) elemre, mutasson az **Add** (Hozzáadás) parancsra, és kattintson az **Existing Item** (Meglévő elem) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-267">Right-click **Dependencies** in the **Solution Explorer** window, point to **Add**, and click **Existing Item**.</span></span>  
2. <span data-ttu-id="aabe6-268">Lépjen a **C:\ADFGettingStarted** mappába, jelölje ki a **partitionweblogs.hql** és az **input.log** fájlt, majd kattintson az **Add** (Hozzáadás) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-268">Navigate to the **C:\ADFGettingStarted** and select **partitionweblogs.hql**, **input.log** files, and click **Add**.</span></span> <span data-ttu-id="aabe6-269">Ezt a két fájlt [Az oktatóanyag áttekintése](data-factory-build-your-first-pipeline.md) című cikk előfeltételeinek részeként hozta létre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-269">You created these two files as part of prerequisites from the [Tutorial Overview](data-factory-build-your-first-pipeline.md).</span></span>

<span data-ttu-id="aabe6-270">Amikor a következő lépésben közzéteszi a megoldást, a **partitionweblogs.hql** fájlt az `adfgetstarted` blob-tároló **script** mappájába tölti fel a rendszer.</span><span class="sxs-lookup"><span data-stu-id="aabe6-270">When you publish the solution in the next step, the **partitionweblogs.hql** file is uploaded to the **script** folder in the `adfgetstarted` blob container.</span></span>   

### <a name="publishdeploy-data-factory-entities"></a><span data-ttu-id="aabe6-271">Data Factory-entitások közzététele/üzembe helyezése</span><span class="sxs-lookup"><span data-stu-id="aabe6-271">Publish/deploy Data Factory entities</span></span>
<span data-ttu-id="aabe6-272">Ebben a lépésben a projektben lévő Data Factory-entitásokat (társított szolgáltatások, adatkészletek és folyamat) teszi közzé az Azure Data Factory szolgáltatásban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-272">In this step, you publish the Data Factory entities (linked services, datasets, and pipeline) in your project to the Azure Data Factory service.</span></span> <span data-ttu-id="aabe6-273">A közzétételi folyamatban megadja a data factory nevét.</span><span class="sxs-lookup"><span data-stu-id="aabe6-273">In the process of publishing, you specify the name for your data factory.</span></span> 

1. <span data-ttu-id="aabe6-274">A Solution Explorerben (Megoldáskezelőben) kattintson a jobb gombbal a projektre, majd kattintson a **Publish** (Közzététel) parancsra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-274">Right-click project in the Solution Explorer, and click **Publish**.</span></span>
2. <span data-ttu-id="aabe6-275">Ha megjelenik a **Sign in to your Microsoft account** (Bejelentkezés a Microsoft-fiókba) párbeszédpanel, adja meg az Azure-előfizetéssel rendelkező fiókja hitelesítő adatait, és kattintson a **sign in** (bejelentkezés) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-275">If you see **Sign in to your Microsoft account** dialog box, enter your credentials for the account that has Azure subscription, and click **sign in**.</span></span>
3. <span data-ttu-id="aabe6-276">A következő párbeszédpanelnek kell megjelennie:</span><span class="sxs-lookup"><span data-stu-id="aabe6-276">You should see the following dialog box:</span></span>

   ![Publish (Közzététel) párbeszédpanel](./media/data-factory-build-your-first-pipeline-using-vs/publish.png)
4. <span data-ttu-id="aabe6-278">A **Data Factory konfigurálási** lapján hajtsa végre a következő lépéseket:</span><span class="sxs-lookup"><span data-stu-id="aabe6-278">In the **Configure data factory** page, do the following steps:</span></span>

    ![Közzététel – Új data factory beállításai](media/data-factory-build-your-first-pipeline-using-vs/publish-new-data-factory.png)

   1. <span data-ttu-id="aabe6-280">Válassza a **Create New Data Factory** (Új data factory létrehozása) lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="aabe6-280">select **Create New Data Factory** option.</span></span>
   2. <span data-ttu-id="aabe6-281">Adja meg a data factory egyedi **nevét**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-281">Enter a unique **name** for the data factory.</span></span> <span data-ttu-id="aabe6-282">Például: **DataFactoryUsingVS09152016**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-282">For example: **DataFactoryUsingVS09152016**.</span></span> <span data-ttu-id="aabe6-283">A névnek globálisan egyedinek kell lennie.</span><span class="sxs-lookup"><span data-stu-id="aabe6-283">The name must be globally unique.</span></span>
   3. <span data-ttu-id="aabe6-284">A **Subscription** (Előfizetés) mezőben válassza ki a megfelelő előfizetést.</span><span class="sxs-lookup"><span data-stu-id="aabe6-284">Select the right subscription for the **Subscription** field.</span></span> 
        > [!IMPORTANT]
        > <span data-ttu-id="aabe6-285">Ha egy előfizetést sem lát, ellenőrizze, hogy olyan fiókkal jelentkezett-e be, amely rendszergazdája vagy társadminisztrátora az előfizetésnek.</span><span class="sxs-lookup"><span data-stu-id="aabe6-285">If you do not see any subscription, ensure that you logged in using an account that is an admin or co-admin of the subscription.</span></span>
   4. <span data-ttu-id="aabe6-286">Válassza ki a data factoryhoz az **erőforráscsoportot**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-286">Select the **resource group** for the data factory to be created.</span></span>
   5. <span data-ttu-id="aabe6-287">Válassza ki a data factoryhoz a **régiót**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-287">Select the **region** for the data factory.</span></span>
   6. <span data-ttu-id="aabe6-288">Kattintson a **Tovább** gombra a **Publish Items** (Elemek közzététele) oldalra való váltáshoz.</span><span class="sxs-lookup"><span data-stu-id="aabe6-288">Click **Next** to switch to the **Publish Items** page.</span></span> <span data-ttu-id="aabe6-289">(Ha a **Tovább** gomb le van tiltva, nyomja le a **TAB** billentyűt a Name (Név) mezőből való kilépéshez.)</span><span class="sxs-lookup"><span data-stu-id="aabe6-289">(Press **TAB** to move out of the Name field to if the **Next** button is disabled.)</span></span>

    > [!IMPORTANT]
    > <span data-ttu-id="aabe6-290">Ha a közzététel során a **Data factory name “DataFactoryUsingVS” is not available** (A „DataFactoryUsingVS” data factory-név nem érhető el) hibaüzenetet kapja, módosítsa a nevet (például: azÖnneveDataFactoryUsingVS).</span><span class="sxs-lookup"><span data-stu-id="aabe6-290">If you receive the error **Data factory name “DataFactoryUsingVS” is not available** when publishing, change the name (for example, yournameDataFactoryUsingVS).</span></span> <span data-ttu-id="aabe6-291">A Data Factory-összetevők elnevezési szabályait a [Data Factory - Naming Rules](data-factory-naming-rules.md) (Data Factory – Elnevezési szabályok) című témakörben találhatja.</span><span class="sxs-lookup"><span data-stu-id="aabe6-291">See [Data Factory - Naming Rules](data-factory-naming-rules.md) topic for naming rules for Data Factory artifacts.</span></span>   
1. <span data-ttu-id="aabe6-292">A **Publish Items** (Elemek közzététele) oldalon győződjön meg arról, hogy az összes Data Factory-entitás ki van jelölve, és kattintson a **Tovább** gombra a **Summary** (Összegzés) oldalra való váltáshoz.</span><span class="sxs-lookup"><span data-stu-id="aabe6-292">In the **Publish Items** page, ensure that all the Data Factories entities are selected, and click **Next** to switch to the **Summary** page.</span></span>

    ![Publish items (Elemek közzététele) oldal](media/data-factory-build-your-first-pipeline-using-vs/publish-items-page.png)     
2. <span data-ttu-id="aabe6-294">Tekintse át az összefoglalót, és kattintson a **Tovább** gombra az üzembehelyezési folyamat elindításához, és a **Deployment Status** (Üzembehelyezési állapot) megtekintéséhez.</span><span class="sxs-lookup"><span data-stu-id="aabe6-294">Review the summary and click **Next** to start the deployment process and view the **Deployment Status**.</span></span>

    ![Összefoglaló lap](media/data-factory-build-your-first-pipeline-using-vs/summary-page.png)
3. <span data-ttu-id="aabe6-296">A **Deployment Status** (Üzembehelyezési állapot) oldalon meg kell jelennie az üzembehelyezési folyamat állapotának.</span><span class="sxs-lookup"><span data-stu-id="aabe6-296">In the **Deployment Status** page, you should see the status of the deployment process.</span></span> <span data-ttu-id="aabe6-297">Miután befejeződött az üzembe helyezés, kattintson a Finish (Befejezés) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-297">Click Finish after the deployment is done.</span></span>

<span data-ttu-id="aabe6-298">Fontos tudnivalók:</span><span class="sxs-lookup"><span data-stu-id="aabe6-298">Important points to note:</span></span>

- <span data-ttu-id="aabe6-299">Ha a **This subscription is not registered to use namespace Microsoft.DataFactory** (Az előfizetés nem jogosult használni a Microsoft.DataFactory névteret) hibaüzenetet kapja, tegye a következők egyikét, és próbálkozzon újra a közzététellel:</span><span class="sxs-lookup"><span data-stu-id="aabe6-299">If you receive the error: **This subscription is not registered to use namespace Microsoft.DataFactory**, do one of the following and try publishing again:</span></span>
    - <span data-ttu-id="aabe6-300">Az Azure PowerShellben futtassa az alábbi parancsot a Data Factory-szolgáltató regisztrálásához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-300">In Azure PowerShell, run the following command to register the Data Factory provider.</span></span>
        ```PowerShell   
        Register-AzureRmResourceProvider -ProviderNamespace Microsoft.DataFactory
        ```
        <span data-ttu-id="aabe6-301">Az alábbi parancs futtatásával ellenőrizheti, hogy a Data Factory-szolgáltató regisztrálva van-e.</span><span class="sxs-lookup"><span data-stu-id="aabe6-301">You can run the following command to confirm that the Data Factory provider is registered.</span></span>

        ```PowerShell
        Get-AzureRmResourceProvider
        ```
    - <span data-ttu-id="aabe6-302">Az Azure-előfizetés használatával jelentkezzen be az [Azure Portalra](https://portal.azure.com), és navigáljon egy Data Factory panelre, vagy hozzon létre egy data factoryt az Azure Portalon.</span><span class="sxs-lookup"><span data-stu-id="aabe6-302">Login using the Azure subscription in to the [Azure portal](https://portal.azure.com) and navigate to a Data Factory blade (or) create a data factory in the Azure portal.</span></span> <span data-ttu-id="aabe6-303">Ezzel a művelettel automatikusan regisztrálja a szolgáltatót.</span><span class="sxs-lookup"><span data-stu-id="aabe6-303">This action automatically registers the provider for you.</span></span>
- <span data-ttu-id="aabe6-304">A data factory neve később DNS-névként regisztrálható, így nyilvánosan láthatóvá válhat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-304">The name of the data factory may be registered as a DNS name in the future and hence become publically visible.</span></span>
- <span data-ttu-id="aabe6-305">Data Factory-példányok létrehozásához az Azure-előfizetés rendszergazdájának vagy társadminisztrátorának kell lennie.</span><span class="sxs-lookup"><span data-stu-id="aabe6-305">To create Data Factory instances, you need to be an admin or co-admin of the Azure subscription</span></span>

### <a name="monitor-pipeline"></a><span data-ttu-id="aabe6-306">Folyamat figyelése</span><span class="sxs-lookup"><span data-stu-id="aabe6-306">Monitor pipeline</span></span>
<span data-ttu-id="aabe6-307">Ebben a lépésben a data factory Diagramnézete használatával figyeli a folyamatot.</span><span class="sxs-lookup"><span data-stu-id="aabe6-307">In this step, you monitor the pipeline using Diagram View of the data factory.</span></span> 

#### <a name="monitor-pipeline-using-diagram-view"></a><span data-ttu-id="aabe6-308">Folyamat figyelése diagramnézetben</span><span class="sxs-lookup"><span data-stu-id="aabe6-308">Monitor pipeline using Diagram View</span></span>
1. <span data-ttu-id="aabe6-309">Jelentkezzen be az [Azure Portalra](https://portal.azure.com/), és tegye a következőket:</span><span class="sxs-lookup"><span data-stu-id="aabe6-309">Log in to the [Azure portal](https://portal.azure.com/), do the following steps:</span></span>
   1. <span data-ttu-id="aabe6-310">Kattintson a **További szolgáltatások**, majd az **Adat-előállítók** elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-310">Click **More services** and click **Data factories**.</span></span>
       
        ![Data factoryk tallózása](./media/data-factory-build-your-first-pipeline-using-vs/browse-datafactories.png)
   2. <span data-ttu-id="aabe6-312">Válassza ki a data factory nevét a data factoryk listájából (például: **DataFactoryUsingVS09152016**).</span><span class="sxs-lookup"><span data-stu-id="aabe6-312">Select the name of your data factory (for example: **DataFactoryUsingVS09152016**) from the list of data factories.</span></span>
   
       ![A data factory kiválasztása](./media/data-factory-build-your-first-pipeline-using-vs/select-first-data-factory.png)
2. <span data-ttu-id="aabe6-314">A data factory kezdőlapján kattintson a **Diagram** lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-314">In the home page for your data factory, click **Diagram**.</span></span>

    ![Diagram csempe](./media/data-factory-build-your-first-pipeline-using-vs/diagram-tile.png)
3. <span data-ttu-id="aabe6-316">A diagramnézet áttekintést nyújt az oktatóanyagban használt folyamatokról és adatkészletekről.</span><span class="sxs-lookup"><span data-stu-id="aabe6-316">In the Diagram View, you see an overview of the pipelines, and datasets used in this tutorial.</span></span>

    ![Diagramnézet](./media/data-factory-build-your-first-pipeline-using-vs/diagram-view-2.png)
4. <span data-ttu-id="aabe6-318">A folyamat összes tevékenységének megtekintéséhez kattintson a jobb gombbal a folyamatra a diagramban, majd kattintson a Feldolgozási sor megnyitása elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-318">To view all activities in the pipeline, right-click pipeline in the diagram and click Open Pipeline.</span></span>

    ![Folyamat megnyitása menü](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-menu.png)
5. <span data-ttu-id="aabe6-320">Győződjön meg arról, hogy a HDInsightHive tevékenység megjelenik a folyamatban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-320">Confirm that you see the HDInsightHive activity in the pipeline.</span></span>

    ![Folyamat megnyitása nézet](./media/data-factory-build-your-first-pipeline-using-vs/open-pipeline-view.png)

    <span data-ttu-id="aabe6-322">Az előző nézethez való visszatéréshez az oldal tetején lévő navigációs menüben kattintson a **Data factory** elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-322">To navigate back to the previous view, click **Data factory** in the breadcrumb menu at the top.</span></span>
6. <span data-ttu-id="aabe6-323">A **diagramnézetben** kattintson duplán az **AzureBlobInput** adatkészletre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-323">In the **Diagram View**, double-click the dataset **AzureBlobInput**.</span></span> <span data-ttu-id="aabe6-324">Győződjön meg arról, hogy a szelet **Ready** (Kész) állapotú.</span><span class="sxs-lookup"><span data-stu-id="aabe6-324">Confirm that the slice is in **Ready** state.</span></span> <span data-ttu-id="aabe6-325">Eltarthat néhány percig, amíg a szelet Ready (Kész) állapotúként jelenik meg.</span><span class="sxs-lookup"><span data-stu-id="aabe6-325">It may take a couple of minutes for the slice to show up in Ready state.</span></span> <span data-ttu-id="aabe6-326">Ha ez azután sem történik meg, hogy vár néhány percet, ellenőrizze, hogy a megfelelő tárolóba (`adfgetstarted`) és mappába (`inputdata`) helyezte-e a bemeneti fájlt (input.log).</span><span class="sxs-lookup"><span data-stu-id="aabe6-326">If it does not happen after you wait for sometime, see if you have the input file (input.log) placed in the right container (`adfgetstarted`) and folder (`inputdata`).</span></span> <span data-ttu-id="aabe6-327">Arról is győződjön meg, hogy a bemeneti adatkészlet **external** (külső) tulajdonságának beállítása **true** (igaz).</span><span class="sxs-lookup"><span data-stu-id="aabe6-327">And, make sure that the **external** property on the input dataset is set to **true**.</span></span> 

   ![Kész állapotú bemeneti szelet](./media/data-factory-build-your-first-pipeline-using-vs/input-slice-ready.png)
7. <span data-ttu-id="aabe6-329">Kattintson az **X** elemre az **AzureBlobInput** panel bezárásához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-329">Click **X** to close **AzureBlobInput** blade.</span></span>
8. <span data-ttu-id="aabe6-330">A **diagramnézetben** kattintson duplán az **AzureBlobOutput** adatkészletre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-330">In the **Diagram View**, double-click the dataset **AzureBlobOutput**.</span></span> <span data-ttu-id="aabe6-331">Látni fogja, hogy a szelet feldolgozás alatt áll.</span><span class="sxs-lookup"><span data-stu-id="aabe6-331">You see that the slice that is currently being processed.</span></span>

   ![Adatkészlet](./media/data-factory-build-your-first-pipeline-using-vs/dataset-blade.png)
9. <span data-ttu-id="aabe6-333">A feldolgozás befejeztével a szelet **Ready** (Kész) állapotúra vált.</span><span class="sxs-lookup"><span data-stu-id="aabe6-333">When processing is done, you see the slice in **Ready** state.</span></span>

   > [!IMPORTANT]
   > <span data-ttu-id="aabe6-334">Az igény szerinti HDInsight-fürt létrehozása általában eltart egy ideig (körülbelül 20 percig).</span><span class="sxs-lookup"><span data-stu-id="aabe6-334">Creation of an on-demand HDInsight cluster usually takes sometime (approximately 20 minutes).</span></span> <span data-ttu-id="aabe6-335">Ezért a folyamat várhatóan **körülbelül 30 perc** alatt dolgozza fel a szeletet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-335">Therefore, expect the pipeline to take **approximately 30 minutes** to process the slice.</span></span>  
   
    ![Adatkészlet](./media/data-factory-build-your-first-pipeline-using-vs/dataset-slice-ready.png)    
10. <span data-ttu-id="aabe6-337">Ha a szelet **Kész** állapotú, a Blob Storage-tároló `adfgetstarted` tárolójában tekintse meg a `partitioneddata` mappát a kimeneti adatokért.</span><span class="sxs-lookup"><span data-stu-id="aabe6-337">When the slice is in **Ready** state, check the `partitioneddata` folder in the `adfgetstarted` container in your blob storage for the output data.</span></span>  

    ![kimeneti adatok](./media/data-factory-build-your-first-pipeline-using-vs/three-ouptut-files.png)
11. <span data-ttu-id="aabe6-339">A szelet részleteinek az **Adatszelet** panelen való megtekintéséhez kattintson a szeletre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-339">Click the slice to see details about it in a **Data slice** blade.</span></span>

    ![Adatszelet részletei](./media/data-factory-build-your-first-pipeline-using-vs/data-slice-details.png)  
12. <span data-ttu-id="aabe6-341">Kattintson egy tevékenységfuttatásra az **Activity runs list** (Tevékenységfuttatások listája) területen a tevékenységfuttatás (ebben az esetben Hive-tevékenység) részleteinek az **Activity run details** (Tevékenységfuttatás részletei) ablakban való megjelenítéséhez.</span><span class="sxs-lookup"><span data-stu-id="aabe6-341">Click an activity run in the **Activity runs list** to see details about an activity run (Hive activity in our scenario) in an **Activity run details** window.</span></span> 
  
    ![Tevékenységfuttatás részletei](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-blade.png)    

    <span data-ttu-id="aabe6-343">A naplófájlokban láthatja a végrehajtott Hive-lekérdezést és az állapotadatokat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-343">From the log files, you can see the Hive query that was executed and status information.</span></span> <span data-ttu-id="aabe6-344">A naplók hasznosak bármilyen hiba esetén a hibaelhárításban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-344">These logs are useful for troubleshooting any issues.</span></span>  

<span data-ttu-id="aabe6-345">A [Monitor datasets and pipeline](data-factory-monitor-manage-pipelines.md) (Adatkészletek és folyamatok figyelése) című cikkben útmutatást találhat arról, hogy hogyan használhatja az Azure Portalt az oktatóanyagban létrehozott folyamatok és adatkészletek figyeléséhez.</span><span class="sxs-lookup"><span data-stu-id="aabe6-345">See [Monitor datasets and pipeline](data-factory-monitor-manage-pipelines.md) for instructions on how to use the Azure portal to monitor the pipeline and datasets you have created in this tutorial.</span></span>

#### <a name="monitor-pipeline-using-monitor--manage-app"></a><span data-ttu-id="aabe6-346">Folyamat figyelése a Monitor & Manage alkalmazással</span><span class="sxs-lookup"><span data-stu-id="aabe6-346">Monitor pipeline using Monitor & Manage App</span></span>
<span data-ttu-id="aabe6-347">A folyamatok figyeléséhez a Monitor & Manage alkalmazást is használhatja.</span><span class="sxs-lookup"><span data-stu-id="aabe6-347">You can also use Monitor & Manage application to monitor your pipelines.</span></span> <span data-ttu-id="aabe6-348">Az alkalmazás használatával kapcsolatos részletes információkért olvassa el a [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md) (Azure Data Factory-folyamatok figyelése és felügyelete a Monitoring and Management használatával) című cikket.</span><span class="sxs-lookup"><span data-stu-id="aabe6-348">For detailed information about using this application, see [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

1. <span data-ttu-id="aabe6-349">Kattintson a Monitor & Manage csempére.</span><span class="sxs-lookup"><span data-stu-id="aabe6-349">Click Monitor & Manage tile.</span></span>

    ![Monitor & Manage csempe](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-tile.png)
2. <span data-ttu-id="aabe6-351">Meg kell jelennie a Monitor & Manage alkalmazásnak.</span><span class="sxs-lookup"><span data-stu-id="aabe6-351">You should see Monitor & Manage application.</span></span> <span data-ttu-id="aabe6-352">Módosítsa a **kezdési idő** és a **befejezési idő** értékét, hogy megfeleljen a folyamat kezdési (04-01-2016 12:00 AM) és befejezési (04-02-2016 12:00 AM) idejének, és kattintson az **Apply** (Alkalmaz) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-352">Change the **Start time** and **End time** to match start (04-01-2016 12:00 AM) and end times (04-02-2016 12:00 AM) of your pipeline, and click **Apply**.</span></span>

    ![Monitor & Manage alkalmazás](./media/data-factory-build-your-first-pipeline-using-vs/monitor-and-manage-app.png)
3. <span data-ttu-id="aabe6-354">Ha látni szeretné egy tevékenységablak részleteit, jelölje ki az **Activity Windows** (Tevékenységablakok) listában.</span><span class="sxs-lookup"><span data-stu-id="aabe6-354">To see details about an activity window, select it in the **Activity Windows list** to see details about it.</span></span>
    <span data-ttu-id="aabe6-355">![Tevékenységablakok részletei](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)</span><span class="sxs-lookup"><span data-stu-id="aabe6-355">![Activity window details](./media/data-factory-build-your-first-pipeline-using-vs/activity-window-details.png)</span></span>

> [!IMPORTANT]
> <span data-ttu-id="aabe6-356">A szelet sikeres feldolgozásakor a rendszer törli a bemeneti fájlt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-356">The input file gets deleted when the slice is processed successfully.</span></span> <span data-ttu-id="aabe6-357">Ezért ha újra szeretné futtatni a szeletet, vagy újra el szeretné végezni az oktatóanyagot, töltse fel a bemeneti fájlt (input.log) az `adfgetstarted` tároló `inputdata` mappájába.</span><span class="sxs-lookup"><span data-stu-id="aabe6-357">Therefore, if you want to rerun the slice or do the tutorial again, upload the input file (input.log) to the `inputdata` folder of the `adfgetstarted` container.</span></span>

### <a name="additional-notes"></a><span data-ttu-id="aabe6-358">További megjegyzések</span><span class="sxs-lookup"><span data-stu-id="aabe6-358">Additional notes</span></span>
- <span data-ttu-id="aabe6-359">A data factory egy vagy több folyamattal rendelkezhet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-359">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="aabe6-360">A folyamaton belül egy vagy több tevékenység lehet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-360">A pipeline can have one or more activities in it.</span></span> <span data-ttu-id="aabe6-361">Ilyen például a másolási tevékenység, amely adatokat másol a forrásadattárból a céladattárba, és a HDInsight Hive tevékenység, amely egy Hive-szkriptet futtat a bemeneti adatok átalakításához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-361">For example, a Copy Activity to copy data from a source to a destination data store and a HDInsight Hive activity to run a Hive script to transform input data.</span></span> <span data-ttu-id="aabe6-362">A másolási tevékenység által támogatott forrásokért és fogadókért tekintse meg a [támogatott adattárak](data-factory-data-movement-activities.md#supported-data-stores-and-formats) című részt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-362">See [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats) for all the sources and sinks supported by the Copy Activity.</span></span> <span data-ttu-id="aabe6-363">A Data Factory által támogatott számítási szolgáltatások listájáért tekintse meg a [számítási társított szolgáltatások](data-factory-compute-linked-services.md) című részt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-363">See [compute linked services](data-factory-compute-linked-services.md) for the list of compute services supported by Data Factory.</span></span>
- <span data-ttu-id="aabe6-364">A társított szolgáltatások adattárakat vagy számítási szolgáltatásokat társítanak az Azure data factoryhez.</span><span class="sxs-lookup"><span data-stu-id="aabe6-364">Linked services link data stores or compute services to an Azure data factory.</span></span> <span data-ttu-id="aabe6-365">A másolási tevékenység által támogatott forrásokért és fogadókért tekintse meg a [támogatott adattárak](data-factory-data-movement-activities.md#supported-data-stores-and-formats) című részt.</span><span class="sxs-lookup"><span data-stu-id="aabe6-365">See [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats) for all the sources and sinks supported by the Copy Activity.</span></span> <span data-ttu-id="aabe6-366">A Data Factory által támogatott számítási szolgáltatások és a futtatható [átalakítási tevékenységek](data-factory-compute-linked-services.md) listáját a [számítási társított szolgáltatásokat](data-factory-data-transformation-activities.md) ismertető részben találja.</span><span class="sxs-lookup"><span data-stu-id="aabe6-366">See [compute linked services](data-factory-compute-linked-services.md) for the list of compute services supported by Data Factory and [transformation activities](data-factory-data-transformation-activities.md) that can run on them.</span></span>
- <span data-ttu-id="aabe6-367">Az Azure Storage társított szolgáltatás definíciójában használt JSON-tulajdonságokkal kapcsolatos információk: [Adatok áthelyezése az Azure Blobból vagy az Azure Blobba](data-factory-azure-blob-connector.md#azure-storage-linked-service).</span><span class="sxs-lookup"><span data-stu-id="aabe6-367">See [Move data from/to Azure Blob](data-factory-azure-blob-connector.md#azure-storage-linked-service) for details about JSON properties used in the Azure Storage linked service definition.</span></span>
- <span data-ttu-id="aabe6-368">Igény szerinti HDInsight-fürt helyett saját HDInsight-fürtöt is használhat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-368">You could use your own HDInsight cluster instead of using an on-demand HDInsight cluster.</span></span> <span data-ttu-id="aabe6-369">További információ: [Compute Linked Services](data-factory-compute-linked-services.md) (Számítási társított szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="aabe6-369">See [Compute Linked Services](data-factory-compute-linked-services.md) for details.</span></span>
-  <span data-ttu-id="aabe6-370">A Data Factory létrehoz egy **Linux-alapú** HDInsight-fürtöt az előző JSON-fájllal.</span><span class="sxs-lookup"><span data-stu-id="aabe6-370">The Data Factory creates a **Linux-based** HDInsight cluster for you with the preceding JSON.</span></span> <span data-ttu-id="aabe6-371">További információkért lásd: [On-demand HDInsight Linked Service](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) (Igény szerinti HDInsight társított szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="aabe6-371">See [On-demand HDInsight Linked Service](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) for details.</span></span>
- <span data-ttu-id="aabe6-372">A HDInsight-fürt létrehoz egy **alapértelmezett tárolót** a JSON-fájlban megadott blobtárolóban (linkedServiceName).</span><span class="sxs-lookup"><span data-stu-id="aabe6-372">The HDInsight cluster creates a **default container** in the blob storage you specified in the JSON (linkedServiceName).</span></span> <span data-ttu-id="aabe6-373">A fürt törlésekor a HDInsight nem törli ezt a tárolót.</span><span class="sxs-lookup"><span data-stu-id="aabe6-373">HDInsight does not delete this container when the cluster is deleted.</span></span> <span data-ttu-id="aabe6-374">Ez a működésmód szándékos.</span><span class="sxs-lookup"><span data-stu-id="aabe6-374">This behavior is by design.</span></span> <span data-ttu-id="aabe6-375">Igény szerinti HDInsight társított szolgáltatás esetén a rendszer a szeletek feldolgozásakor mindig létrehoz egy HDInsight-fürtöt, kivéve, ha van meglévő élő fürt (timeToLive).</span><span class="sxs-lookup"><span data-stu-id="aabe6-375">With on-demand HDInsight linked service, a HDInsight cluster is created every time a slice is processed unless there is an existing live cluster (timeToLive).</span></span> <span data-ttu-id="aabe6-376">A fürt automatikusan törlődik a feldolgozás megtörténtekor.</span><span class="sxs-lookup"><span data-stu-id="aabe6-376">The cluster is automatically deleted when the processing is done.</span></span>
    
    <span data-ttu-id="aabe6-377">Ahogy egyre több szelet lesz feldolgozva, egyre több tároló jelenik meg az Azure Blob Storage-tárban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-377">As more slices are processed, you see many containers in your Azure blob storage.</span></span> <span data-ttu-id="aabe6-378">Ha nincs szüksége rájuk a feladatokkal kapcsolatos hibaelhárításhoz, törölheti őket a tárolási költségek csökkentése érdekében.</span><span class="sxs-lookup"><span data-stu-id="aabe6-378">If you do not need them for troubleshooting of the jobs, you may want to delete them to reduce the storage cost.</span></span> <span data-ttu-id="aabe6-379">A tárolók neve a következő mintát követi: `adf**yourdatafactoryname**-**linkedservicename**-datetimestamp`.</span><span class="sxs-lookup"><span data-stu-id="aabe6-379">The names of these containers follow a pattern: `adf**yourdatafactoryname**-**linkedservicename**-datetimestamp`.</span></span> <span data-ttu-id="aabe6-380">Az Azure Blob Storage-tárból olyan eszközökkel törölheti a tárolókat, mint például a [Microsoft Storage Explorer](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="aabe6-380">Use tools such as [Microsoft Storage Explorer](http://storageexplorer.com/) to delete containers in your Azure blob storage.</span></span>
- <span data-ttu-id="aabe6-381">Jelenleg a kimeneti adatkészlet vezérli az ütemezést, ezért kimeneti adatkészletet akkor is létre kell hoznia, ha a tevékenység nem állít elő semmilyen kimenetet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-381">Currently, output dataset is what drives the schedule, so you must create an output dataset even if the activity does not produce any output.</span></span> <span data-ttu-id="aabe6-382">Ha a tevékenység nem fogad semmilyen bemenetet, kihagyhatja a bemeneti adatkészlet létrehozását.</span><span class="sxs-lookup"><span data-stu-id="aabe6-382">If the activity doesn't take any input, you can skip creating the input dataset.</span></span> 
- <span data-ttu-id="aabe6-383">Ez az oktatóanyag nem tartalmazza az adatok Azure Data Factory használatával történő másolásának leírását.</span><span class="sxs-lookup"><span data-stu-id="aabe6-383">This tutorial does not show how copy data by using Azure Data Factory.</span></span> <span data-ttu-id="aabe6-384">Az adatok Azure Data Factory használatával történő másolásának útmutatásáért olvassa el [az adatok Blob Storage-ból SQL Database-be történő másolását ismertető oktatóanyagot](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="aabe6-384">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>


## <a name="use-server-explorer-to-view-data-factories"></a><span data-ttu-id="aabe6-385">A Kiszolgókezelő használata data factoryk megtekintéséhez</span><span class="sxs-lookup"><span data-stu-id="aabe6-385">Use Server Explorer to view data factories</span></span>
1. <span data-ttu-id="aabe6-386">A **Visual Studio** menüjében kattintson a **View** (Megtekintés), majd a **Server Explorer** (Kiszolgálókezelő) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-386">In **Visual Studio**, click **View** on the menu, and click **Server Explorer**.</span></span>
2. <span data-ttu-id="aabe6-387">A Server Explorer (Kiszolgálókezelő) ablakban bontsa ki az **Azure**, majd a **Data Factory** elemet.</span><span class="sxs-lookup"><span data-stu-id="aabe6-387">In the Server Explorer window, expand **Azure** and expand **Data Factory**.</span></span> <span data-ttu-id="aabe6-388">Ha megjelenik a **Sign in to Visual Studio** (Jelentkezzen be a Visual Studióba) üzenet, adja meg az Azure-előfizetéséhez társított **fiókot**, és kattintson a **Continue** (Folytatás) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-388">If you see **Sign in to Visual Studio**, enter the **account** associated with your Azure subscription and click **Continue**.</span></span> <span data-ttu-id="aabe6-389">Adja meg a **jelszót**, és kattintson a **Sign in** (Bejelentkezés) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-389">Enter **password**, and click **Sign in**.</span></span> <span data-ttu-id="aabe6-390">A Visual Studio megpróbálja lekérni az információkat az előfizetésében elérhető összes Azure data factoryről.</span><span class="sxs-lookup"><span data-stu-id="aabe6-390">Visual Studio tries to get information about all Azure data factories in your subscription.</span></span> <span data-ttu-id="aabe6-391">Ennek a műveletnek az állapota a **Data Factory Task List** (Data Factory-feladatlista) ablakban jelenik meg.</span><span class="sxs-lookup"><span data-stu-id="aabe6-391">You see the status of this operation in the **Data Factory Task List** window.</span></span>

    ![Server Explorer (Kiszolgálókezelő)](./media/data-factory-build-your-first-pipeline-using-vs/server-explorer.png)
3. <span data-ttu-id="aabe6-393">Ha egy meglévő data factory alapján szeretne létrehozni Visual Studio-projektet, kattintson a jobb gombbal egy dara factoryre, és válassza az **Export Data Factory to New Project** (Data factory exportálása új projektbe) lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="aabe6-393">You can right-click a data factory, and select **Export Data Factory to New Project** to create a Visual Studio project based on an existing data factory.</span></span>

    ![Export data factory (Data factory exportálása) menüelem](./media/data-factory-build-your-first-pipeline-using-vs/export-data-factory-menu.png)

## <a name="update-data-factory-tools-for-visual-studio"></a><span data-ttu-id="aabe6-395">Visual Studióhoz készült Data Factory-eszközök frissítése</span><span class="sxs-lookup"><span data-stu-id="aabe6-395">Update Data Factory tools for Visual Studio</span></span>
<span data-ttu-id="aabe6-396">A Visual Studióhoz készült Data Factory-eszközök frissítéséhez tegye a következőket:</span><span class="sxs-lookup"><span data-stu-id="aabe6-396">To update Azure Data Factory tools for Visual Studio, do the following steps:</span></span>

1. <span data-ttu-id="aabe6-397">Kattintson a menüben a **Tools** (Eszközök) elemre, és válassza az **Extensions and Updates** (Bővítmények és frissítések) lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="aabe6-397">Click **Tools** on the menu and select **Extensions and Updates**.</span></span>
2. <span data-ttu-id="aabe6-398">A bal oldali panelen válassza az **Updates** (Frissítések) elemet, majd válassza a **Visual Studio Gallery** (Visual Studio-gyűjtemény) lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="aabe6-398">Select **Updates** in the left pane and then select **Visual Studio Gallery**.</span></span>
3. <span data-ttu-id="aabe6-399">Válassza az **Azure Data Factory tools for Visual Studio** lehetőséget, és kattintson az **Update** (Frissítés) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-399">Select **Azure Data Factory tools for Visual Studio** and click **Update**.</span></span> <span data-ttu-id="aabe6-400">Ha nem látja ezt a bejegyzést, már rendelkezik az eszközök legújabb verziójával.</span><span class="sxs-lookup"><span data-stu-id="aabe6-400">If you do not see this entry, you already have the latest version of the tools.</span></span>

## <a name="use-configuration-files"></a><span data-ttu-id="aabe6-401">Konfigurációs fájlok használata</span><span class="sxs-lookup"><span data-stu-id="aabe6-401">Use configuration files</span></span>
<span data-ttu-id="aabe6-402">A Visual Studióban konfigurációs fájlokat használhat, ha az egyes környezetekhez eltérően szeretné konfigurálni a társított szolgáltatások/táblák/folyamatok tulajdonságait.</span><span class="sxs-lookup"><span data-stu-id="aabe6-402">You can use configuration files in Visual Studio to configure properties for linked services/tables/pipelines differently for each environment.</span></span>

<span data-ttu-id="aabe6-403">Használja például az alábbi JSON-definíciót egy Azure Storage társított szolgáltatáshoz.</span><span class="sxs-lookup"><span data-stu-id="aabe6-403">Consider the following JSON definition for an Azure Storage linked service.</span></span> <span data-ttu-id="aabe6-404">A **connectionString** tulajdonság accountname és accountkey értékeit annak a környezetnek (fejlesztői/teszt/éles) megfelelően adja meg, amelyikben üzembe helyezi a Data Factory-entitásokat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-404">To specify **connectionString** with different values for accountname and accountkey based on the environment (Dev/Test/Production) to which you are deploying Data Factory entities.</span></span> <span data-ttu-id="aabe6-405">Az ilyen működést úgy érheti el, hogy minden környezethez külön konfigurációs fájlt használ.</span><span class="sxs-lookup"><span data-stu-id="aabe6-405">You can achieve this behavior by using separate configuration file for each environment.</span></span>

```json
{
    "name": "StorageLinkedService",
    "properties": {
        "type": "AzureStorage",
        "description": "",
        "typeProperties": {
            "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
        }
    }
}
```

### <a name="add-a-configuration-file"></a><span data-ttu-id="aabe6-406">Konfigurációs fájl hozzáadása</span><span class="sxs-lookup"><span data-stu-id="aabe6-406">Add a configuration file</span></span>
<span data-ttu-id="aabe6-407">Adjon hozzá konfigurációs fájlt az egyes környezetekhez a következő lépések végrehajtásával:</span><span class="sxs-lookup"><span data-stu-id="aabe6-407">Add a configuration file for each environment by performing the following steps:</span></span>   

1. <span data-ttu-id="aabe6-408">A Visual Studio-megoldásban kattintson a jobb gombbal a Data Factory-projektre, mutasson az **Add** (Hozzáadás) elemre, és kattintson a **New Item** (Új elem) lehetőségre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-408">Right-click the Data Factory project in your Visual Studio solution, point to **Add**, and click **New item**.</span></span>
2. <span data-ttu-id="aabe6-409">A telepített sablonok bal oldali listájában válassza a **Config** elemet, jelölje ki a **Configuration File** (Konfigurációs fájl) lehetőséget, adja meg a konfigurációs fájl **nevét**, majd kattintson az **Add** (Hozzáadás) elemre.</span><span class="sxs-lookup"><span data-stu-id="aabe6-409">Select **Config** from the list of installed templates on the left, select **Configuration File**, enter a **name** for the configuration file, and click **Add**.</span></span>

    ![Konfigurációs fájl hozzáadása](./media/data-factory-build-your-first-pipeline-using-vs/add-config-file.png)
3. <span data-ttu-id="aabe6-411">Adja meg a konfigurációs paramétereket és az értéküket az alábbi formátumban:</span><span class="sxs-lookup"><span data-stu-id="aabe6-411">Add configuration parameters and their values in the following format:</span></span>

    ```json
    {
        "$schema": "http://datafactories.schema.management.azure.com/vsschemas/V1/Microsoft.DataFactory.Config.json",
        "AzureStorageLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
            }
        ],
        "AzureSqlLinkedService1": [
            {
                "name": "$.properties.typeProperties.connectionString",
                "value":  "Server=tcp:spsqlserver.database.windows.net,1433;Database=spsqldb;User ID=spelluru;Password=Sowmya123;Trusted_Connection=False;Encrypt=True;Connection Timeout=30"
            }
        ]
    }
    ```

    <span data-ttu-id="aabe6-412">Ez a példa konfigurálja egy Azure Storage társított szolgáltatás és egy Azure SQL társított szolgáltatás connectionString tulajdonságát.</span><span class="sxs-lookup"><span data-stu-id="aabe6-412">This example configures connectionString property of an Azure Storage linked service and an Azure SQL linked service.</span></span> <span data-ttu-id="aabe6-413">Figyelje meg, hogy a névmegadás szintaxisa a [JsonPath](http://goessner.net/articles/JsonPath/).</span><span class="sxs-lookup"><span data-stu-id="aabe6-413">Notice that the syntax for specifying name is [JsonPath](http://goessner.net/articles/JsonPath/).</span></span>   

    <span data-ttu-id="aabe6-414">Ha a JSON-fájlban szerepel egy olyan tulajdonság, amely értékek tömbjével rendelkezik a következő kódban látható módon:</span><span class="sxs-lookup"><span data-stu-id="aabe6-414">If JSON has a property that has an array of values as shown in the following code:</span></span>  

    ```json
    "structure": [
          {
              "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
        }
    ],
    ```

    <span data-ttu-id="aabe6-415">Konfigurálja a tulajdonságokat a következő konfigurációs fájlban látható módon (használjon nulláról induló indexelést):</span><span class="sxs-lookup"><span data-stu-id="aabe6-415">Configure properties as shown in the following configuration file (use zero-based indexing):</span></span>

    ```json
    {
        "name": "$.properties.structure[0].name",
        "value": "FirstName"
    }
    {
        "name": "$.properties.structure[0].type",
        "value": "String"
    }
    {
        "name": "$.properties.structure[1].name",
        "value": "LastName"
    }
    {
        "name": "$.properties.structure[1].type",
        "value": "String"
    }
    ```

### <a name="property-names-with-spaces"></a><span data-ttu-id="aabe6-416">Tulajdonságnevek szóközökkel</span><span class="sxs-lookup"><span data-stu-id="aabe6-416">Property names with spaces</span></span>
<span data-ttu-id="aabe6-417">Ha egy tulajdonságnév szóközöket tartalmaz, használjon szögletes zárójeleket az alábbi példában látható módon (Adatbázis-kiszolgáló neve):</span><span class="sxs-lookup"><span data-stu-id="aabe6-417">If a property name has spaces in it, use square brackets as shown in the following example (Database server name):</span></span>

```json
 {
     "name": "$.properties.activities[1].typeProperties.webServiceParameters.['Database server name']",
     "value": "MyAsqlServer.database.windows.net"
 }
```

### <a name="deploy-solution-using-a-configuration"></a><span data-ttu-id="aabe6-418">Megoldás üzembe helyezése konfiguráció használatával</span><span class="sxs-lookup"><span data-stu-id="aabe6-418">Deploy solution using a configuration</span></span>
<span data-ttu-id="aabe6-419">Amikor Azure Data Factory-entitásokat tesz közzé a Visual Studióban, megadhatja azt a konfigurációt, amelyet a közzétételi művelethez szeretne használni.</span><span class="sxs-lookup"><span data-stu-id="aabe6-419">When you are publishing Azure Data Factory entities in VS, you can specify the configuration that you want to use for that publishing operation.</span></span>

<span data-ttu-id="aabe6-420">Entitások közzététele Azure Data Factory-projektben konfigurációs fájl használatával:</span><span class="sxs-lookup"><span data-stu-id="aabe6-420">To publish entities in an Azure Data Factory project using configuration file:</span></span>   

1. <span data-ttu-id="aabe6-421">Kattintson a jobb gombbal a Data Factory projektre, majd kattintson a **Publish** (Közzététel) elemre a **Publish Items** (Elemek közzététele) párbeszédpanel megjelenítéséhez.</span><span class="sxs-lookup"><span data-stu-id="aabe6-421">Right-click Data Factory project and click **Publish** to see the **Publish Items** dialog box.</span></span>
2. <span data-ttu-id="aabe6-422">Válasszon ki egy meglévő data factoryt, vagy adja meg az értékeket egy új data factory létrehozásához a **Configure data factory** (Data factory konfigurálása) oldalon, és kattintson a **Next** (Tovább) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-422">Select an existing data factory or specify values for creating a data factory on the **Configure data factory** page, and click **Next**.</span></span>   
3. <span data-ttu-id="aabe6-423">A **Publish Items** (Elemek közzététele) oldalon megjelenik egy legördülő lista a **Select Deployment Config** (Üzembehelyezési konfiguráció kiválasztása) mező elérhető beállításaival.</span><span class="sxs-lookup"><span data-stu-id="aabe6-423">On the **Publish Items** page: you see a drop-down list with available configurations for the **Select Deployment Config** field.</span></span>

    ![Konfigurációs fájl kiválasztása](./media/data-factory-build-your-first-pipeline-using-vs/select-config-file.png)
4. <span data-ttu-id="aabe6-425">Válassza ki a használni kívánt **konfigurációs fájlt**, és kattintson a **Next** (Tovább) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-425">Select the **configuration file** that you would like to use and click **Next**.</span></span>
5. <span data-ttu-id="aabe6-426">Győződjön meg arról, hogy a JSON-fájl neve megjelenik a **Summary** (Összegzés) oldalon, és kattintson a **Next** (Tovább) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-426">Confirm that you see the name of JSON file in the **Summary** page and click **Next**.</span></span>
6. <span data-ttu-id="aabe6-427">Miután befejeződött az üzembehelyezési művelet, kattintson a **Finish** (Befejezés) gombra.</span><span class="sxs-lookup"><span data-stu-id="aabe6-427">Click **Finish** after the deployment operation is finished.</span></span>

<span data-ttu-id="aabe6-428">Az üzembe helyezéskor a rendszer a konfigurációs fájlban szereplő értékek alapján beállítja a JSON-fájlokban szereplő tulajdonságok értékeit, mielőtt üzembe helyezné az entitásokat az Azure Data Factoryban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-428">When you deploy, the values from the configuration file are used to set values for properties in the JSON files before the entities are deployed to Azure Data Factory service.</span></span>   

## <a name="use-azure-key-vault"></a><span data-ttu-id="aabe6-429">Az Azure Key Vault használata</span><span class="sxs-lookup"><span data-stu-id="aabe6-429">Use Azure Key Vault</span></span>
<span data-ttu-id="aabe6-430">A bizalmas adatok, például kapcsolati karakterláncok véglegesítése a kódtárban ellenjavallt, és gyakran a biztonsági szabályzatba ütközik.</span><span class="sxs-lookup"><span data-stu-id="aabe6-430">It is not advisable and often against security policy to commit sensitive data such as connection strings to the code repository.</span></span> <span data-ttu-id="aabe6-431">A bizalmas adatok az Azure Key Vaultban való tárolásának és a Data Factory-entitások közzétételekor való használatának elsajátításához lásd az [ADF Secure Publish](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ADFSecurePublish) mintát a Githubon.</span><span class="sxs-lookup"><span data-stu-id="aabe6-431">See [ADF Secure Publish](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/ADFSecurePublish) sample on GitHub to learn about storing sensitive information in Azure Key Vault and using it while publishing Data Factory entities.</span></span> <span data-ttu-id="aabe6-432">A Visual Studio Secure Publish (Biztonságos közzététel) bővítménye lehetővé teszi a titkos kulcsok a Key Vaultban való tárolását, és csak hivatkozások meghatározását azokra a társított szolgáltatásokban/telepítési konfigurációkban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-432">The Secure Publish extension for Visual Studio allows the secrets to be stored in Key Vault and only references to them are specified in linked services/ deployment configurations.</span></span> <span data-ttu-id="aabe6-433">A hivatkozások feloldására az Azure Data Factory-entitások Azure-ban való közzétételekor kerül sor.</span><span class="sxs-lookup"><span data-stu-id="aabe6-433">These references are resolved when you publish Data Factory entities to Azure.</span></span> <span data-ttu-id="aabe6-434">Ezen fájlok ekkor a titkos kulcsok közzététele nélkül véglegesíthetők a forrástárházban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-434">These files can then be committed to source repository without exposing any secrets.</span></span>

## <a name="summary"></a><span data-ttu-id="aabe6-435">Összefoglalás</span><span class="sxs-lookup"><span data-stu-id="aabe6-435">Summary</span></span>
<span data-ttu-id="aabe6-436">Az oktatóanyag során létrehozott egy Azure data factoryt, amely egy HDInsight Hadoop-fürtön futtatott Hive-parancsfájllal dolgozza fel az adatokat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-436">In this tutorial, you created an Azure data factory to process data by running Hive script on a HDInsight hadoop cluster.</span></span> <span data-ttu-id="aabe6-437">Az Azure Portal Data Factory Editor eszközét használta a következő lépések végrehajtásához:</span><span class="sxs-lookup"><span data-stu-id="aabe6-437">You used the Data Factory Editor in the Azure portal to do the following steps:</span></span>  

1. <span data-ttu-id="aabe6-438">Létrehozott egy Azure **data factoryt**.</span><span class="sxs-lookup"><span data-stu-id="aabe6-438">Created an Azure **data factory**.</span></span>
2. <span data-ttu-id="aabe6-439">Létrehozott két **társított szolgáltatást**:</span><span class="sxs-lookup"><span data-stu-id="aabe6-439">Created two **linked services**:</span></span>
   1. <span data-ttu-id="aabe6-440">Az **Azure Storage** társított szolgáltatást, amely a bemeneti és kimeneti adatokat tároló Azure blob-tárolót társítja a data factoryval.</span><span class="sxs-lookup"><span data-stu-id="aabe6-440">**Azure Storage** linked service to link your Azure blob storage that holds input/output files to the data factory.</span></span>
   2. <span data-ttu-id="aabe6-441">Az **Azure HDInsight** igény szerinti társított szolgáltatást, amely egy igény szerinti HDInsight Hadoop-fürtöt társít a data factoryval.</span><span class="sxs-lookup"><span data-stu-id="aabe6-441">**Azure HDInsight** on-demand linked service to link an on-demand HDInsight Hadoop cluster to the data factory.</span></span> <span data-ttu-id="aabe6-442">Az Azure Data Factory létrehoz egy HDInsight Hadoop-fürtöt, amely igény szerint dolgozza fel a bemeneti adatokat és állítja elő a kimeneti adatokat.</span><span class="sxs-lookup"><span data-stu-id="aabe6-442">Azure Data Factory creates a HDInsight Hadoop cluster just-in-time to process input data and produce output data.</span></span>
3. <span data-ttu-id="aabe6-443">Létrehozott két **adatkészletet**, amelyek leírják a bemeneti és kimeneti adatokat az adatcsatorna HDInsight Hive-tevékenysége számára.</span><span class="sxs-lookup"><span data-stu-id="aabe6-443">Created two **datasets**, which describe input and output data for HDInsight Hive activity in the pipeline.</span></span>
4. <span data-ttu-id="aabe6-444">Létrehozott egy **folyamatot** egy **HDInsight Hive**-tevékenységgel.</span><span class="sxs-lookup"><span data-stu-id="aabe6-444">Created a **pipeline** with a **HDInsight Hive** activity.</span></span>  

## <a name="next-steps"></a><span data-ttu-id="aabe6-445">Következő lépések</span><span class="sxs-lookup"><span data-stu-id="aabe6-445">Next Steps</span></span>
<span data-ttu-id="aabe6-446">Az oktatóanyag során létrehozott egy folyamatot egy adatátalakítási tevékenységgel (HDInsight-tevékenység), amely Hive-parancsfájlt futtat egy igény szerinti HDInsight-fürtön.</span><span class="sxs-lookup"><span data-stu-id="aabe6-446">In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand HDInsight cluster.</span></span> <span data-ttu-id="aabe6-447">Ha tudni szeretné, hogyan használhatja a Másolás tevékenységet az adatok Azure-blobból Azure SQL Database adatbázisba történő másolásához, tekintse meg a következő cikket: [Tutorial: Copy data from an Azure blob to Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) (Oktatóanyag: adatok másolása Azure-blobból Azure SQL Database adatbázisba).</span><span class="sxs-lookup"><span data-stu-id="aabe6-447">To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see [Tutorial: Copy data from an Azure blob to Azure SQL](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>

<span data-ttu-id="aabe6-448">Összefűzhet két tevékenységet (vagyis egymás után futtathatja őket), ha az egyik tevékenység kimeneti adatkészletét a másik tevékenység bemeneti adatkészleteként állítja be.</span><span class="sxs-lookup"><span data-stu-id="aabe6-448">You can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="aabe6-449">Lásd [a Data Factorybeli ütemezést és végrehajtást](data-factory-scheduling-and-execution.md) ismertető cikket.</span><span class="sxs-lookup"><span data-stu-id="aabe6-449">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 


## <a name="see-also"></a><span data-ttu-id="aabe6-450">Lásd még:</span><span class="sxs-lookup"><span data-stu-id="aabe6-450">See Also</span></span>
| <span data-ttu-id="aabe6-451">Témakör</span><span class="sxs-lookup"><span data-stu-id="aabe6-451">Topic</span></span> | <span data-ttu-id="aabe6-452">Leírás</span><span class="sxs-lookup"><span data-stu-id="aabe6-452">Description</span></span> |
|:--- |:--- |
| [<span data-ttu-id="aabe6-453">Folyamatok</span><span class="sxs-lookup"><span data-stu-id="aabe6-453">Pipelines</span></span>](data-factory-create-pipelines.md) |<span data-ttu-id="aabe6-454">Ebből a cikkből megismerheti az Azure Data Factory folyamatait és tevékenységeit, és megtudhatja, hogyan hozhat létre velük teljes körű, adatvezérelt munkafolyamatokat saját forgatókönyvéhez vagy vállalkozásához.</span><span class="sxs-lookup"><span data-stu-id="aabe6-454">This article helps you understand pipelines and activities in Azure Data Factory and how to use them to construct data-driven workflows for your scenario or business.</span></span> |
| [<span data-ttu-id="aabe6-455">Adatkészletek</span><span class="sxs-lookup"><span data-stu-id="aabe6-455">Datasets</span></span>](data-factory-create-datasets.md) |<span data-ttu-id="aabe6-456">Ennek a cikknek a segítségével megismerheti az adatkészleteket az Azure Data Factoryban.</span><span class="sxs-lookup"><span data-stu-id="aabe6-456">This article helps you understand datasets in Azure Data Factory.</span></span> |
| [<span data-ttu-id="aabe6-457">Adatátalakítási tevékenységek</span><span class="sxs-lookup"><span data-stu-id="aabe6-457">Data Transformation Activities</span></span>](data-factory-data-transformation-activities.md) |<span data-ttu-id="aabe6-458">Ez a cikk felsorolja az Azure Data Factory által támogatott adatátalakítási tevékenységeket (mint például a jelen oktatóanyagban használt HDInsight Hive-átalakítás).</span><span class="sxs-lookup"><span data-stu-id="aabe6-458">This article provides a list of data transformation activities (such as HDInsight Hive transformation you used in this tutorial) supported by Azure Data Factory.</span></span> |
| [<span data-ttu-id="aabe6-459">Ütemezés és végrehajtás</span><span class="sxs-lookup"><span data-stu-id="aabe6-459">Scheduling and execution</span></span>](data-factory-scheduling-and-execution.md) |<span data-ttu-id="aabe6-460">Ez a cikk ismerteti az Azure Data Factory-alkalmazásmodell ütemezési és végrehajtási aspektusait.</span><span class="sxs-lookup"><span data-stu-id="aabe6-460">This article explains the scheduling and execution aspects of Azure Data Factory application model.</span></span> |
| [<span data-ttu-id="aabe6-461">Folyamatok figyelése és felügyelete a Monitoring App használatával</span><span class="sxs-lookup"><span data-stu-id="aabe6-461">Monitor and manage pipelines using Monitoring App</span></span>](data-factory-monitor-manage-app.md) |<span data-ttu-id="aabe6-462">Ez a cikk ismerteti, hogyan figyelheti és felügyelheti a folyamatokat, illetve hogyan kereshet bennük hibákat a Monitoring & Management App használatával.</span><span class="sxs-lookup"><span data-stu-id="aabe6-462">This article describes how to monitor, manage, and debug pipelines using the Monitoring & Management App.</span></span> |
