---
title: "Másolja a tevékenység teljesítmény- és hangolási útmutató |} Microsoft Docs"
description: "További információk a másolási tevékenység használatakor az Azure Data Factory adatátvitel teljesítményét befolyásoló legfontosabb tényezők."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="335ac-103">Másolja a tevékenység teljesítmény- és hangolási útmutató</span><span class="sxs-lookup"><span data-stu-id="335ac-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="335ac-104">Az Azure Data Factory másolási tevékenység egy első osztályú biztonságos, megbízható és nagy teljesítményű Adatbetöltési megoldást nyújt.</span><span class="sxs-lookup"><span data-stu-id="335ac-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="335ac-105">Ez lehetővé teszi terabájtos adatkészleteket több példányát minden nap felhő gazdag számos és a helyszíni adattárolókhoz.</span><span class="sxs-lookup"><span data-stu-id="335ac-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="335ac-106">Blazing-gyors Adatbetöltési teljesítmény annak érdekében, hogy az alapvető "big data" probléma összpontosíthat kulcs: speciális elemzési megoldások kialakításához, és lekérése mélyebben elemezheti az adatokat.</span><span class="sxs-lookup"><span data-stu-id="335ac-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="335ac-107">Azure számos vállalati szintű adatok tárolási és adatok adatraktár megoldások, és a másolási tevékenység során magas szinten optimalizált Adatbetöltési konfigurálása, és állítson be egyszerű élményt nyújt.</span><span class="sxs-lookup"><span data-stu-id="335ac-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="335ac-108">Csak egyetlen példány tevékenységgel érhet el:</span><span class="sxs-lookup"><span data-stu-id="335ac-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="335ac-109">Az adatok betöltése **Azure SQL Data Warehouse** : **1,2 GB/s**.</span><span class="sxs-lookup"><span data-stu-id="335ac-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="335ac-110">A használati esetek bemutatóért lásd: [1 TB-os betöltése az Azure SQL Data Warehouse a 15 perc Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="335ac-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="335ac-111">Az adatok betöltése **Azure Blob Storage tárolóban** : **1,0 GB/s**</span><span class="sxs-lookup"><span data-stu-id="335ac-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="335ac-112">Az adatok betöltése **Azure Data Lake Store** : **1,0 GB/s**</span><span class="sxs-lookup"><span data-stu-id="335ac-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="335ac-113">Ez a cikk ismerteti:</span><span class="sxs-lookup"><span data-stu-id="335ac-113">This article describes:</span></span>

* <span data-ttu-id="335ac-114">[Hivatkozás számok](#performance-reference) támogatott forrás és a fogadó adattárolókhoz segítségével megtervezheti a projekt;</span><span class="sxs-lookup"><span data-stu-id="335ac-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="335ac-115">Funkciókat, amelyek különböző helyzetekben, például a Másolás átviteli képes javítani [adatátviteli adategységek cloud](#cloud-data-movement-units), [másolási párhuzamos](#parallel-copy), és [másolási előkészített](#staged-copy);</span><span class="sxs-lookup"><span data-stu-id="335ac-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="335ac-116">[Teljesítményhangolás útmutatást](#performance-tuning-steps) hogyan javítható a teljesítmény és a Másolás teljesítményre gyakorolt hatásáról tényezők a.</span><span class="sxs-lookup"><span data-stu-id="335ac-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="335ac-117">Ha nem ismeri a másolási tevékenység során általában, lásd: [adatok áthelyezése a másolási tevékenység segítségével](data-factory-data-movement-activities.md) a cikk elolvasása előtt.</span><span class="sxs-lookup"><span data-stu-id="335ac-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="335ac-118">Teljesítmény-hivatkozás</span><span class="sxs-lookup"><span data-stu-id="335ac-118">Performance reference</span></span>

<span data-ttu-id="335ac-119">Referenciaként táblázat alatti másolási átviteli számát mutatja MB/s mértékegységben a belső tesztekre alapozva megadott forrás- és fogadó párokat.</span><span class="sxs-lookup"><span data-stu-id="335ac-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="335ac-120">Az összehasonlításhoz, azt is bemutatja, különböző beállításait [adatátviteli adategységek cloud](#cloud-data-movement-units) vagy [az adatkezelési átjáró méretezhetőség](data-factory-data-management-gateway-high-availability-scalability.md) a fájlmásolás (több átjárócsomópontok) segítségével.</span><span class="sxs-lookup"><span data-stu-id="335ac-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Teljesítmény mátrix](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="335ac-122">**Vegye figyelembe a következő szempontok:**</span><span class="sxs-lookup"><span data-stu-id="335ac-122">**Points to note:**</span></span>
* <span data-ttu-id="335ac-123">Átviteli sebesség számítja ki a következő képlet: [forrás olvasható adatok mérete] / [a másolási tevékenység időtartama futtatása].</span><span class="sxs-lookup"><span data-stu-id="335ac-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="335ac-124">A tábla a hivatkozás számok volt mérni [TPC-H](http://www.tpc.org/tpch/) adathalmaz egy egyetlen másolási tevékenység során futtassa.</span><span class="sxs-lookup"><span data-stu-id="335ac-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="335ac-125">Az Azure data tárolja a forrás- és fogadó is, azonos Azure-régióban.</span><span class="sxs-lookup"><span data-stu-id="335ac-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="335ac-126">A hibrid másolás között a helyszíni és felhőalapú adattároló, minden átjárócsomópont futott, de a elkülönül a helyszíni adattárolót alatt specification gépen.</span><span class="sxs-lookup"><span data-stu-id="335ac-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="335ac-127">Ha egy adott tevékenység átjáró kiszolgálón már futott, a másolási művelet felhasznált csak kis részét a tesztgép CPU, a memória vagy a hálózati sávszélesség.</span><span class="sxs-lookup"><span data-stu-id="335ac-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="335ac-128">A további [szempont az adatkezelési átjáró](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="335ac-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="335ac-129">CPU</span><span class="sxs-lookup"><span data-stu-id="335ac-129">CPU</span></span></td>
        <td><span data-ttu-id="335ac-130">32 processzormag 2,20 GHz -es Intel Xeon E5-2660 v2</span><span class="sxs-lookup"><span data-stu-id="335ac-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="335ac-131">Memory (Memória)</span><span class="sxs-lookup"><span data-stu-id="335ac-131">Memory</span></span></td>
        <td><span data-ttu-id="335ac-132">128 GB</span><span class="sxs-lookup"><span data-stu-id="335ac-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="335ac-133">Network (Hálózat)</span><span class="sxs-lookup"><span data-stu-id="335ac-133">Network</span></span></td>
        <td><span data-ttu-id="335ac-134">Internetes adapter: 10 GB/s; intranetes adapterének: 40 GB/s</span><span class="sxs-lookup"><span data-stu-id="335ac-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="335ac-135">Nagyobb átviteli teljesítményt érhet el, ami további adatok adatátviteli egység (DMUs) alapértelmezett maximális DMUs, amely egy felhő-felhőbe történő másolás tevékenységfuttatási 32.</span><span class="sxs-lookup"><span data-stu-id="335ac-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="335ac-136">Például a 100 DMUs érhet el az adatok másolását az Azure Blob az Azure Data Lake Store: **1.0GBps**.</span><span class="sxs-lookup"><span data-stu-id="335ac-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="335ac-137">Tekintse meg a [adatátviteli adategységek Cloud](#cloud-data-movement-units) szakasz ezt a szolgáltatást és a támogatott forgatókönyv szerint.</span><span class="sxs-lookup"><span data-stu-id="335ac-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="335ac-138">Ügyfél [az Azure támogatási](https://azure.microsoft.com/support/) további DMUs kéréséhez.</span><span class="sxs-lookup"><span data-stu-id="335ac-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="335ac-139">Párhuzamos másolása</span><span class="sxs-lookup"><span data-stu-id="335ac-139">Parallel copy</span></span>
<span data-ttu-id="335ac-140">A forrás-adatok olvasása, vagy adatok írása az a cél **belül a másolási tevékenység során futtassa párhuzamosan**.</span><span class="sxs-lookup"><span data-stu-id="335ac-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="335ac-141">Ez a funkció növeli a teljesítményt, a másolási műveletek, és csökkenti a adatok áthelyezéséhez szükséges időt.</span><span class="sxs-lookup"><span data-stu-id="335ac-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="335ac-142">Ez a beállítás különbözik a **egyidejűségi** tulajdonság a tevékenységdefinícióban.</span><span class="sxs-lookup"><span data-stu-id="335ac-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="335ac-143">A **egyidejűségi** tulajdonság határozza meg, hogy **egyidejű másolási tevékenység fut** folyamat adatok különböző tevékenység Windows (13: 00 való hajnali 2 óra, Reggel 2 3 AM, 3 Reggel 4 óra és így tovább).</span><span class="sxs-lookup"><span data-stu-id="335ac-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="335ac-144">Ez a funkció akkor hasznos, ha egy korábbi terheléselosztási elvégezhető.</span><span class="sxs-lookup"><span data-stu-id="335ac-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="335ac-145">A párhuzamos másolási képesség vonatkozik egy **tevékenységfuttatási egyetlen**.</span><span class="sxs-lookup"><span data-stu-id="335ac-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="335ac-146">Egy mintaforgatókönyv vizsgáljuk meg.</span><span class="sxs-lookup"><span data-stu-id="335ac-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="335ac-147">A következő példában a múltban a több szeletek kell feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="335ac-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="335ac-148">Adat-előállító fut az egyes szeletek másolási tevékenység (egy tevékenység futott) példánya:</span><span class="sxs-lookup"><span data-stu-id="335ac-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="335ac-149">Az adatszelet az első tevékenység ablakból (13: 00 hajnali 2 Órakor) == > tevékenység fut 1</span><span class="sxs-lookup"><span data-stu-id="335ac-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="335ac-150">Az adatszelet, a második tevékenység ablakból (hajnali 2 Órakor hajnali 3 Órakor) == > tevékenység fut 2</span><span class="sxs-lookup"><span data-stu-id="335ac-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="335ac-151">Az adatszelet, a második tevékenység ablakból (3 de hajnali 4 Órakor) == > tevékenység fut 3</span><span class="sxs-lookup"><span data-stu-id="335ac-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="335ac-152">És így tovább.</span><span class="sxs-lookup"><span data-stu-id="335ac-152">And so on.</span></span>

<span data-ttu-id="335ac-153">Ebben a példában amikor a **egyidejűségi** értéke 2, **tevékenység fut 1** és **tevékenység fut 2** adatokat másolni két tevékenység windows **egyidejűleg** adatok mozgása teljesítmény javítása érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="335ac-154">Azonban ha több fájl Tevékenységfuttatási 1 társul, az adatátviteli szolgáltatás fájlokat másolja a forrás egy fájlhoz egyszerre.</span><span class="sxs-lookup"><span data-stu-id="335ac-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="335ac-155">A mozgás adategységek felhő</span><span class="sxs-lookup"><span data-stu-id="335ac-155">Cloud data movement units</span></span>
<span data-ttu-id="335ac-156">A **felhő adatok adatátviteli egység (DMU)** egy mérték, amely jelöli az (a Processzor, memória és a hálózatierőforrás-lefoglalás kombinációja) adat-előállítóban egyetlen egységben.</span><span class="sxs-lookup"><span data-stu-id="335ac-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="335ac-157">Egy DMU egy felhő-felhőbe történő másolás művelet, de nem egy hibrid másolás használhatók.</span><span class="sxs-lookup"><span data-stu-id="335ac-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="335ac-158">Alapértelmezés szerint a Data Factory DMU egyetlen felhő használja a Futtatás egyetlen másolási tevékenység végrehajtásához.</span><span class="sxs-lookup"><span data-stu-id="335ac-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="335ac-159">Ez az alapértelmezett felülbírálásához adjon meg értéket a **cloudDataMovementUnits** tulajdonság az alábbiak szerint.</span><span class="sxs-lookup"><span data-stu-id="335ac-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="335ac-160">Egy adott másolási forrását, és a fogadó további egységek konfigurálásakor kaphat jobb teljesítménye szintjét kapcsolatos információk: a [teljesítményfigyelési](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="335ac-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="335ac-161">A **engedélyezett értékek** a a **cloudDataMovementUnits** tulajdonság (alapértelmezett) 1, 2, 4, 8, 16, 32.</span><span class="sxs-lookup"><span data-stu-id="335ac-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="335ac-162">A **felhő DMUs tényleges száma** egyenlő vagy kisebb, mint a konfigurált érték, attól függően, hogy a adatmintát, hogy használja-e a másolási művelet futásidőben.</span><span class="sxs-lookup"><span data-stu-id="335ac-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="335ac-163">Ha további felhőalapú DMUs magasabb átviteli van szüksége, forduljon a [az Azure támogatási](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="335ac-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="335ac-164">8 beállítása, a fenti jelenleg működik csak akkor, ha Ön **több fájl másolása Blob storage vagy Data Lake Store vagy az Azure Blob storage/Data Lake Store/Amazon S3/felhő FTP/felhő SFTP SQL-adatbázis**.</span><span class="sxs-lookup"><span data-stu-id="335ac-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="335ac-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="335ac-165">parallelCopies</span></span>
<span data-ttu-id="335ac-166">Használhatja a **parallelCopies** tulajdonság, amely jelzi a másolási tevékenység során használni kívánt párhuzamosságát.</span><span class="sxs-lookup"><span data-stu-id="335ac-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="335ac-167">Ez a tulajdonság a másolási tevékenység során, a fogadó adattárolókhoz párhuzamosan írni vagy olvasni a forrás is szálai maximális számának tulajdonképpen.</span><span class="sxs-lookup"><span data-stu-id="335ac-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="335ac-168">Minden egyes futtatása másolási tevékenységhez adat-előállító száma párhuzamos adatokat másolni a forrás adatokat tárolja, és a cél adatok tárolására használandó határozza meg.</span><span class="sxs-lookup"><span data-stu-id="335ac-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="335ac-169">Alapértelmezett száma párhuzamos, amelyet használ a forrás és a fogadó által használt függ.</span><span class="sxs-lookup"><span data-stu-id="335ac-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="335ac-170">Forrás és a fogadó</span><span class="sxs-lookup"><span data-stu-id="335ac-170">Source and sink</span></span> | <span data-ttu-id="335ac-171">Alapértelmezett párhuzamos példányszám szolgáltatás határozza meg</span><span class="sxs-lookup"><span data-stu-id="335ac-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="335ac-172">Adatok másolása közötti fájlalapú tárolók (Blob-tároló; Data Lake Store; Amazon S3; a helyszíni fájlrendszer; egy helyszíni HDFS)</span><span class="sxs-lookup"><span data-stu-id="335ac-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="335ac-173">1 és 32.</span><span class="sxs-lookup"><span data-stu-id="335ac-173">Between 1 and 32.</span></span> <span data-ttu-id="335ac-174">A fájlok és a felhő adatok adatátviteli egység (DMUs) száma átmásolhatja az adatokat két felhőalapú adattároló, vagy az átjáró számítógépe (érdekében másolja az adatokat, vagy egy helyszíni adattárolóból) egy hibrid másolás használt fizikai konfigurációját között méretétől függ.</span><span class="sxs-lookup"><span data-stu-id="335ac-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="335ac-175">Az adatok másolása **forrás adatok tárolásához Azure Table Storage**</span><span class="sxs-lookup"><span data-stu-id="335ac-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="335ac-176">4</span><span class="sxs-lookup"><span data-stu-id="335ac-176">4</span></span> |
| <span data-ttu-id="335ac-177">Minden más forrás és a fogadó pár</span><span class="sxs-lookup"><span data-stu-id="335ac-177">All other source and sink pairs</span></span> |<span data-ttu-id="335ac-178">1</span><span class="sxs-lookup"><span data-stu-id="335ac-178">1</span></span> |

<span data-ttu-id="335ac-179">Általában az alapértelmezett viselkedés biztosítani fogja a legjobb teljesítményt.</span><span class="sxs-lookup"><span data-stu-id="335ac-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="335ac-180">Azonban az adatok üzemeltető gépek terhelését vezérlésére tárolja, vagy másolási teljesítmény hangolására meg is felülbírálhatja az alapértelmezett értéket, és adjon meg egy értéket a **parallelCopies** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="335ac-181">Az érték 1 és 32 (mind a két szélsőértéket beleértve) között kell lennie.</span><span class="sxs-lookup"><span data-stu-id="335ac-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="335ac-182">Futásidőben a legjobb teljesítmény érdekében másolási tevékenység értéket használ, amely kisebb vagy egyenlő a megadott érték.</span><span class="sxs-lookup"><span data-stu-id="335ac-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="335ac-183">Vegye figyelembe a következő szempontok:</span><span class="sxs-lookup"><span data-stu-id="335ac-183">Points to note:</span></span>

* <span data-ttu-id="335ac-184">Fájlalapú tárolók közötti adatok másolásakor a **parallelCopies** határozza meg a fájlok szintjén párhuzamosságát.</span><span class="sxs-lookup"><span data-stu-id="335ac-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="335ac-185">Egyetlen fájlba adattömbösítő történne alá, automatikusan és transzparens módon, és úgy van kialakítva, párhuzamos és merőleges parallelCopies az adatok betöltése az ajánlott megfelelő adatrészletméretnek az egy adott forrás adattároló-típus használatával.</span><span class="sxs-lookup"><span data-stu-id="335ac-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="335ac-186">Tényleges száma párhuzamos adatátviteli szolgáltatást használja, a másolási művelet futásidőben nem több, mint a fájlok száma.</span><span class="sxs-lookup"><span data-stu-id="335ac-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="335ac-187">Ha a Másolás viselkedése **mergeFile**, másolási tevékenység fájlszintű párhuzamossági tudják kihasználni.</span><span class="sxs-lookup"><span data-stu-id="335ac-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="335ac-188">Ha ad meg értéket a **parallelCopies** tulajdonság, fontolja meg a terhelést növelni a forrás és a fogadó adattároló, és az átjáró, ha az egy hibrid másolás.</span><span class="sxs-lookup"><span data-stu-id="335ac-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="335ac-189">Ez akkor fordul elő, különösen ha van több tevékenységek vagy tevékenységének ugyanazt az adattárat futtathat egyidejű futtatását.</span><span class="sxs-lookup"><span data-stu-id="335ac-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="335ac-190">Ha azt észleli, hogy az adattár vagy az átjáró túlterhelik a a terhelés, csökkentse a **parallelCopies** érték a terhelés alól.</span><span class="sxs-lookup"><span data-stu-id="335ac-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="335ac-191">Adatok másolása, amelyek nem fájl alapú áruházak, amelyek a fájlalapú tárolók, az adatátviteli szolgáltatás figyelmen kívül hagyja a **parallelCopies** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="335ac-192">Akkor is, ha a párhuzamos végrehajtás meg van adva, akkor nem lesz alkalmazva ebben az esetben.</span><span class="sxs-lookup"><span data-stu-id="335ac-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="335ac-193">Használja az adatkezelési átjáró 1.11 vagy újabb verzióját kell használnia a **parallelCopies** a beállítást, ha így tesz, hibrid másolatát.</span><span class="sxs-lookup"><span data-stu-id="335ac-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="335ac-194">A két tulajdonság használatával eredményesebb, valamint javítható az adatok adatátviteli teljesítményt, lásd: a [használati esetek minta](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="335ac-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="335ac-195">Nem kell konfigurálni **parallelCopies** előnyeit az alapértelmezett viselkedés.</span><span class="sxs-lookup"><span data-stu-id="335ac-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="335ac-196">Ha konfigurálja és **parallelCopies** túl kicsi, több felhőalapú DMUs nem teljes kihasználását.</span><span class="sxs-lookup"><span data-stu-id="335ac-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="335ac-197">Számlázási gyakorolt hatás</span><span class="sxs-lookup"><span data-stu-id="335ac-197">Billing impact</span></span>
<span data-ttu-id="335ac-198">Rendelkezik **fontos** jegyezze meg, hogy van szó, a másolási művelet teljes ideje alapján.</span><span class="sxs-lookup"><span data-stu-id="335ac-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="335ac-199">Ha egy feladat használatával egy órával magával egy felhőalapú egység, és most négy felhő egységek 15 percet vesz igénybe, az általános számlázási szinte változatlan marad.</span><span class="sxs-lookup"><span data-stu-id="335ac-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="335ac-200">Például használhatja négy felhő egység.</span><span class="sxs-lookup"><span data-stu-id="335ac-200">For example, you use four cloud units.</span></span> <span data-ttu-id="335ac-201">Az első felhő egység fordít 10 perc, a második érték 10 perc, 5 perc, a harmadik közül, és a negyedik, 5 perc minden, a másolási tevékenység során egy futtatásához.</span><span class="sxs-lookup"><span data-stu-id="335ac-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="335ac-202">A teljes másolása (adatátvitel) ideje, 10 + 10 + 5 + 5 = 30 perc van szó.</span><span class="sxs-lookup"><span data-stu-id="335ac-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="335ac-203">Használatával **parallelCopies** számlázás nincs hatással.</span><span class="sxs-lookup"><span data-stu-id="335ac-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="335ac-204">Előkészített másolása</span><span class="sxs-lookup"><span data-stu-id="335ac-204">Staged copy</span></span>
<span data-ttu-id="335ac-205">Adatok másolása a forrás-tárolóban a fogadó adattárat, amikor előfordulhat, hogy használatát választja a Blob storage egy ideiglenes átmeneti tárolóként.</span><span class="sxs-lookup"><span data-stu-id="335ac-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="335ac-206">Átmeneti is különösen hasznos az alábbi esetekben:</span><span class="sxs-lookup"><span data-stu-id="335ac-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="335ac-207">**Betöltési különböző adattároló adatait az SQL Data Warehouse polybase kívánt**.</span><span class="sxs-lookup"><span data-stu-id="335ac-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="335ac-208">Az SQL Data Warehouse PolyBase a nagy átviteli mechanizmusként nagy mennyiségű adatok betöltése az SQL Data Warehouse használja.</span><span class="sxs-lookup"><span data-stu-id="335ac-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="335ac-209">Azonban az adatok a Blob Storage tárolóban kell lennie, és további feltételeknek kell megfelelnie.</span><span class="sxs-lookup"><span data-stu-id="335ac-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="335ac-210">Adatok betöltése a eltérő a Blob storage tárolóban, amikor adatok másolása ideiglenes átmeneti Blob-tároló keresztül aktiválhatja.</span><span class="sxs-lookup"><span data-stu-id="335ac-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="335ac-211">Ebben az esetben adat-előállító hajtja végre a szükséges adatátalakítást annak érdekében, hogy megfelel-e a PolyBase követelményeinek.</span><span class="sxs-lookup"><span data-stu-id="335ac-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="335ac-212">A PolyBase majd az adatok betöltése az SQL Data Warehouse használ.</span><span class="sxs-lookup"><span data-stu-id="335ac-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="335ac-213">További részletekért lásd: [használja a PolyBase az adatok betöltése az Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="335ac-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="335ac-214">A használati esetek bemutatóért lásd: [1 TB-os betöltése az Azure SQL Data Warehouse a 15 perc Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="335ac-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="335ac-215">**Néha szükséges lehet elvégezni egy hibrid adatátvitelt jelölik a (Ez azt jelenti, hogy egy a helyszíni adatok közötti másolásához tároló és a felhőalapú adatokat tárol) lassú hálózati kapcsolaton keresztül**.</span><span class="sxs-lookup"><span data-stu-id="335ac-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="335ac-216">A teljesítmény javítása érdekében tömörítheti az adatokat a helyszíni, így az adatok áthelyezése az átmeneti adattár a felhőben kevesebb időt vesz igénybe.</span><span class="sxs-lookup"><span data-stu-id="335ac-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="335ac-217">Majd az adatokat az átmeneti kibontani, a céltár adatok betöltése előtt.</span><span class="sxs-lookup"><span data-stu-id="335ac-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="335ac-218">**Nyissa meg a 80-as port eltérő port és a tűzfalon a 443-as porton vállalati informatikai házirendeknek miatt érdemes**.</span><span class="sxs-lookup"><span data-stu-id="335ac-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="335ac-219">Például amikor egy helyszíni adattároló adatok másolása az Azure SQL Database fogadó vagy egy Azure SQL Data Warehouse fogadó, akkor aktiválnia kell a Windows tűzfal és a vállalati tűzfalon 1433-as port kimenő TCP-kommunikáció.</span><span class="sxs-lookup"><span data-stu-id="335ac-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="335ac-220">Ebben a forgatókönyvben előnyeit az átjáró első adatok egy Blob storage átmeneti példányhoz HTTP vagy HTTPS a 443-as porton.</span><span class="sxs-lookup"><span data-stu-id="335ac-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="335ac-221">Ezt követően az adatok betöltése az SQL Database vagy az SQL Data Warehouse Blob storage átmeneti.</span><span class="sxs-lookup"><span data-stu-id="335ac-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="335ac-222">Ez a folyamat az 1433-as port engedélyezéséhez nem kell.</span><span class="sxs-lookup"><span data-stu-id="335ac-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="335ac-223">Hogyan előkészített másolási működik</span><span class="sxs-lookup"><span data-stu-id="335ac-223">How staged copy works</span></span>
<span data-ttu-id="335ac-224">Az átmeneti funkció aktiválásakor először az adatokat a rendszer átmásolja az a forrás-tárolót az átmeneti adattárolóhoz (kapcsolja a saját).</span><span class="sxs-lookup"><span data-stu-id="335ac-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="335ac-225">Ezt követően az adatok átmásolva az átmeneti adattár fogadó adattárba.</span><span class="sxs-lookup"><span data-stu-id="335ac-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="335ac-226">Adat-előállító automatikusan kezeli a két szakaszból álló folyamata.</span><span class="sxs-lookup"><span data-stu-id="335ac-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="335ac-227">Adat-előállító is megtisztítja az átmeneti tárolási ideiglenes adatait, az adatmozgás befejeződése után.</span><span class="sxs-lookup"><span data-stu-id="335ac-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="335ac-228">A felhőbe másolásának esetéhez (a forrás- és fogadó adatok a felhőben vannak áruházak), az átjáró nem használatos.</span><span class="sxs-lookup"><span data-stu-id="335ac-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="335ac-229">A Data Factory szolgáltatásnak a másolási műveleteket hajtja végre.</span><span class="sxs-lookup"><span data-stu-id="335ac-229">The Data Factory service performs the copy operations.</span></span>

![Másolás előkészített: felhős alkalmazás esetében](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="335ac-231">A hibrid másolás forgatókönyvben (forrása a helyszíni és a fogadó a felhőben), az átjáró adatokat helyezi át a forrás adattárból átmeneti adattárat.</span><span class="sxs-lookup"><span data-stu-id="335ac-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="335ac-232">Data Factory szolgáltatásnak mozgatja az adatokat az átmeneti adattárolóból fogadó adattárba.</span><span class="sxs-lookup"><span data-stu-id="335ac-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="335ac-233">Felhőalapú adattároló történő helyszíni adattárolóihoz átmeneti tárolással végzett másolás is támogatja a fordított folyamata.</span><span class="sxs-lookup"><span data-stu-id="335ac-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Másolás előkészített: hibrid forgatókönyvek](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="335ac-235">Adatátvitel aktiválásakor egy átmeneti tároló használatával megadhatja, hogy kívánja-e az adatok áthelyezése az adatforrás adattárolóból ideiglenes vagy átmeneti adattárolóihoz előtt tömörített, és majd kibontása előtt az adatok áthelyezése egy ideiglenes, vagy az átmeneti adatok adatait a fogadó adattárolóban tárolja.</span><span class="sxs-lookup"><span data-stu-id="335ac-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="335ac-236">Jelenleg nem lehet másolni az adatok között egy átmeneti tárolási használatával két helyszíni adattárolókhoz.</span><span class="sxs-lookup"><span data-stu-id="335ac-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="335ac-237">Várhatóan hamarosan elérhető ezt a beállítást.</span><span class="sxs-lookup"><span data-stu-id="335ac-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="335ac-238">Konfiguráció</span><span class="sxs-lookup"><span data-stu-id="335ac-238">Configuration</span></span>
<span data-ttu-id="335ac-239">Konfigurálja a **enableStaging** a másolási tevékenység beállítást adja meg, hogy az adatokat a Blob Storage tárolóban előtt töltse be a cél-tárolóban átmenetileg tárolva.</span><span class="sxs-lookup"><span data-stu-id="335ac-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="335ac-240">Ha **enableStaging** igaz értéke esetén a következő táblázatban szereplő további tulajdonságainak meghatározásához.</span><span class="sxs-lookup"><span data-stu-id="335ac-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="335ac-241">Ha még nincs fiókja, szükség hozzon létre egy Azure Storage vagy a megosztott aláírás-társított szolgáltatást az átmeneti tárolási.</span><span class="sxs-lookup"><span data-stu-id="335ac-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="335ac-242">Tulajdonság</span><span class="sxs-lookup"><span data-stu-id="335ac-242">Property</span></span> | <span data-ttu-id="335ac-243">Leírás</span><span class="sxs-lookup"><span data-stu-id="335ac-243">Description</span></span> | <span data-ttu-id="335ac-244">Alapértelmezett érték</span><span class="sxs-lookup"><span data-stu-id="335ac-244">Default value</span></span> | <span data-ttu-id="335ac-245">Szükséges</span><span class="sxs-lookup"><span data-stu-id="335ac-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="335ac-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="335ac-246">**enableStaging**</span></span> |<span data-ttu-id="335ac-247">Adja meg, hogy átmeneti tárolási ideiglenes adatot másolni.</span><span class="sxs-lookup"><span data-stu-id="335ac-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="335ac-248">False (Hamis)</span><span class="sxs-lookup"><span data-stu-id="335ac-248">False</span></span> |<span data-ttu-id="335ac-249">Nem</span><span class="sxs-lookup"><span data-stu-id="335ac-249">No</span></span> |
| <span data-ttu-id="335ac-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="335ac-250">**linkedServiceName**</span></span> |<span data-ttu-id="335ac-251">Adja meg egy [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) vagy [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) társított szolgáltatás, amely az ideiglenes átmeneti tárolóként történő használó tárolási példányát.</span><span class="sxs-lookup"><span data-stu-id="335ac-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="335ac-252">Adatok betöltése az SQL Data Warehouse polybase a tároló és a közös hozzáférésű jogosultságkód nem használható.</span><span class="sxs-lookup"><span data-stu-id="335ac-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="335ac-253">Más esetekben használható.</span><span class="sxs-lookup"><span data-stu-id="335ac-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="335ac-254">N/A</span><span class="sxs-lookup"><span data-stu-id="335ac-254">N/A</span></span> |<span data-ttu-id="335ac-255">Igen, mikor **enableStaging** igaz értékre van beállítva</span><span class="sxs-lookup"><span data-stu-id="335ac-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="335ac-256">**elérési út**</span><span class="sxs-lookup"><span data-stu-id="335ac-256">**path**</span></span> |<span data-ttu-id="335ac-257">Adja meg a Blob. tárolási elérési útja, amelyet szeretne az előkészített adatok.</span><span class="sxs-lookup"><span data-stu-id="335ac-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="335ac-258">Ha nem ad meg egy elérési utat, a szolgáltatás tárolót hoz létre ideiglenes adatok tárolására.</span><span class="sxs-lookup"><span data-stu-id="335ac-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="335ac-259">Adjon meg egy elérési utat, csak akkor, ha a közös hozzáférésű jogosultságkód tárhelyet használ, vagy ideiglenes az adatokat egy adott helyen van szüksége.</span><span class="sxs-lookup"><span data-stu-id="335ac-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="335ac-260">N/A</span><span class="sxs-lookup"><span data-stu-id="335ac-260">N/A</span></span> |<span data-ttu-id="335ac-261">Nem</span><span class="sxs-lookup"><span data-stu-id="335ac-261">No</span></span> |
| <span data-ttu-id="335ac-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="335ac-262">**enableCompression**</span></span> |<span data-ttu-id="335ac-263">Meghatározza, hogy adatokat tömörített-e, mielőtt azt a cél felé.</span><span class="sxs-lookup"><span data-stu-id="335ac-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="335ac-264">Ez a beállítás az átvitt adatok mennyiségét csökkenti.</span><span class="sxs-lookup"><span data-stu-id="335ac-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="335ac-265">False (Hamis)</span><span class="sxs-lookup"><span data-stu-id="335ac-265">False</span></span> |<span data-ttu-id="335ac-266">Nem</span><span class="sxs-lookup"><span data-stu-id="335ac-266">No</span></span> |

<span data-ttu-id="335ac-267">Íme egy minta definíciója másolási tevékenység az az előző táblázatban leírt tulajdonságokkal:</span><span class="sxs-lookup"><span data-stu-id="335ac-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="335ac-268">Számlázási gyakorolt hatás</span><span class="sxs-lookup"><span data-stu-id="335ac-268">Billing impact</span></span>
<span data-ttu-id="335ac-269">Van szó, a két lépésből áll: duration másolja, majd másolja át a típust.</span><span class="sxs-lookup"><span data-stu-id="335ac-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="335ac-270">Használatakor a felhőbe történő másolás (az adatok másolása a felhő-tárolóban egy másik felhőben adattárolóhoz), közben átmeneti van szó, a [másolása időtartamának összege 1 és 2. lépést] x [felhő másolási Egységár].</span><span class="sxs-lookup"><span data-stu-id="335ac-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="335ac-271">Használatakor során (az adatok másolása egy helyszíni adattároló egy felhőalapú adattárolóhoz) hibrid másolatát átmeneti van szó, a [hibrid másolás időtartam] x [hibrid másolás Egységár] + [cloud másolási időtartam] [felhő másolási Egységár] x.</span><span class="sxs-lookup"><span data-stu-id="335ac-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="335ac-272">Teljesítmény hangolási lépései</span><span class="sxs-lookup"><span data-stu-id="335ac-272">Performance tuning steps</span></span>
<span data-ttu-id="335ac-273">Javasoljuk, hogy szánjon a Data Factory szolgáltatásnak a másolási tevékenység teljesítményét az alábbi lépéseket:</span><span class="sxs-lookup"><span data-stu-id="335ac-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="335ac-274">**Meghatározásához**.</span><span class="sxs-lookup"><span data-stu-id="335ac-274">**Establish a baseline**.</span></span> <span data-ttu-id="335ac-275">A fejlesztési fázisban tesztelje a feldolgozási sor másolási tevékenység segítségével egy reprezentatív minta alapján.</span><span class="sxs-lookup"><span data-stu-id="335ac-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="335ac-276">Használhatja a Data Factory [modell felosztás](data-factory-scheduling-and-execution.md) használata adatok korlátozásához.</span><span class="sxs-lookup"><span data-stu-id="335ac-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="335ac-277">Végrehajtási idő és a teljesítményt nyújt a gyűjtése a **figyelés és a felügyeleti alkalmazás**.</span><span class="sxs-lookup"><span data-stu-id="335ac-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="335ac-278">Válasszon **figyelő & kezelése** a Data Factory kezdőlapon.</span><span class="sxs-lookup"><span data-stu-id="335ac-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="335ac-279">A faszerkezetes nézetben válassza ki a **kimeneti adatkészlet**.</span><span class="sxs-lookup"><span data-stu-id="335ac-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="335ac-280">Az a **tevékenység Windows** menüben válassza ki a másolási tevékenység során futtassa.</span><span class="sxs-lookup"><span data-stu-id="335ac-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="335ac-281">**Tevékenység Windows** sorolja fel, a másolási tevékenység időtartamát és a másolt adatok méretét.</span><span class="sxs-lookup"><span data-stu-id="335ac-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="335ac-282">Az átviteli sebesség szerepel **tevékenység ablak Explorer**.</span><span class="sxs-lookup"><span data-stu-id="335ac-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="335ac-283">Az alkalmazással kapcsolatos további tudnivalókért lásd: [figyelése és kezelése az Azure Data Factory adatcsatornák a figyelés és a felügyeleti alkalmazás](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="335ac-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![Tevékenységfuttatás részletei](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="335ac-285">A cikk későbbi részében összehasonlíthatja a teljesítmény és a forgatókönyvhöz a másolási tevékenység konfigurációjának [teljesítményfigyelési](#performance-reference) a tesztelés.</span><span class="sxs-lookup"><span data-stu-id="335ac-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="335ac-286">**Diagnosztizálhatja és teljesítményének optimalizálásához**.</span><span class="sxs-lookup"><span data-stu-id="335ac-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="335ac-287">Ha azt láthatja a teljesítmény nem felel meg az elvárásainak, akkor teljesítmény szűk keresztmetszetek azonosítása.</span><span class="sxs-lookup"><span data-stu-id="335ac-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="335ac-288">Ezt követően optimalizálása teljesítményét, és távolítsa el, vagy a szűk keresztmetszetek elkerülése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="335ac-289">A teljesítmény megállapítása teljes leírása, ez a cikk terjed, de az alábbiakban néhány gyakori szempontok:</span><span class="sxs-lookup"><span data-stu-id="335ac-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="335ac-290">Teljesítménnyel kapcsolatos szolgáltatások:</span><span class="sxs-lookup"><span data-stu-id="335ac-290">Performance features:</span></span>
     * [<span data-ttu-id="335ac-291">Párhuzamos másolása</span><span class="sxs-lookup"><span data-stu-id="335ac-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="335ac-292">A mozgás adategységek felhő</span><span class="sxs-lookup"><span data-stu-id="335ac-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="335ac-293">Előkészített másolása</span><span class="sxs-lookup"><span data-stu-id="335ac-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="335ac-294">Adatok adatkezelési átjáró méretezhetőség</span><span class="sxs-lookup"><span data-stu-id="335ac-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="335ac-295">Adatkezelési átjáró</span><span class="sxs-lookup"><span data-stu-id="335ac-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="335ac-296">Forrás</span><span class="sxs-lookup"><span data-stu-id="335ac-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="335ac-297">A fogadó</span><span class="sxs-lookup"><span data-stu-id="335ac-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="335ac-298">Szerializálás és a deszerializálás</span><span class="sxs-lookup"><span data-stu-id="335ac-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="335ac-299">Tömörítés</span><span class="sxs-lookup"><span data-stu-id="335ac-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="335ac-300">Oszlop leképezése</span><span class="sxs-lookup"><span data-stu-id="335ac-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="335ac-301">Egyéb szempontok</span><span class="sxs-lookup"><span data-stu-id="335ac-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="335ac-302">**Bontsa ki a teljes adatkészletet a**.</span><span class="sxs-lookup"><span data-stu-id="335ac-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="335ac-303">Ha elégedett a végrehajtási eredményt és a teljesítményt, bővítheti a definíció- és adatcsatorna aktív időszakának fedik le a teljes adatkészletet.</span><span class="sxs-lookup"><span data-stu-id="335ac-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="335ac-304">Az adatkezelési átjáró szempontjai</span><span class="sxs-lookup"><span data-stu-id="335ac-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="335ac-305">**Átjáró telepítési**: javasoljuk, hogy a gazdagép az adatkezelési átjáró egy dedikált gépet használjon.</span><span class="sxs-lookup"><span data-stu-id="335ac-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="335ac-306">Lásd: [az adatkezelési átjáró használatának szempontjai](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="335ac-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="335ac-307">**Átjáró felügyeleti és felfelé vagy kibővített**: egy vagy több átjáró csomópontokkal egyetlen logikai átjáró ki tud szolgálni másolási tevékenység több fut egyidejűleg egy időben.</span><span class="sxs-lookup"><span data-stu-id="335ac-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="335ac-308">Megtekintheti a közel valós idejű pillanatképe erőforrás-használat (Processzor, memória, network(in/out), stb.), valamint a korlát az Azure portálon, illetve fut egyidejűleg futó feladatainak számát lásd átjáró gépen [figyelő átjárót a portál](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span><span class="sxs-lookup"><span data-stu-id="335ac-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="335ac-309">Ha hibrid adatátvitel nagy száma párhuzamos másolási tevékenység fut vagy nagy mennyiségű adat másolása nehéz szükség van, érdemes lehet [növelheti vagy horizontális felskálázás átjáró](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) úgy, hogy jobban tudják használni az erőforrás vagy kiépítése További erőforrás másolása építve.</span><span class="sxs-lookup"><span data-stu-id="335ac-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="335ac-310">A forrás szempontjai</span><span class="sxs-lookup"><span data-stu-id="335ac-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="335ac-311">Általános kérdések</span><span class="sxs-lookup"><span data-stu-id="335ac-311">General</span></span>
<span data-ttu-id="335ac-312">Győződjön meg arról, hogy az alapul szolgáló adattár nem túlterhelik az egyéb munkaterhelések vagy rajta.</span><span class="sxs-lookup"><span data-stu-id="335ac-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="335ac-313">A Microsoft adatokat tárolja, lásd: [figyelése és beállítása a témakörök](#performance-reference) kifejezetten az adatokról, és ismernie az adatok tárolásához teljesítményt nyújt, a válaszhoz szükséges idő minimalizálása és átviteli sebesség maximalizálása súgó.</span><span class="sxs-lookup"><span data-stu-id="335ac-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="335ac-314">Ha az adatok másolása az Blob-tárolóból az SQL Data Warehouse-érdemes **PolyBase** teljesítmény növelése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="335ac-315">Lásd: [használja a PolyBase az adatok betöltése az Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) részleteiről.</span><span class="sxs-lookup"><span data-stu-id="335ac-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="335ac-316">A használati esetek bemutatóért lásd: [1 TB-os betöltése az Azure SQL Data Warehouse a 15 perc Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="335ac-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="335ac-317">Fájl alapú adattároló</span><span class="sxs-lookup"><span data-stu-id="335ac-317">File-based data stores</span></span>
<span data-ttu-id="335ac-318">*(A Blob storage, Data Lake Store, Amazon S3, a helyi fájlrendszer és a helyszíni HDFS tartalmazza)*</span><span class="sxs-lookup"><span data-stu-id="335ac-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="335ac-319">**Átlagos méretét és a fájlok száma**: másolási tevékenység egyszerre visz át egy adatfájlt.</span><span class="sxs-lookup"><span data-stu-id="335ac-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="335ac-320">Az áthelyezett adatok ugyanannyi a teljes teljesítményt verziója alacsonyabb, ha néhány nagy fájlok miatt a rendszer-indításkori fázis a fájl helyett a sok kisméretű fájlt tartalmaz.</span><span class="sxs-lookup"><span data-stu-id="335ac-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="335ac-321">Ezért ha lehetséges, kis fájlok egységgé kombinálják ahhoz, hogy nagyobb átviteli teljesítményt nagyobb fájlok.</span><span class="sxs-lookup"><span data-stu-id="335ac-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="335ac-322">**Fájl formátuma és tömörítést**: további részleteket a teljesítmény javítása érdekében tekintse meg a [szempontok a szerializálás és a deszerializálás](#considerations-for-serialization-and-deserialization) és [tömörítés szempontjai](#considerations-for-compression) szakaszok.</span><span class="sxs-lookup"><span data-stu-id="335ac-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="335ac-323">Az a **helyszíni fájlrendszer** forgatókönyv, amelyben **az adatkezelési átjáró** van szükség esetén tekintse meg a [az adatkezelési átjáró szempontjai](#considerations-for-data-management-gateway) szakasz.</span><span class="sxs-lookup"><span data-stu-id="335ac-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="335ac-324">Relációs adattároló.</span><span class="sxs-lookup"><span data-stu-id="335ac-324">Relational data stores</span></span>
<span data-ttu-id="335ac-325">*(Tartalmazza az SQL-adatbázis; Az SQL Data Warehouse; Amazon Redshift; SQL Server-adatbázisok; és Oracle, MySQL, DB2, Teradata, Sybase és PostgreSQL adatbázisok stb.)*</span><span class="sxs-lookup"><span data-stu-id="335ac-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="335ac-326">**Adatminta**: A következő tábla sémáját hatással van a Másolás átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="335ac-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="335ac-327">Nagy sorméret kis sorméret akkora adatok másolása egy jobb teljesítményt biztosít.</span><span class="sxs-lookup"><span data-stu-id="335ac-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="335ac-328">A hiba oka, hogy az adatbázis hatékonyabban le adatokat, amelyek kevesebb sort tartalmaznak kevesebb kötegekben.</span><span class="sxs-lookup"><span data-stu-id="335ac-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="335ac-329">**Lekérdezés vagy tárolt eljárás**: optimalizálja a lekérdezést, vagy adja meg, a másolási tevékenység forrásból teszi lehetővé az adatlehívást hatékonyabban tárolt eljárás logikáját.</span><span class="sxs-lookup"><span data-stu-id="335ac-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="335ac-330">A **helyszíni relációs adatbázisok**, például az SQL Server és Oracle, amelyek használatát **az adatkezelési átjáró**, tekintse meg a [az adatkezelési átjárószempontjai](#considerations-on-data-management-gateway) szakasz.</span><span class="sxs-lookup"><span data-stu-id="335ac-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="335ac-331">A fogadó szempontjai</span><span class="sxs-lookup"><span data-stu-id="335ac-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="335ac-332">Általános kérdések</span><span class="sxs-lookup"><span data-stu-id="335ac-332">General</span></span>
<span data-ttu-id="335ac-333">Győződjön meg arról, hogy az alapul szolgáló adattár nem túlterhelik az egyéb munkaterhelések vagy rajta.</span><span class="sxs-lookup"><span data-stu-id="335ac-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="335ac-334">A Microsoft adatokat tárolja, tekintse meg [figyelése és beállítása a témakörök](#performance-reference) vonatkoznak, adattároló.</span><span class="sxs-lookup"><span data-stu-id="335ac-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="335ac-335">Ezek a témakörök azt segítenek megérteni adatok tárolási teljesítményt nyújt, és a válaszhoz szükséges idő minimalizálása és átviteli sebesség maximalizálása érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="335ac-336">Adatok másolása **Blob-tároló** való **SQL Data Warehouse**, érdemes lehet **PolyBase** teljesítmény növelése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="335ac-337">Lásd: [használja a PolyBase az adatok betöltése az Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) részleteiről.</span><span class="sxs-lookup"><span data-stu-id="335ac-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="335ac-338">A használati esetek bemutatóért lásd: [1 TB-os betöltése az Azure SQL Data Warehouse a 15 perc Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="335ac-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="335ac-339">Fájl alapú adattároló</span><span class="sxs-lookup"><span data-stu-id="335ac-339">File-based data stores</span></span>
<span data-ttu-id="335ac-340">*(A Blob storage, Data Lake Store, Amazon S3, a helyi fájlrendszer és a helyszíni HDFS tartalmazza)*</span><span class="sxs-lookup"><span data-stu-id="335ac-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="335ac-341">**Másolja a viselkedés**: adatok másolása egy másik fájlalapú tároló, ha a másolási tevékenység keresztül három pontot tartalmaz a **copyBehavior** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="335ac-342">Megőrzi a hierarchia, hierarchia simítja, illetve egyesíti a fájlokat.</span><span class="sxs-lookup"><span data-stu-id="335ac-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="335ac-343">Hierarchia egybesimítását vagy megőrzi az rendelkezik kevéssé vagy egyáltalán ne teljesítményigény, de a fájlok egyesítése hatására a teljesítményigény növelése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="335ac-344">**Fájl formátuma és tömörítést**: lásd: a [szempontok a szerializálás és a deszerializálás](#considerations-for-serialization-and-deserialization) és [tömörítés szempontjai](#considerations-for-compression) szakaszokban további részleteket a teljesítmény javítása érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="335ac-345">**BLOB-tároló**: jelenleg Blob storage támogatja csak blokkblobokat optimalizált adatátvitel és átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="335ac-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="335ac-346">A **helyszíni fájlrendszerek** használatát igénylő forgatókönyvek **az adatkezelési átjáró**, tekintse meg a [az adatkezelési átjáró szempontjai](#considerations-for-data-management-gateway) szakasz.</span><span class="sxs-lookup"><span data-stu-id="335ac-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="335ac-347">Relációs adattároló.</span><span class="sxs-lookup"><span data-stu-id="335ac-347">Relational data stores</span></span>
<span data-ttu-id="335ac-348">*(Tartalmazza az SQL-adatbázis, az SQL Data Warehouse, az SQL Server-adatbázisok és Oracle-adatbázis)*</span><span class="sxs-lookup"><span data-stu-id="335ac-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="335ac-349">**Másolja a viselkedés**: attól függően, hogy a Tulajdonságok még állított **sqlSink**, másolási tevékenység írja az adatokat a céladatbázis különböző módon.</span><span class="sxs-lookup"><span data-stu-id="335ac-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="335ac-350">Alapértelmezés szerint az adatok adatátviteli szolgáltatás által a tömeges másolási API lehet adatokat beszúrni hozzáfűzése módját, amely a legjobb teljesítményt biztosít.</span><span class="sxs-lookup"><span data-stu-id="335ac-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="335ac-351">Konfigurálja a gyűjtő tárolt eljárást, ha az adatbázis az adatokat soronként egyidejűleg ahelyett, hogy a tömeges betöltés vonatkozik.</span><span class="sxs-lookup"><span data-stu-id="335ac-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="335ac-352">Teljesítmény jelentősen csökken.</span><span class="sxs-lookup"><span data-stu-id="335ac-352">Performance drops significantly.</span></span> <span data-ttu-id="335ac-353">Ha az adatkészlet túl nagy, ha lehetséges, fontolja meg, hogy használja a **sqlWriterCleanupScript** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="335ac-354">Ha konfigurálja az **sqlWriterCleanupScript** minden másolási tevékenységhez tulajdonság futtatásához, a szolgáltatás váltja ki a parancsprogramot, és majd illessze be az adatokat a tömeges másolási API-t használja.</span><span class="sxs-lookup"><span data-stu-id="335ac-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="335ac-355">Például az egész tábla felülírja a legújabb adatokkal, is megadhat egy parancsfájlt, amely először a forrás az új adatok tömeges-betöltés előtt az összes bejegyzés törlése.</span><span class="sxs-lookup"><span data-stu-id="335ac-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="335ac-356">**Minta és kötegelt adatméret**:</span><span class="sxs-lookup"><span data-stu-id="335ac-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="335ac-357">A következő tábla sémáját hatással van a Másolás átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="335ac-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="335ac-358">Adatok akkora másolásához nagy sorméret lehetővé teszi egy kis sorméret jobb teljesítményt, mert az adatbázis hatékonyabban véglegesítheti az adatok kevesebb kötegek.</span><span class="sxs-lookup"><span data-stu-id="335ac-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="335ac-359">Másolási tevékenység adatokat egy sorozat része kötegek beszúrása</span><span class="sxs-lookup"><span data-stu-id="335ac-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="335ac-360">Beállíthatja a sorok számát egy kötegben használatával a **writeBatchSize** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="335ac-361">Ha az adatok kis sora van, akkor megadhatja a **writeBatchSize** tulajdonság alacsonyabb kötegelt terheléssel jár és nagyobb átviteli sebességgel kihasználják a magasabb értékű.</span><span class="sxs-lookup"><span data-stu-id="335ac-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="335ac-362">Ha az adatok sor mérete nagy, legyen óvatos növelésével **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="335ac-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="335ac-363">Nagy érték egy példány hibáját okozta. az adatbázis túlterhelés vezethet.</span><span class="sxs-lookup"><span data-stu-id="335ac-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="335ac-364">A **helyszíni relációs adatbázisok** , például az SQL Server és Oracle, amelyek használatát **az adatkezelési átjáró**, tekintse meg a [az adatkezelési átjárószempontjai](#considerations-for-data-management-gateway)szakasz.</span><span class="sxs-lookup"><span data-stu-id="335ac-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="335ac-365">NoSQL-tárolókon</span><span class="sxs-lookup"><span data-stu-id="335ac-365">NoSQL stores</span></span>
<span data-ttu-id="335ac-366">*(Tartalmazza a Table storage és Azure Cosmos DB)*</span><span class="sxs-lookup"><span data-stu-id="335ac-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="335ac-367">A **Table storage**:</span><span class="sxs-lookup"><span data-stu-id="335ac-367">For **Table storage**:</span></span>
  * <span data-ttu-id="335ac-368">**Partíció**: írás a kihagyásos partíciók jelentősen csökkenti a teljesítményt.</span><span class="sxs-lookup"><span data-stu-id="335ac-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="335ac-369">A forrásadatok rendezze partíciós kulcs, így az adatok bekerülnek hatékonyan egy partíciót egymás után, vagy állítsa be az adatokat írni egy olyan partíciót logikát.</span><span class="sxs-lookup"><span data-stu-id="335ac-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="335ac-370">A **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="335ac-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="335ac-371">**Kötegméret**: A **writeBatchSize** tulajdonság határozza meg a párhuzamos kérelmek száma a dokumentumok létrehozásához Azure Cosmos DB szolgáltatáshoz.</span><span class="sxs-lookup"><span data-stu-id="335ac-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="335ac-372">Jobb teljesítmény várható növelésével **writeBatchSize** , mert több párhuzamos kérések érkeznek, az Azure Cosmos-Adatbázishoz.</span><span class="sxs-lookup"><span data-stu-id="335ac-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="335ac-373">Azonban figyelemmel a sávszélesség-szabályozás írásakor Azure Cosmos DB (hibaüzenet: "kérelmek aránya az nagy").</span><span class="sxs-lookup"><span data-stu-id="335ac-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="335ac-374">Számos tényező okozhat, szabályozás, dokumentum mérete, beleértve a dokumentumok, és a célgyűjtemény indexelési házirendet számát.</span><span class="sxs-lookup"><span data-stu-id="335ac-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="335ac-375">Magasabb másolási átviteli sebesség eléréséhez érdemes lehet jobban gyűjteménye, például S3.</span><span class="sxs-lookup"><span data-stu-id="335ac-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="335ac-376">Szempontok a szerializálás és a deszerializálás</span><span class="sxs-lookup"><span data-stu-id="335ac-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="335ac-377">Szerializálás és a deszerializálás akkor fordulhat elő, ha a bemeneti adatkészlet vagy kimeneti adatkészlet egy fájlt.</span><span class="sxs-lookup"><span data-stu-id="335ac-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="335ac-378">Lásd: [fájl- és tömörítési formátum támogatott](data-factory-supported-file-and-compression-formats.md) a másolási tevékenység által támogatott fájlformátumok adatokkal.</span><span class="sxs-lookup"><span data-stu-id="335ac-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="335ac-379">**Másolja a viselkedés**:</span><span class="sxs-lookup"><span data-stu-id="335ac-379">**Copy behavior**:</span></span>

* <span data-ttu-id="335ac-380">A fájlok másolása a fájl alapú adattárolók között:</span><span class="sxs-lookup"><span data-stu-id="335ac-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="335ac-381">Ha a bemeneti és kimeneti adatkészletek mindkét rendelkeznek azonos vagy nem fájl formátuma beállítások, az adatátviteli szolgáltatás hajtja végre a szerializálás vagy deszerializálás nélkül bináris másolatát.</span><span class="sxs-lookup"><span data-stu-id="335ac-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="335ac-382">A forgatókönyv, amelyben a forrás és a fogadó fájl formátuma beállítások eltérnek egymáshoz képest magasabb átviteli láthatja.</span><span class="sxs-lookup"><span data-stu-id="335ac-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="335ac-383">Ha a bemeneti és kimeneti adatkészletek mindkét szöveges formátumú, és csak a kódolás különböző típusú, az adatok mozgása szolgáltatásnak csak nincs kódolási átalakítás.</span><span class="sxs-lookup"><span data-stu-id="335ac-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="335ac-384">Nem minden szerializálási és néhány bináris másolatot terhet képest teljesítményt deszerializálás.</span><span class="sxs-lookup"><span data-stu-id="335ac-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="335ac-385">Ha a bemeneti és kimeneti adatkészletek mindkét rendelkeznek különböző fájlformátumok vagy különböző konfigurációkat, például az elválasztó karaktert, az adatátviteli szolgáltatás deserializes forrásadatok adatfolyamként, átalakítás és majd szerializálni, a megadott kimeneti formátumra alakítja.</span><span class="sxs-lookup"><span data-stu-id="335ac-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="335ac-386">Ez a művelet egy sokkal jelentős teljesítménybeli, más esetekben terhet képest eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="335ac-387">Belőle a tárolóban, amely nem fájl alapú (például a tárolóból fájlalapú relációs áruház) fájlokat másolja, a szerializálás vagy deszerializálás lépésre szükség.</span><span class="sxs-lookup"><span data-stu-id="335ac-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="335ac-388">Ez a lépés jelentős teljesítménybeli terhelést eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="335ac-389">**Fájlformátum**: A fájlformátum választja hatással lehetnek a fájlmásolás.</span><span class="sxs-lookup"><span data-stu-id="335ac-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="335ac-390">Például az Avro adatokkal metaadatokat tárol kompakt bináris formátumot.</span><span class="sxs-lookup"><span data-stu-id="335ac-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="335ac-391">Széles körű támogatást nyújtanak a Hadoop rendszerben, feldolgozása és lekérdezéséhez rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="335ac-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="335ac-392">Az Avro azonban drágább a szerializálás és a deszerializálás, amely szövegformátum képest alacsonyabb másolási teljesítményt eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="335ac-393">Győződjön meg a kiválasztott fájl formátuma a feldolgozási folyamat során holistically.</span><span class="sxs-lookup"><span data-stu-id="335ac-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="335ac-394">Útmutató milyen formában az adatokat tárolja, forrás adattárolókhoz vagy kibontani a külső rendszerek; a legjobb formátumát tárolási elemzésfeldolgozási és lekérdezése; és milyen formátumban az adatok exportálja a jelentéskészítés és a képi megjelenítés eszközök adatpiacait.</span><span class="sxs-lookup"><span data-stu-id="335ac-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="335ac-395">Egyes esetekben az optimálisnál gyengébb fájl formátuma olvasási és írási teljesítmény lehet hasznos, amikor az átfogó analitikai folyamat érdemes.</span><span class="sxs-lookup"><span data-stu-id="335ac-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="335ac-396">Tömörítés szempontjai</span><span class="sxs-lookup"><span data-stu-id="335ac-396">Considerations for compression</span></span>
<span data-ttu-id="335ac-397">Ha a bemeneti vagy kimeneti adatkészlet egy olyan fájl, beállíthatja a másolási tevékenység tömörítése és kibontása végrehajtásához, írja az adatokat a cél.</span><span class="sxs-lookup"><span data-stu-id="335ac-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="335ac-398">Ha úgy dönt, hogy a tömörítés, ellenőrizze-e egy bemeneti/kimeneti (I/O) közötti kompromisszumot és a CPU.</span><span class="sxs-lookup"><span data-stu-id="335ac-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="335ac-399">A számítási erőforrásokat a felesleges adatok költségek tömörítése.</span><span class="sxs-lookup"><span data-stu-id="335ac-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="335ac-400">De ismét csökkenti a hálózati i/o- és tárolási.</span><span class="sxs-lookup"><span data-stu-id="335ac-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="335ac-401">Attól függően, hogy az adatok egy teljes másolatot átviteli sebességének program jelenhet meg.</span><span class="sxs-lookup"><span data-stu-id="335ac-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="335ac-402">**Kodek**: másolási tevékenység gzip, bzip2 és Deflate tömörítést típusokat támogatja.</span><span class="sxs-lookup"><span data-stu-id="335ac-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="335ac-403">Az Azure HDInsight feldolgozásra összes háromféle is felhasználhatnak.</span><span class="sxs-lookup"><span data-stu-id="335ac-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="335ac-404">Minden egyes tömörítési kodek előnye is van.</span><span class="sxs-lookup"><span data-stu-id="335ac-404">Each compression codec has advantages.</span></span> <span data-ttu-id="335ac-405">Például bzip2 rendelkezik a legalacsonyabb másolási átviteli, de a legjobb Hive lekérdezés teljesítmény bzip2 kap, mert feldolgozásra felosztása.</span><span class="sxs-lookup"><span data-stu-id="335ac-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="335ac-406">A gzip legkiegyensúlyozottabb a beállítást, és a leggyakrabban használt.</span><span class="sxs-lookup"><span data-stu-id="335ac-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="335ac-407">Válassza ki a kodek a végpont forgatókönyvéhez leginkább illő.</span><span class="sxs-lookup"><span data-stu-id="335ac-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="335ac-408">**Szint**: minden tömörítési kodek két lehetőség közül választhat: leggyorsabb tömörített és optimális tömörített.</span><span class="sxs-lookup"><span data-stu-id="335ac-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="335ac-409">A leggyorsabb tömörített beállítás akkor is, ha a fájl nem optimális tömörített, minél gyorsabban tömöríti az adatokat.</span><span class="sxs-lookup"><span data-stu-id="335ac-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="335ac-410">Az optimális tömörített beállítás több időt tölt a tömörítést, és adatok mennyisége minimális eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="335ac-411">Mindkét lehetőség megtekintéséhez, amely biztosítja, hogy jobb összesített teljesítményt abban az esetben, ha tesztelheti.</span><span class="sxs-lookup"><span data-stu-id="335ac-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="335ac-412">**Szempont**: egy nagy mennyiségű adatot egy helyi tárolóban és a felhő közötti másolásához érdemes ideiglenes blob-tároló, tömörítve történjen.</span><span class="sxs-lookup"><span data-stu-id="335ac-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="335ac-413">Átmeneti tárolás használatával akkor hasznos, ha a vállalati hálózat és az Azure-szolgáltatások a sávszélesség korlátozó tényezővé, és azt szeretné, hogy a bemeneti adatkészlet és a kimeneti adatkészlet mindkét tömörítetlenül.</span><span class="sxs-lookup"><span data-stu-id="335ac-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="335ac-414">Pontosabban a egyetlen másolási tevékenység során is felosztása két másolási tevékenység.</span><span class="sxs-lookup"><span data-stu-id="335ac-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="335ac-415">Az első másolási tevékenység átmásolja a forrás egy ideiglenes vagy átmeneti blob tömörített formátumban.</span><span class="sxs-lookup"><span data-stu-id="335ac-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="335ac-416">A második másolási tevékenység másolja át a tömörített adatok átmeneti, és amíg a gyűjtő ír majd kibontja.</span><span class="sxs-lookup"><span data-stu-id="335ac-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="335ac-417">Oszlopleképezés szempontjai</span><span class="sxs-lookup"><span data-stu-id="335ac-417">Considerations for column mapping</span></span>
<span data-ttu-id="335ac-418">Beállíthatja a **columnMappings** tulajdonságot a másolási tevékenység a térkép összes vagy a kimeneti oszlop a bemeneti oszlopok egy részét.</span><span class="sxs-lookup"><span data-stu-id="335ac-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="335ac-419">Az adatátviteli szolgáltatás a adatokat olvas a forráskiszolgálóról, miután kell oszlopleképezés végre az adatokat, mielőtt írja az adatokat a fogadó.</span><span class="sxs-lookup"><span data-stu-id="335ac-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="335ac-420">A felesleges feldolgozási másolási átviteli csökkenti.</span><span class="sxs-lookup"><span data-stu-id="335ac-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="335ac-421">Ha a forrás adattár lekérdezhető, például ha például az SQL-adatbázis vagy SQL Server relációs áruházbeli, vagy ha például a Table storage vagy Azure Cosmos DB, egy NoSQL-tároló érdemes kérdez le, az oszlop szűrési és átrendezése logikát a **lekérdezés** tulajdonság oszlopleképezés használata helyett.</span><span class="sxs-lookup"><span data-stu-id="335ac-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="335ac-422">Ezzel a módszerrel a leképezés során az adatátviteli szolgáltatás adatokat olvas a forrás-tárolót, ahol használata sokkal hatékonyabb következik be.</span><span class="sxs-lookup"><span data-stu-id="335ac-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="335ac-423">Egyéb szempontok</span><span class="sxs-lookup"><span data-stu-id="335ac-423">Other considerations</span></span>
<span data-ttu-id="335ac-424">Ha át kívánja másolni adatok mérete túl nagy, módosíthatja az adatokat a slicing mechanizmus használatával a Data Factory az üzleti logika további partícióra.</span><span class="sxs-lookup"><span data-stu-id="335ac-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="335ac-425">Ezt követően ütemezni a másolási tevékenység gyakoribb futtatásához minden másolási tevékenységhez, futtassa a adatméret csökkentése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="335ac-426">Legyen óvatos adatkészletek és a Data Factory igénylő ugyanazon adattár-összekötőhöz egyszerre másolási tevékenység száma.</span><span class="sxs-lookup"><span data-stu-id="335ac-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="335ac-427">Sok egyidejű másolási feladat lehet, hogy szabályozni a tárolóban, így csökkent teljesítményt, a másolási feladat belső, az újrapróbálkozásokat és néhány esetben végrehajtása sikertelen.</span><span class="sxs-lookup"><span data-stu-id="335ac-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="335ac-428">Mintaforgatókönyv: egy a helyszíni SQL Server másolását. a Blob storage</span><span class="sxs-lookup"><span data-stu-id="335ac-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="335ac-429">**A forgatókönyv**: egy folyamatot egy helyi SQL Server a Blob storage CSV formátumú adatokat másolni épül.</span><span class="sxs-lookup"><span data-stu-id="335ac-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="335ac-430">Ahhoz, hogy gyorsabban a másolási feladat, a CSV-fájlok lehet tömörített bzip2 formátumba.</span><span class="sxs-lookup"><span data-stu-id="335ac-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="335ac-431">**Vizsgálati és elemzési**: az átviteli sebessége a másolási tevékenység érték kevesebb, mint 2 MB/s, amely sokkal lassabb, mint a teljesítmény teljesítményteszt.</span><span class="sxs-lookup"><span data-stu-id="335ac-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="335ac-432">**Teljesítményelemzés és hangolása**: a teljesítmény a probléma elhárításához vizsgáljuk meg az adatok feldolgozása és áthelyezése módját.</span><span class="sxs-lookup"><span data-stu-id="335ac-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="335ac-433">**Olvassa el az adatok**: átjáró megnyílik az SQL-kiszolgálóval, és elküldi a lekérdezést.</span><span class="sxs-lookup"><span data-stu-id="335ac-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="335ac-434">SQL Server az adatfolyamot küld átjáró az intraneten keresztül válaszol.</span><span class="sxs-lookup"><span data-stu-id="335ac-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="335ac-435">**Szerializálható és az adatok tömörítése**: átjáró rendezi sorba a CSV formátumnak adatfolyamban, és tömöríti az adatokat, bzip2 adatfolyamba.</span><span class="sxs-lookup"><span data-stu-id="335ac-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="335ac-436">**Adatírás**: átjáró feltölti a bzip2 adatfolyam a Blob storage az interneten keresztül.</span><span class="sxs-lookup"><span data-stu-id="335ac-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="335ac-437">Ahogy látja, folyamatban van-e az adatok feldolgozása és adatfolyam-továbbítási soros módon áthelyezése: SQL Server > LAN > átjáró > WAN > Blob-tároló.</span><span class="sxs-lookup"><span data-stu-id="335ac-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="335ac-438">**Az általános teljesítményt a minimális átviteli engedi át keresztül a feldolgozási sor**.</span><span class="sxs-lookup"><span data-stu-id="335ac-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Adatfolyam](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="335ac-440">Egy vagy több, az alábbi tényezők okozhat a teljesítménybeli szűk keresztmetszetek:</span><span class="sxs-lookup"><span data-stu-id="335ac-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="335ac-441">**Forrás**: az SQL Server maga rendelkezik alacsony átviteli túl nagy terhelés miatt.</span><span class="sxs-lookup"><span data-stu-id="335ac-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="335ac-442">**Az adatkezelési átjáró**:</span><span class="sxs-lookup"><span data-stu-id="335ac-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="335ac-443">**LAN**: átjáró messze az SQL Server-számítógépen található, és kis sávszélességű kapcsolattal rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="335ac-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="335ac-444">**Átjáró**: átjáró elérte a következő műveletek végrehajtásához a terhelés korlátozások vonatkoznak:</span><span class="sxs-lookup"><span data-stu-id="335ac-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="335ac-445">**Szerializálási**: lassú átviteli szerializálása közben a CSV formátumnak adatfolyam rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="335ac-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="335ac-446">**Tömörítés**: úgy döntött, hogy a lassú tömörítési kodek (például bzip2, amely az alapvető i7 2,8 MB/s).</span><span class="sxs-lookup"><span data-stu-id="335ac-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="335ac-447">**WAN**: a vállalati hálózat és az Azure-szolgáltatások között sávszélessége alacsony (például T1 = 1,544 kbps; T2 = 6,312 kbit/s).</span><span class="sxs-lookup"><span data-stu-id="335ac-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="335ac-448">**Gyűjtése**: a Blob storage alacsony átviteli rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="335ac-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="335ac-449">(Ez a forgatókönyv nem valószínű, mert az SLA garantálja 60 MB/s legalább.)</span><span class="sxs-lookup"><span data-stu-id="335ac-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="335ac-450">Ebben az esetben bzip2 adattömörítés előfordulhat, hogy lehet lassítja a teljes folyamat.</span><span class="sxs-lookup"><span data-stu-id="335ac-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="335ac-451">A gzip tömörítési kodek átváltás, előfordulhat, hogy a szűk keresztmetszetet megkönnyítése érdekében.</span><span class="sxs-lookup"><span data-stu-id="335ac-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="335ac-452">Lehetséges eset: párhuzamos példányát használhatja az</span><span class="sxs-lookup"><span data-stu-id="335ac-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="335ac-453">**A forgatókönyv I:** 1 MB-os fájlok másolása 1000 a helyszíni fájlrendszerben azon Blob Storage tárolóban.</span><span class="sxs-lookup"><span data-stu-id="335ac-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="335ac-454">**Elemzés és teljesítményhangolás**: példát, ha egy darab négyportos core számítógépen telepített átjárót adat-előállító segítségével 16 párhuzamos másolatok helyezze át fájlokat a fájlrendszerből a Blob storage egyidejűleg.</span><span class="sxs-lookup"><span data-stu-id="335ac-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="335ac-455">A párhuzamos végrehajtás nagyobb teljesítményt eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="335ac-456">Emellett közvetlenül megadhatja a párhuzamos másolatok száma.</span><span class="sxs-lookup"><span data-stu-id="335ac-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="335ac-457">Sok kisméretű fájlok másolásakor párhuzamos másolatok jelentősen segíthet az átviteli sebesség erőforrások hatékonyabb használata.</span><span class="sxs-lookup"><span data-stu-id="335ac-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![1. forgatókönyv](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="335ac-459">**A forgatókönyv II**: 20 blobok 500 MB-os blobtárolóból Data Lake Store Analytics másolja, majd ezután a teljesítmény hangolására.</span><span class="sxs-lookup"><span data-stu-id="335ac-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="335ac-460">**Elemzés és teljesítményhangolás**: Ebben a forgatókönyvben adat-előállító átmásolja az adatokat a Blob storage Data Lake Store single-példány használatával (**parallelCopies** állítsa 1-) és egyetlen-felhőbeli adatát adatátviteli egység.</span><span class="sxs-lookup"><span data-stu-id="335ac-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="335ac-461">Az átviteli sebesség azt láthatja, amely közel ismerteti a [teljesítmény útmutató szakaszban](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="335ac-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![2. forgatókönyv](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="335ac-463">**A forgatókönyv III**: egyes fájl mérete nagyobb, mint MB több tucatnyi és a teljes kötet mérete nagy.</span><span class="sxs-lookup"><span data-stu-id="335ac-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="335ac-464">**Elemzés és a teljesítmény bekapcsolásáról**: növelése **parallelCopies** nem egy egyetlen-felhő DMU az erőforrás-korlátozások miatt másolási jobb teljesítményt eredményez.</span><span class="sxs-lookup"><span data-stu-id="335ac-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="335ac-465">Ehelyett adjon meg további felhőalapú DMUs az adatátvitel végrehajtásához további erőforrások eléréséhez.</span><span class="sxs-lookup"><span data-stu-id="335ac-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="335ac-466">Ne adjon meg egy értéket a **parallelCopies** tulajdonság.</span><span class="sxs-lookup"><span data-stu-id="335ac-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="335ac-467">Adat-előállító kezeli a párhuzamos végrehajtás meg.</span><span class="sxs-lookup"><span data-stu-id="335ac-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="335ac-468">Ebben az esetben, ha **cloudDataMovementUnits** 4, körülbelül átviteli négy alkalommal következik be.</span><span class="sxs-lookup"><span data-stu-id="335ac-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![3. forgatókönyv](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="335ac-470">Referencia</span><span class="sxs-lookup"><span data-stu-id="335ac-470">Reference</span></span>
<span data-ttu-id="335ac-471">Az alábbiakban a teljesítmény figyelése és hivatkozások beállítása a támogatott adatokat tároló egy részénél:</span><span class="sxs-lookup"><span data-stu-id="335ac-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="335ac-472">Az Azure Storage (beleértve a Blob storage és a Table storage): [Azure Storage méretezhetőségi célok](../storage/common/storage-scalability-targets.md) és [Azure Storage teljesítményére és méretezhetőségére ellenőrzőlista](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="335ac-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="335ac-473">Az Azure SQL Database: Is [figyelemmel kísérni a teljesítményét](../sql-database/sql-database-single-database-monitor.md) , és ellenőrizze az adatbázis tranzakciós egységek (DTU) százalékos aránya</span><span class="sxs-lookup"><span data-stu-id="335ac-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="335ac-474">Az SQL Data Warehouse: Alkalmasságát mérik adattárházegységek (dwu-k); Lásd: [kezelése számítási teljesítményt az Azure SQL Data Warehouse (áttekintés)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span><span class="sxs-lookup"><span data-stu-id="335ac-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="335ac-475">Az Azure Cosmos DB: [teljesítményszintek az Azure Cosmos-Adatbázisba](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="335ac-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="335ac-476">A helyszíni SQL Server: [figyelő és a teljesítmény hangolni?](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="335ac-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="335ac-477">A helyi fájlkiszolgáló: [teljesítményhangolás fájlkiszolgálók](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="335ac-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
