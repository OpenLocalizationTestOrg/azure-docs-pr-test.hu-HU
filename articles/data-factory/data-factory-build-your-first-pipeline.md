---
title: "Data Factory-oktatóanyag: adatok első folyamatát |} Microsoft Docs"
description: "Az Azure Data Factory oktatóanyag bemutatja, hogyan hozhat létre és dolgozza fel a Hive parancsfájl használata a Hadoop-fürthöz adatok adat-előállító ütemezni."
services: data-factory
keywords: "az Azure data factory oktatóanyag, hadoop-fürt, hadoop hive"
documentationcenter: 
author: spelluru
manager: jhubbard
editor: 
ms.assetid: 81f36c76-6e78-4d93-a3f2-0317b413f1d0
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 08e2988d455cca21726162d9fb128e91fd51f463
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 08/29/2017
---
# <a name="tutorial-build-your-first-pipeline-to-transform-data-using-hadoop-cluster"></a><span data-ttu-id="f5c2f-104">Oktatóanyag: Felépítheti első folyamatát átalakítására adatok Hadoop-fürt használatával</span><span class="sxs-lookup"><span data-stu-id="f5c2f-104">Tutorial: Build your first pipeline to transform data using Hadoop cluster</span></span>
> [!div class="op_single_selector"]
> * [<span data-ttu-id="f5c2f-105">Áttekintés és előfeltételek</span><span class="sxs-lookup"><span data-stu-id="f5c2f-105">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="f5c2f-106">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="f5c2f-106">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="f5c2f-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="f5c2f-107">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="f5c2f-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="f5c2f-108">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="f5c2f-109">Resource Manager-sablon</span><span class="sxs-lookup"><span data-stu-id="f5c2f-109">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="f5c2f-110">REST API</span><span class="sxs-lookup"><span data-stu-id="f5c2f-110">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="f5c2f-111">Ebben az oktatóanyagban a első Azure data factory és olyan adatokat hoz létre.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-111">In this tutorial, you build your first Azure data factory with a data pipeline.</span></span> <span data-ttu-id="f5c2f-112">A feldolgozási sor bemeneti adatok átalakítja az Azure HDInsight (Hadoop) eredményezett kimeneti adatokat fürtökön Hive parancsfájl futtatásával.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-112">The pipeline transforms input data by running Hive script on an Azure HDInsight (Hadoop) cluster to produce output data.</span></span>  

<span data-ttu-id="f5c2f-113">Ez a cikk áttekintése és az oktatóanyag előfeltételei tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-113">This article provides overview and prerequisites for the tutorial.</span></span> <span data-ttu-id="f5c2f-114">Miután elvégezte az előfeltételeket, az oktatóanyag a következő eszközök/SDK-k egyikével teheti: Azure-portálon, a Visual Studio, a PowerShell, a Resource Manager-sablon, a REST API-t.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-114">After you complete the prerequisites, you can do the tutorial using one of the following tools/SDKs: Azure portal, Visual Studio, PowerShell, Resource Manager template, REST API.</span></span> <span data-ttu-id="f5c2f-115">Válassza ki a legördülő lista elején (vagy) az oktatóanyag segítségével ezen beállítások valamelyikét kell tennie a cikk végén hivatkozások a lehetőségek közül.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-115">Select one of the options in the drop-down list at the beginning (or) links at the end of this article to do the tutorial using one of these options.</span></span>    

## <a name="tutorial-overview"></a><span data-ttu-id="f5c2f-116">Az oktatóanyag áttekintése</span><span class="sxs-lookup"><span data-stu-id="f5c2f-116">Tutorial overview</span></span>
<span data-ttu-id="f5c2f-117">Ebben az oktatóanyagban hajtsa végre a következő lépéseket:</span><span class="sxs-lookup"><span data-stu-id="f5c2f-117">In this tutorial, you perform the following steps:</span></span>

1. <span data-ttu-id="f5c2f-118">Hozzon létre egy **adat-előállító**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-118">Create a **data factory**.</span></span> <span data-ttu-id="f5c2f-119">Egy adat-előállító tartalmazhat egy vagy több, helyezze át, és az adatok átalakítása adatok folyamatok.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-119">A data factory can contain one or more data pipelines that move and transform data.</span></span> 

    <span data-ttu-id="f5c2f-120">Ebben az oktatóanyagban létrehoz egy folyamatot, az adat-előállítóban.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-120">In this tutorial, you create one pipeline in the data factory.</span></span> 
2. <span data-ttu-id="f5c2f-121">Hozzon létre egy **csővezeték**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-121">Create a **pipeline**.</span></span> <span data-ttu-id="f5c2f-122">Egy folyamat rendelkezhet egy vagy több tevékenységet (Példa: másolási tevékenység során, a HDInsight Hive tevékenység).</span><span class="sxs-lookup"><span data-stu-id="f5c2f-122">A pipeline can have one or more activities (Examples: Copy Activity, HDInsight Hive Activity).</span></span> <span data-ttu-id="f5c2f-123">A példa a Hive parancsfájlok futtatására szolgál egy HDInsight Hadoop-fürt HDInsight Hive tevékenységet használja.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-123">This sample uses the HDInsight Hive activity that runs a Hive script on a HDInsight Hadoop cluster.</span></span> <span data-ttu-id="f5c2f-124">A parancsfájl először táblázatot hoz létre, amely a nyers webes naplóadatokat, az Azure blob storage-ban tárolt hivatkozik, és majd particionálja a nyers adatok hónap és év szerint.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-124">The script first creates a table that references the raw web log data stored in Azure blob storage and then partitions the raw data by year and month.</span></span>

    <span data-ttu-id="f5c2f-125">Ebben az oktatóanyagban a folyamatot használja a Hive tevékenység adatok átalakítására futtatja a Hive-lekérdezések egy Azure HDInsight Hadoop-fürt.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-125">In this tutorial, the pipeline uses the Hive Activity to transform data by running a Hive query on an Azure HDInsight Hadoop cluster.</span></span> 
3. <span data-ttu-id="f5c2f-126">Hozzon létre **összekapcsolt szolgáltatások**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-126">Create **linked services**.</span></span> <span data-ttu-id="f5c2f-127">Adattároló csatolásához összekapcsolt szolgáltatás vagy egy számítási szolgáltatást, hogy a data factory létrehozása.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-127">You create a linked service to link a data store or a compute service to the data factory.</span></span> <span data-ttu-id="f5c2f-128">Például az Azure Storage adattárat a feldolgozási tevékenységek bemeneti/kimeneti adatokat tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-128">A data store such as Azure Storage holds input/output data of activities in the pipeline.</span></span> <span data-ttu-id="f5c2f-129">A számítási szolgáltatás, például a HDInsight Hadoop-fürt folyamatok/átalakítások adatokat.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-129">A compute service such as HDInsight Hadoop cluster processes/transforms data.</span></span>

    <span data-ttu-id="f5c2f-130">Ebben az oktatóanyagban létrehoz két összekapcsolt szolgáltatások: **Azure Storage** és **Azure HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-130">In this tutorial, you create two linked services: **Azure Storage** and **Azure HDInsight**.</span></span> <span data-ttu-id="f5c2f-131">Az Azure Storage társított szolgáltatás hivatkozások egy Azure Storage-fiókot, amely tárolja a bemeneti/kimeneti adatok data factoryval való.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-131">The Azure Storage linked service links an Azure Storage Account that holds the input/output data to the data factory.</span></span> <span data-ttu-id="f5c2f-132">Az Azure HDInsight kapcsolódó szolgáltatás hivatkozások adatok data factoryval való átalakításához használt Azure HDInsight-fürtöt.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-132">Azure HDInsight linked service links an Azure HDInsight cluster that is used to transform data to the data factory.</span></span> 
3. <span data-ttu-id="f5c2f-133">Hozzon létre a bemeneti és kimeneti **adatkészletek**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-133">Create input and output **datasets**.</span></span> <span data-ttu-id="f5c2f-134">Egy bemeneti adatkészlet egy tevékenységhez, a folyamat a bemeneti és egy kimeneti adatkészlet a tevékenység kimeneti jelenti.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-134">An input dataset represents the input for an activity in the pipeline and an output dataset represents the output for the activity.</span></span>

    <span data-ttu-id="f5c2f-135">Ebben az oktatóanyagban a bemeneti és kimeneti adatkészletek adja meg a bemeneti és kimeneti adatok az Azure Blob Storage helyét.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-135">In this tutorial, the input and output datasets specify locations of input and output data in the Azure Blob Storage.</span></span> <span data-ttu-id="f5c2f-136">Az Azure tárolás társított szolgáltatásának határozza meg, mi az Azure Storage-fiókot használni.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-136">The Azure Storage linked service specifies what Azure Storage Account is used.</span></span> <span data-ttu-id="f5c2f-137">Egy bemeneti adatkészlet határozza meg, ha a bemeneti fájlok találhatók, és egy kimeneti adatkészlet határozza meg, ahol a kimeneti fájlok kerülnek.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-137">An input dataset specifies where the input files are located and an output dataset specifies where the output files are placed.</span></span> 


<span data-ttu-id="f5c2f-138">Lásd: [Bevezetés az Azure Data Factory](data-factory-introduction.md) cikk részletes áttekintés az Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-138">See [Introduction to Azure Data Factory](data-factory-introduction.md) article for a detailed overview of Azure Data Factory.</span></span>
  
<span data-ttu-id="f5c2f-139">Itt a **diagram nézet** az adat-előállító minta ebben az oktatóanyagban készít.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-139">Here is the **diagram view** of the sample data factory you build in this tutorial.</span></span> <span data-ttu-id="f5c2f-140">**MyFirstPipeline** egy tevékenysége, amely akkor Hive típusú **AzureBlobInput** bemeneti és előállított dataset **AzureBlobOutput** egy kimeneti adatkészletet.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-140">**MyFirstPipeline** has one activity of type Hive that consumes **AzureBlobInput** dataset as an input and produces **AzureBlobOutput** dataset as an output.</span></span> 

![A Data Factory oktatóanyag diagram nézet](media/data-factory-build-your-first-pipeline/data-factory-tutorial-diagram-view.png)


<span data-ttu-id="f5c2f-142">Ebben az oktatóanyagban **inputdata** mappában található a **adfgetstarted** Azure blob-tároló input.log nevű egyetlen fájlt tartalmaz.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-142">In this tutorial, **inputdata** folder of the **adfgetstarted** Azure blob container contains one file named input.log.</span></span> <span data-ttu-id="f5c2f-143">Ez a naplófájl a három hónapos bejegyzésekkel rendelkezik: január, február és a 2016. március.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-143">This log file has entries from three months: January, February, and March of 2016.</span></span> <span data-ttu-id="f5c2f-144">Az alábbiakban a minta sorok minden hónapban a bemeneti fájl.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-144">Here are the sample rows for each month in the input file.</span></span> 

```
2016-01-01,02:01:09,SAMPLEWEBSITE,GET,/blogposts/mvc4/step2.png,X-ARR-LOG-ID=2ec4b8ad-3cf0-4442-93ab-837317ece6a1,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,53175,871 
2016-02-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
2016-03-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
```

<span data-ttu-id="f5c2f-145">A fájl feldolgozása a folyamat HDInsight Hive tevékenységet, a tevékenység futtatása egy Hive-parancsfájl a HDInsight-fürt partíciókat, hogy évhez és hónaphoz által bemeneti adatai.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-145">When the file is processed by the pipeline with HDInsight Hive Activity, the activity runs a Hive script on the HDInsight cluster that partitions input data by year and month.</span></span> <span data-ttu-id="f5c2f-146">A parancsfájl minden hónap bejegyzéseket tartalmazó fájl tartalmazó három kimeneti mappákat hoz létre.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-146">The script creates three output folders that contain a file with entries from each month.</span></span>  

```
adfgetstarted/partitioneddata/year=2016/month=1/000000_0
adfgetstarted/partitioneddata/year=2016/month=2/000000_0
adfgetstarted/partitioneddata/year=2016/month=3/000000_0
```

<span data-ttu-id="f5c2f-147">A fent látható minta sorok, az első másikat (2016-01-01) íródik a 000000_0 fájl az adott hónapban = 1 mappa.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-147">From the sample lines shown above, the first one (with 2016-01-01) is written to the 000000_0 file in the month=1 folder.</span></span> <span data-ttu-id="f5c2f-148">Hasonlóképpen, a második érték íródik a fájl az adott hónapban = 2 mappa és a harmadik egy íródik a fájl az adott hónapban = 3 mappa.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-148">Similarly, the second one is written to the file in the month=2 folder and the third one is written to the file in the month=3 folder.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="f5c2f-149">Előfeltételek</span><span class="sxs-lookup"><span data-stu-id="f5c2f-149">Prerequisites</span></span>
<span data-ttu-id="f5c2f-150">Ez az oktatóanyag megkezdése előtt rendelkeznie kell a következő előfeltételek teljesülését:</span><span class="sxs-lookup"><span data-stu-id="f5c2f-150">Before you begin this tutorial, you must have the following prerequisites:</span></span>

1. <span data-ttu-id="f5c2f-151">**Azure-előfizetés** – Ha nem rendelkezik Azure-előfizetéssel, is létrehozhat egy ingyenes próbafiók néhány percig.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-151">**Azure subscription** - If you don't have an Azure subscription, you can create a free trial account in just a couple of minutes.</span></span> <span data-ttu-id="f5c2f-152">Tekintse meg a [ingyenes próba](https://azure.microsoft.com/pricing/free-trial/) foglalkozó hogyan beszerezhet egy ingyenes próbafiókot.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-152">See the [Free Trial](https://azure.microsoft.com/pricing/free-trial/) article on how you can obtain a free trial account.</span></span>
2. <span data-ttu-id="f5c2f-153">**Az Azure Storage** – ebben az oktatóanyagban az adatok tárolása egy általános célú standard Azure-tárfiókot használja.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-153">**Azure Storage** – You use a general-purpose standard Azure storage account for storing the data in this tutorial.</span></span> <span data-ttu-id="f5c2f-154">Ha egy általános célú szabványos Azure storage-fiók nem rendelkezik, tekintse meg a [hozzon létre egy tárfiókot](../storage/common/storage-create-storage-account.md#create-a-storage-account) cikk.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-154">If you don't have a general-purpose standard Azure storage account, see the [Create a storage account](../storage/common/storage-create-storage-account.md#create-a-storage-account) article.</span></span> <span data-ttu-id="f5c2f-155">Miután létrehozta a tárfiókot, jegyezze fel a **fióknév** és **hozzáférési kulcs**.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-155">After you have created the storage account, note down the **account name** and **access key**.</span></span> <span data-ttu-id="f5c2f-156">Lásd: [megtekintése, másolása és újragenerálása tárolási hívóbetűk](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span><span class="sxs-lookup"><span data-stu-id="f5c2f-156">See [View, copy and regenerate storage access keys](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span></span>
3. <span data-ttu-id="f5c2f-157">Töltse le, és tekintse át a Hive lekérdezés fájlt (**HQL**) helyen: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span><span class="sxs-lookup"><span data-stu-id="f5c2f-157">Download and review the Hive query file (**HQL**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span></span> <span data-ttu-id="f5c2f-158">Ez a lekérdezés átalakítja a bemeneti adatok eredményezett kimeneti adatokat.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-158">This query transforms input data to produce output data.</span></span> 
4. <span data-ttu-id="f5c2f-159">Töltse le, és tekintse át a minta bemeneti fájl (**input.log**) helyen: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span><span class="sxs-lookup"><span data-stu-id="f5c2f-159">Download and review the sample input file (**input.log**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span></span>
5. <span data-ttu-id="f5c2f-160">Hozzon létre egy blob-tároló nevű **adfgetstarted** az Azure Blob Storage tárolóban.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-160">Create a blob container named **adfgetstarted** in your Azure Blob Storage.</span></span> 
6. <span data-ttu-id="f5c2f-161">Töltse fel **partitionweblogs.hql** fájlt a **parancsfájl** mappájában a **adfgetstarted** tároló.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-161">Upload **partitionweblogs.hql** file to the **script** folder in the **adfgetstarted** container.</span></span> <span data-ttu-id="f5c2f-162">Használjon például az eszközök [Microsoft Azure Tártallózó](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="f5c2f-162">Use tools such as [Microsoft Azure Storage Explorer](http://storageexplorer.com/).</span></span> 
7. <span data-ttu-id="f5c2f-163">Töltse fel **input.log** fájlt a **inputdata** mappájában a **adfgetstarted** tároló.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-163">Upload **input.log** file to the **inputdata** folder in the **adfgetstarted** container.</span></span> 

<span data-ttu-id="f5c2f-164">Miután elvégezte az előfeltételeket, válasszon az alábbi eszközök/SDK-k az oktatóanyag elvégzéséhez:</span><span class="sxs-lookup"><span data-stu-id="f5c2f-164">After you complete the prerequisites, select one of the following tools/SDKs to do the tutorial:</span></span> 

- [<span data-ttu-id="f5c2f-165">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="f5c2f-165">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
- [<span data-ttu-id="f5c2f-166">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="f5c2f-166">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
- [<span data-ttu-id="f5c2f-167">PowerShell</span><span class="sxs-lookup"><span data-stu-id="f5c2f-167">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
- [<span data-ttu-id="f5c2f-168">Resource Manager-sablon</span><span class="sxs-lookup"><span data-stu-id="f5c2f-168">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
- [<span data-ttu-id="f5c2f-169">REST API</span><span class="sxs-lookup"><span data-stu-id="f5c2f-169">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="f5c2f-170">Azure-portál és a Visual Studio adja meg az adat-előállítók kialakításának grafikus felhasználói Felülettel módot.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-170">Azure portal and Visual Studio provide GUI way of building your data factories.</span></span> <span data-ttu-id="f5c2f-171">Mivel a PowerShell, a Resource Manager-sablon és a REST API-beállítások az adat-előállítók kialakításának scripting/programozási megoldást kínál.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-171">Whereas, PowerShell, Resource Manager Template, and REST API options provides scripting/programming way of building your data factories.</span></span>

> [!NOTE]
> <span data-ttu-id="f5c2f-172">Az oktatóanyagban található adatfolyamat átalakítja a bemeneti adatokat, hogy ezzel kimeneti adatokat hozzon létre.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-172">The data pipeline in this tutorial transforms input data to produce output data.</span></span> <span data-ttu-id="f5c2f-173">A forrásadattár adatait nem másolja egy céladattárba.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-173">It does not copy data from a source data store to a destination data store.</span></span> <span data-ttu-id="f5c2f-174">Az adatok Azure Data Factory használatával történő másolásának útmutatásáért olvassa el [az adatok Blob Storage-ból SQL Database-be történő másolását ismertető oktatóanyagot](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="f5c2f-174">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="f5c2f-175">Összefűzhet két tevékenységet (vagyis egymás után futtathatja őket), ha az egyik tevékenység kimeneti adatkészletét a másik tevékenység bemeneti adatkészleteként állítja be.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-175">You can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="f5c2f-176">Lásd [a Data Factorybeli ütemezést és végrehajtást](data-factory-scheduling-and-execution.md) ismertető cikket.</span><span class="sxs-lookup"><span data-stu-id="f5c2f-176">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 





  
