---
title: "Data Lake Store érintő adatáttelepítések esetében |} Microsoft Docs"
description: "Megérteni a különböző alkalmazási helyzetek és eszközök használatával, mely adatokra is okozhatnak, feldolgozása, letöltése és ábrázolt egy Data Lake Store-ban"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: 2a2801e5c506dcc8aa9ca2ecd275b52c72d5fbbf
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 08/29/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="71e60-103">Azure Data Lake Store használatát a big Data típusú adatok követelmények</span><span class="sxs-lookup"><span data-stu-id="71e60-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="71e60-104">Nagy adatfeldolgozási négy fő szakaszból áll:</span><span class="sxs-lookup"><span data-stu-id="71e60-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="71e60-105">Választásával dolgozhat fel nagy mennyiségű adat adatok tárolóba, valós idejű vagy kötegek</span><span class="sxs-lookup"><span data-stu-id="71e60-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="71e60-106">Az adatok feldolgozása</span><span class="sxs-lookup"><span data-stu-id="71e60-106">Processing the data</span></span>
* <span data-ttu-id="71e60-107">Az adatok letöltése</span><span class="sxs-lookup"><span data-stu-id="71e60-107">Downloading the data</span></span>
* <span data-ttu-id="71e60-108">Az adatok megjelenítése</span><span class="sxs-lookup"><span data-stu-id="71e60-108">Visualizing the data</span></span>

<span data-ttu-id="71e60-109">Ebben a cikkben úgy tekintünk a szakaszok tekintetében az Azure Data Lake Store megtudhatja, hogy a beállítások és a big Data típusú adatok igényeknek megfelelő eszközöket is.</span><span class="sxs-lookup"><span data-stu-id="71e60-109">In this article, we look at these stages with respect to Azure Data Lake Store to understand the options and tools available to meet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="71e60-110">A Data Lake Store betöltik az adatokat</span><span class="sxs-lookup"><span data-stu-id="71e60-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="71e60-111">Ez a szakasz az adatok és a különböző módokon, amelyben el az adatok egy Data Lake Store figyelembe meghatározták a különböző forrásokból mutatja be.</span><span class="sxs-lookup"><span data-stu-id="71e60-111">This section highlights the different sources of data and the different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="71e60-112">![A Data Lake Store betöltik az adatokat](./media/data-lake-store-data-scenarios/ingest-data.png "betöltik az adatokat a Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="71e60-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="71e60-113">Ad hoc adatok</span><span class="sxs-lookup"><span data-stu-id="71e60-113">Ad hoc data</span></span>
<span data-ttu-id="71e60-114">Ez jelöli, amelyek kisebb adatkészletek prototípusának a big Data típusú adatok alkalmazás használja.</span><span class="sxs-lookup"><span data-stu-id="71e60-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="71e60-115">Többféleképpen attól függően, hogy az adatforrás az alkalmi adatok választásával dolgozhat fel.</span><span class="sxs-lookup"><span data-stu-id="71e60-115">There are different ways of ingesting ad hoc data depending on the source of the data.</span></span>

| <span data-ttu-id="71e60-116">Adatforrás</span><span class="sxs-lookup"><span data-stu-id="71e60-116">Data Source</span></span> | <span data-ttu-id="71e60-117">Betöltési használatával</span><span class="sxs-lookup"><span data-stu-id="71e60-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="71e60-118">Helyi számítógép</span><span class="sxs-lookup"><span data-stu-id="71e60-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="71e60-119">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="71e60-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="71e60-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="71e60-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="71e60-121">Az Azure platformfüggetlen parancssori felület 2.0</span><span class="sxs-lookup"><span data-stu-id="71e60-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="71e60-122">A Data Lake Tools for Visual Studio használatával</span><span class="sxs-lookup"><span data-stu-id="71e60-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="71e60-123">Az Azure Storage-Blobba</span><span class="sxs-lookup"><span data-stu-id="71e60-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="71e60-124">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="71e60-125">AdlCopy eszköz</span><span class="sxs-lookup"><span data-stu-id="71e60-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="71e60-126">HDInsight-fürtön futó ból a DistCp</span><span class="sxs-lookup"><span data-stu-id="71e60-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="71e60-127">Adatfolyamként továbbított adatok</span><span class="sxs-lookup"><span data-stu-id="71e60-127">Streamed data</span></span>
<span data-ttu-id="71e60-128">Adatok, például alkalmazások, eszközök, érzékelőket és stb különböző forrásokból létrehozható jelképez. Ezek az adatok különböző eszközök által történő egy Data Lake Store meghatározták.</span><span class="sxs-lookup"><span data-stu-id="71e60-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="71e60-129">Ezek az eszközök általában fog rögzítése és feldolgozni az adatokat az esemény által alapon valós idejű, majd írja be az események kötegekben a Data Lake Store, hogy azok további dolgozhatók fel.</span><span class="sxs-lookup"><span data-stu-id="71e60-129">These tools will usually capture and process the data on an event-by-event basis in real-time, and then write the events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="71e60-130">Az alábbiakban eszközök közül választhat:</span><span class="sxs-lookup"><span data-stu-id="71e60-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="71e60-131">[Az Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) -események az Event Hubsban okozhatnak csak írható Azure Data Lake az Azure Data Lake Store kimeneti használatával.</span><span class="sxs-lookup"><span data-stu-id="71e60-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written to Azure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="71e60-132">[Az Azure HDInsight alatt futó Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) -írhat adatok közvetlenül a Data Lake Store a Storm-fürtök.</span><span class="sxs-lookup"><span data-stu-id="71e60-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly to Data Lake Store from the Storm cluster.</span></span>
* <span data-ttu-id="71e60-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – események fogadásához az Event Hubs, és jegyezze Data Lake Store használatára a [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="71e60-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it to Data Lake Store using the [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="71e60-134">Relációs adatok</span><span class="sxs-lookup"><span data-stu-id="71e60-134">Relational data</span></span>
<span data-ttu-id="71e60-135">A forrásadatok relációs adatbázisból.</span><span class="sxs-lookup"><span data-stu-id="71e60-135">You can also source data from relational databases.</span></span> <span data-ttu-id="71e60-136">Egy meghatározott időtartam során rendelkezésre a relációs adatbázisok gyűjtése hatalmas mennyiségű adat, amely kulcs áttekintést adnak is, ha a big data-feldolgozási folyamaton keresztül.</span><span class="sxs-lookup"><span data-stu-id="71e60-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="71e60-137">A következő eszközök segítségével ilyen adatok áthelyezése a Data Lake Store rendszerbe.</span><span class="sxs-lookup"><span data-stu-id="71e60-137">You can use the following tools to move such data into Data Lake Store.</span></span>

* [<span data-ttu-id="71e60-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="71e60-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="71e60-139">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="71e60-140">Web server naplóadatokat (a feltöltési egyéni alkalmazások használata)</span><span class="sxs-lookup"><span data-stu-id="71e60-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="71e60-141">Ez a fajta adatkészlet kifejezetten feltüntettük mert web server napló adatok elemzése a big data-alkalmazások gyakori használati esetek és a naplófájlokat, és fel kell tölteni a Data Lake Store nagy méretű köteten kell.</span><span class="sxs-lookup"><span data-stu-id="71e60-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files to be uploaded to the Data Lake Store.</span></span> <span data-ttu-id="71e60-142">A következő eszközök bármelyikével használhatja a saját parancsfájlok vagy alkalmazások feltölteni az ilyen adatokat írni.</span><span class="sxs-lookup"><span data-stu-id="71e60-142">You can use any of the following tools to write your own scripts or applications to upload such data.</span></span>

* [<span data-ttu-id="71e60-143">Az Azure platformfüggetlen parancssori felület 2.0</span><span class="sxs-lookup"><span data-stu-id="71e60-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="71e60-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="71e60-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="71e60-145">Az Azure Data Lake Store .NET SDK</span><span class="sxs-lookup"><span data-stu-id="71e60-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="71e60-146">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="71e60-147">Web server napló adatfeltöltési, valamint a más típusú adatok (például közösségi hangulati elemek adatok) feltöltése akkor a saját egyéni parancsfájlok alkalmazások írni, mert azt a rugalmasságot biztosít az adatok feltöltése az összetevő a nagyobb big Data típusú adatok alkalmazás részeként jó módszer.</span><span class="sxs-lookup"><span data-stu-id="71e60-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach to write your own custom scripts/applications because it gives you the flexibility to include your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="71e60-148">Egyes esetekben ez a kód is igénybe vehet az űrlap egy parancsfájl vagy egy egyszerű parancssori segédprogrammal.</span><span class="sxs-lookup"><span data-stu-id="71e60-148">In some cases this code may take the form of a script or simple command line utility.</span></span> <span data-ttu-id="71e60-149">Más esetekben a kód egy üzleti alkalmazás vagy megoldás nagy adatfeldolgozási integrálja használható.</span><span class="sxs-lookup"><span data-stu-id="71e60-149">In other cases, the code may be used to integrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="71e60-150">Társított alkalmazások Azure HDInsight-fürtök</span><span class="sxs-lookup"><span data-stu-id="71e60-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="71e60-151">A legtöbb HDInsight-fürttípusok (Hadoop, HBase, Storm) Data Lake Store támogatják az adatok tárolási tára.</span><span class="sxs-lookup"><span data-stu-id="71e60-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="71e60-152">A HDInsight-fürtök elérni az adatokat az Azure Storage Blobs (WASB).</span><span class="sxs-lookup"><span data-stu-id="71e60-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="71e60-153">A jobb teljesítmény érdekében átmásolhatja az adatokat WASB be a fürthöz tartozó Data Lake Store-fiókba.</span><span class="sxs-lookup"><span data-stu-id="71e60-153">For better performance, you can copy the data from WASB into a Data Lake Store account associated with the cluster.</span></span> <span data-ttu-id="71e60-154">A következő eszközök segítségével másolja az adatokat.</span><span class="sxs-lookup"><span data-stu-id="71e60-154">You can use the following tools to copy the data.</span></span>

* [<span data-ttu-id="71e60-155">Apache ból a DistCp</span><span class="sxs-lookup"><span data-stu-id="71e60-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="71e60-156">AdlCopy szolgáltatás</span><span class="sxs-lookup"><span data-stu-id="71e60-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="71e60-157">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="71e60-158">Tárolt adatokat a helyszíni vagy infrastruktúra-szolgáltatási Hadoop fürtök</span><span class="sxs-lookup"><span data-stu-id="71e60-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="71e60-159">Nagy mennyiségű adat tárolható meglévő Hadoop-fürtök, helyi HDFS használatával gépeken.</span><span class="sxs-lookup"><span data-stu-id="71e60-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="71e60-160">A Hadoop-fürtök egy helyi központi esetleg lehet, hogy az infrastruktúra-szolgáltatási fürtöt az Azure-on belül.</span><span class="sxs-lookup"><span data-stu-id="71e60-160">The Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="71e60-161">Előfordulhat, hogy az ilyen adatok másolása az Azure Data Lake Store megközelítésre egyszeri vagy ismétlődő módon követelményeinek.</span><span class="sxs-lookup"><span data-stu-id="71e60-161">There could be requirements to copy such data to Azure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="71e60-162">Ennek eléréséhez használható különböző lehetőség áll rendelkezésre.</span><span class="sxs-lookup"><span data-stu-id="71e60-162">There are various options that you can use to achieve this.</span></span> <span data-ttu-id="71e60-163">Az alábbiakban olvashat egy listát alternatívák és a kapcsolódó kompromisszumot.</span><span class="sxs-lookup"><span data-stu-id="71e60-163">Below is a list of alternatives and the associated trade-offs.</span></span>

| <span data-ttu-id="71e60-164">Módszer</span><span class="sxs-lookup"><span data-stu-id="71e60-164">Approach</span></span> | <span data-ttu-id="71e60-165">Részletek</span><span class="sxs-lookup"><span data-stu-id="71e60-165">Details</span></span> | <span data-ttu-id="71e60-166">Előnyei</span><span class="sxs-lookup"><span data-stu-id="71e60-166">Advantages</span></span> | <span data-ttu-id="71e60-167">Megfontolandó szempontok</span><span class="sxs-lookup"><span data-stu-id="71e60-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="71e60-168">Adatok másolása közvetlenül a Hadoop-fürtök az Azure Data Lake Store az Azure Data Factory (ADF) használatával</span><span class="sxs-lookup"><span data-stu-id="71e60-168">Use Azure Data Factory (ADF) to copy data directly from Hadoop clusters to Azure Data Lake Store</span></span> |[<span data-ttu-id="71e60-169">ADF HDFS adatforrásként támogatja.</span><span class="sxs-lookup"><span data-stu-id="71e60-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="71e60-170">ADF out-of-az-box támogatást biztosít az HDFS és első-végpontok kezelése és figyelése</span><span class="sxs-lookup"><span data-stu-id="71e60-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="71e60-171">Az adatkezelési átjáró telepített helyszíni vagy a az IaaS a fürt szükséges</span><span class="sxs-lookup"><span data-stu-id="71e60-171">Requires Data Management Gateway to be deployed on-premises or in the IaaS cluster</span></span> |
| <span data-ttu-id="71e60-172">Adatok exportálása a Hadoop-fájlok formájában.</span><span class="sxs-lookup"><span data-stu-id="71e60-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="71e60-173">Ezután másolja a fájlokat az Azure Data Lake Store megfelelő mechanizmussal.</span><span class="sxs-lookup"><span data-stu-id="71e60-173">Then copy the files to Azure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="71e60-174">Azure Data Lake Store használatával másolhat fájlokat:</span><span class="sxs-lookup"><span data-stu-id="71e60-174">You can copy files to Azure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="71e60-175">Az Azure PowerShell, a Windows operációs rendszer</span><span class="sxs-lookup"><span data-stu-id="71e60-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="71e60-176">Az Azure platformfüggetlen parancssori felület 2.0 a nem - Windows operációs rendszer</span><span class="sxs-lookup"><span data-stu-id="71e60-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="71e60-177">Minden Data Lake Store SDK használatával egyéni alkalmazás</span><span class="sxs-lookup"><span data-stu-id="71e60-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="71e60-178">Gyors megkezdéséhez.</span><span class="sxs-lookup"><span data-stu-id="71e60-178">Quick to get started.</span></span> <span data-ttu-id="71e60-179">Testre szabott feltöltések teheti</span><span class="sxs-lookup"><span data-stu-id="71e60-179">Can do customized uploads</span></span> |<span data-ttu-id="71e60-180">Folyamat, amely magában foglalja a több technológiák.</span><span class="sxs-lookup"><span data-stu-id="71e60-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="71e60-181">Kezelési és figyelési eszközök testreszabott jellegéből időbeli kihívást kell nőhet</span><span class="sxs-lookup"><span data-stu-id="71e60-181">Management and monitoring will grow to be a challenge over time given the customized nature of the tools</span></span> |
| <span data-ttu-id="71e60-182">Adatok másolása a Hadoop Azure Storage ból a Distcp segítségével.</span><span class="sxs-lookup"><span data-stu-id="71e60-182">Use Distcp to copy data from Hadoop to Azure Storage.</span></span> <span data-ttu-id="71e60-183">Majd adatok másolása az Azure Storage az Data Lake Store megfelelő mechanizmussal.</span><span class="sxs-lookup"><span data-stu-id="71e60-183">Then copy data from Azure Storage to Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="71e60-184">Az Azure Storage adatok másolása Data Lake Store használata:</span><span class="sxs-lookup"><span data-stu-id="71e60-184">You can copy data from Azure Storage to Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="71e60-185">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="71e60-186">AdlCopy eszköz</span><span class="sxs-lookup"><span data-stu-id="71e60-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="71e60-187">A HDInsight-fürtökön futó Apache ból a DistCp</span><span class="sxs-lookup"><span data-stu-id="71e60-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="71e60-188">Nyílt forráskódú eszközök is használhatók.</span><span class="sxs-lookup"><span data-stu-id="71e60-188">You can use open-source tools.</span></span> |<span data-ttu-id="71e60-189">Folyamat, amely magában foglalja a több technológiák</span><span class="sxs-lookup"><span data-stu-id="71e60-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="71e60-190">Valóban nagy adatkészletek</span><span class="sxs-lookup"><span data-stu-id="71e60-190">Really large datasets</span></span>
<span data-ttu-id="71e60-191">Az adatkészleteket, amelyek között a több terabájt feltöltése, a fenti módszerek használatával néha lassú és költséges lehet.</span><span class="sxs-lookup"><span data-stu-id="71e60-191">For uploading datasets that range in several terabytes, using the methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="71e60-192">Ilyen esetben az alábbi beállítások közül is használhatja.</span><span class="sxs-lookup"><span data-stu-id="71e60-192">In such cases, you can use the options below.</span></span>

* <span data-ttu-id="71e60-193">**Az Azure ExpressRoute segítségével**.</span><span class="sxs-lookup"><span data-stu-id="71e60-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="71e60-194">Az Azure ExpressRoute lehetővé teszi az Azure adatközpontjaiban és az infrastruktúra közötti magánhálózati kapcsolatok létrehozása a helyszínen.</span><span class="sxs-lookup"><span data-stu-id="71e60-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="71e60-195">Ez lehetővé teszi nagy mennyiségű adat átvitele egy megbízható beállítása.</span><span class="sxs-lookup"><span data-stu-id="71e60-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="71e60-196">További információkért lásd: [Azure ExpressRoute dokumentációja](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="71e60-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="71e60-197">**Az adatok "Offline" feltöltése a**.</span><span class="sxs-lookup"><span data-stu-id="71e60-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="71e60-198">Ha Azure ExpressRoute használata nem megvalósítható a bármilyen okból, [Azure Import/Export szolgáltatás](../storage/common/storage-import-export-service.md) szállítási merevlemez-meghajtók az adatait az Azure adatközpontba.</span><span class="sxs-lookup"><span data-stu-id="71e60-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) to ship hard disk drives with your data to an Azure data center.</span></span> <span data-ttu-id="71e60-199">Az adatok először tölt fel az Azure Storage blobs szolgáltatásban.</span><span class="sxs-lookup"><span data-stu-id="71e60-199">Your data is first uploaded to Azure Storage Blobs.</span></span> <span data-ttu-id="71e60-200">Ezután [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) vagy [AdlCopy eszköz](data-lake-store-copy-data-azure-storage-blob.md) adatok másolása az Azure Storage Blobs Data Lake Store-bA.</span><span class="sxs-lookup"><span data-stu-id="71e60-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) to copy data from Azure Storage Blobs to Data Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="71e60-201">Amíg az Import/Export szolgáltatás, a fájlméret, a lemezeken, amelyek az Azure-adatközpontba történő használatával nem lehet nagyobb, mint 195 GB.</span><span class="sxs-lookup"><span data-stu-id="71e60-201">While using the Import/Export service, the file sizes on the disks that you ship to Azure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="71e60-202">Data Lake Store-ban tárolt adatok feldolgozása</span><span class="sxs-lookup"><span data-stu-id="71e60-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="71e60-203">Az adatok elérhetővé válik a Data Lake Store is futtatása az adatok a támogatott big data-alkalmazások használatával.</span><span class="sxs-lookup"><span data-stu-id="71e60-203">Once the data is available in Data Lake Store you can run analysis on that data using the supported big data applications.</span></span> <span data-ttu-id="71e60-204">Jelenleg Azure HDInsight és az Azure Data Lake Analytics is használja a Data Lake Store-ban tárolt adatok adatok feladatok futtatásához.</span><span class="sxs-lookup"><span data-stu-id="71e60-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics to run data analysis jobs on the data stored in Data Lake Store.</span></span>

<span data-ttu-id="71e60-205">![Adatok elemzése az Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "elemezhetik a Data Lake Store-ban")</span><span class="sxs-lookup"><span data-stu-id="71e60-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="71e60-206">A következő példákban is megtekinthetik.</span><span class="sxs-lookup"><span data-stu-id="71e60-206">You can look at the following examples.</span></span>

* [<span data-ttu-id="71e60-207">HDInsight-fürtök létrehozása a Data Lake Store tárolóként</span><span class="sxs-lookup"><span data-stu-id="71e60-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="71e60-208">Az Azure Data Lake Analytics használata a Data Lake Store-ral</span><span class="sxs-lookup"><span data-stu-id="71e60-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="71e60-209">Töltse le az adatok Data Lake Store-ból</span><span class="sxs-lookup"><span data-stu-id="71e60-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="71e60-210">Érdemes azt is, töltse le és tárolt adatok mozgatása az Azure Data Lake Store forgatókönyvek például:</span><span class="sxs-lookup"><span data-stu-id="71e60-210">You might also want to download or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="71e60-211">Adatok áthelyezése az egyéb tárhelyek felületet a meglévő adatok feldolgozása kimenetátirányítási mechanizmusát használó műveletekről.</span><span class="sxs-lookup"><span data-stu-id="71e60-211">Move data to other repositories to interface with your existing data processing pipelines.</span></span> <span data-ttu-id="71e60-212">Például előfordulhat, hogy áthelyezendő adatok Data Lake Store-ból az Azure SQL Database vagy a helyszíni SQL Server.</span><span class="sxs-lookup"><span data-stu-id="71e60-212">For example, you might want to move data from Data Lake Store to Azure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="71e60-213">Adatok letöltése a helyi számítógép alkalmazás prototípusok felépítésekor IDE környezetben feldolgozásra.</span><span class="sxs-lookup"><span data-stu-id="71e60-213">Download data to your local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="71e60-214">![Data Lake Store-ból adatokat kilépési](./media/data-lake-store-data-scenarios/egress-data.png "kilépési adatok Data Lake Store-ból")</span><span class="sxs-lookup"><span data-stu-id="71e60-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="71e60-215">Ilyen esetben a következő beállítások bármelyikét használhatja:</span><span class="sxs-lookup"><span data-stu-id="71e60-215">In such cases, you can use any of the following options:</span></span>

* [<span data-ttu-id="71e60-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="71e60-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="71e60-217">Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="71e60-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="71e60-218">Apache ból a DistCp</span><span class="sxs-lookup"><span data-stu-id="71e60-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="71e60-219">Az alábbi eljárások segítségével a saját parancsfájl/alkalmazás adatok letöltése a Data Lake Store-ból.</span><span class="sxs-lookup"><span data-stu-id="71e60-219">You can also use the following methods to write your own script/application to download data from Data Lake Store.</span></span>

* [<span data-ttu-id="71e60-220">Az Azure platformfüggetlen parancssori felület 2.0</span><span class="sxs-lookup"><span data-stu-id="71e60-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="71e60-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="71e60-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="71e60-222">Az Azure Data Lake Store .NET SDK</span><span class="sxs-lookup"><span data-stu-id="71e60-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="71e60-223">A Data Lake Store-adatok ábrázolása</span><span class="sxs-lookup"><span data-stu-id="71e60-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="71e60-224">A szolgáltatások kombinációját hozhat létre a Data Lake Store-ban tárolt adatok vizuális ábrázolásai.</span><span class="sxs-lookup"><span data-stu-id="71e60-224">You can use a mix of services to create visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="71e60-225">![A Data Lake Store-adatok ábrázolása](./media/data-lake-store-data-scenarios/visualize-data.png "a Data Lake Store-adatok ábrázolása")</span><span class="sxs-lookup"><span data-stu-id="71e60-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="71e60-226">Megkezdheti a [Azure Data Factory Data Lake Store az Azure SQL Data Warehouse tárolt adatok mozgatása](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span><span class="sxs-lookup"><span data-stu-id="71e60-226">You can start by using [Azure Data Factory to move data from Data Lake Store to Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="71e60-227">Ezt követően is [Power BI integrálása az Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) létrehozása az adatok vizuális ábrázolását.</span><span class="sxs-lookup"><span data-stu-id="71e60-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) to create visual representation of the data.</span></span>
