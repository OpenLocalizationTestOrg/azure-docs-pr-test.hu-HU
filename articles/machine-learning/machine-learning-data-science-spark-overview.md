---
title: "A Spark on Azure HDInsight használatának Adattudomány áttekintése |} Microsoft Docs"
description: "A Spark MLlib eszközkészlet jelentős gépi tanulás modellezési képességekkel a HDInsight elosztott környezetben jelent."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="348dd-103">Adattudomány Spark on Azure HDInsight használatának áttekintése</span><span class="sxs-lookup"><span data-stu-id="348dd-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="348dd-104">Ennek a programcsomagnak a témakörök használata a HDInsight Spark például adatfeldolgozást, a szolgáltatás mérnöki csapathoz, a modellezési és a modell kiértékelése a közös adatok tudományos feladatokat jeleníti meg.</span><span class="sxs-lookup"><span data-stu-id="348dd-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="348dd-105">A használt adatok látható egy minta 2013 NYC taxi út és a jegy ára adatkészlet.</span><span class="sxs-lookup"><span data-stu-id="348dd-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="348dd-106">A beépített modellek logisztikai és lineáris regressziós, véletlenszerű erdők és átmenetes súlyozott fák tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="348dd-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="348dd-107">A témakörök a ezek a modellek tárolása az Azure blob storage (WASB) és a pontszám és értékelje a prediktív teljesítményét is megjelennek.</span><span class="sxs-lookup"><span data-stu-id="348dd-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="348dd-108">Összetettebb témákra fedik le, hogyan lehet a modellek betanítása a kereszt-ellenőrzési és a hyper-paraméter abszolút használatával.</span><span class="sxs-lookup"><span data-stu-id="348dd-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="348dd-109">Jelen összefoglaló téma is hivatkozik a témakörök azt ismertetik, hogyan állíthatja be a Spark-fürt, amelyekre szüksége van a végrehajtásához a megadott forgatókönyvek.</span><span class="sxs-lookup"><span data-stu-id="348dd-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="348dd-110">Spark és MLlib</span><span class="sxs-lookup"><span data-stu-id="348dd-110">Spark and MLlib</span></span>
<span data-ttu-id="348dd-111">[Spark](http://spark.apache.org/) egy nyílt forráskódú párhuzamos feldolgozást végző keretrendszer, amely támogatja a memórián belüli feldolgozása folyamatban van a big data elemző alkalmazások teljesítményének növelése érdekében.</span><span class="sxs-lookup"><span data-stu-id="348dd-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="348dd-112">A Spark program sebességét, a könnyű, valamint a kifinomult analytics lett tervezve.</span><span class="sxs-lookup"><span data-stu-id="348dd-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="348dd-113">A Spark memóriában elosztott tárolt számítási képességei jól funkcionálnak a szerepel a machine learning és a graph számítások iteratív algoritmusaival a.</span><span class="sxs-lookup"><span data-stu-id="348dd-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="348dd-114">[MLlib](http://spark.apache.org/mllib/) van a Spark méretezhető machine learning könyvtárban, amely csökkenti a algoritmikus modellezési képességekkel az elosztott környezetben.</span><span class="sxs-lookup"><span data-stu-id="348dd-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="348dd-115">A HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="348dd-115">HDInsight Spark</span></span>
<span data-ttu-id="348dd-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) nyílt forráskódú Spark az Azure üzemeltetett elérhető van.</span><span class="sxs-lookup"><span data-stu-id="348dd-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="348dd-117">Is támogatja a **Jupyter PySpark notebookok** futtatható Spark SQL interaktív lekérdezések átalakítása, szűrési és megjeleníteni az Azure BLOB (WASB) tárolt adatokat a Spark-fürt.</span><span class="sxs-lookup"><span data-stu-id="348dd-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="348dd-118">PySpark a Python API-t a Spark.</span><span class="sxs-lookup"><span data-stu-id="348dd-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="348dd-119">A kódrészletek, amelyek a megoldásokat és megjelenítése a megfelelő előkészítésére itt futtatása a Jupyter notebookok a Spark-fürtjei telepített adatok megjelenítéséhez.</span><span class="sxs-lookup"><span data-stu-id="348dd-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="348dd-120">A modellezési lépések, a következő témakörökben talál, amely bemutatja, hogyan betanítása, értékelje ki, mentse és felhasználását a modell különböző típusú kódot tartalmaznak.</span><span class="sxs-lookup"><span data-stu-id="348dd-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="348dd-121">A telepítő: A Spark-fürtök és a Jupyter notebookok</span><span class="sxs-lookup"><span data-stu-id="348dd-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="348dd-122">Beállítási lépéseket és kód okat ebben a forgatókönyvben egy HDInsight Spark 1.6 használatával.</span><span class="sxs-lookup"><span data-stu-id="348dd-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="348dd-123">De Jupyter notebookok HDInsight Spark 1.6-os és a Spark 2.0 fürtök rendelkeznek.</span><span class="sxs-lookup"><span data-stu-id="348dd-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="348dd-124">A jegyzetfüzetek és a hozzájuk hivatkozások leírása szerepelnek a [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) az azokat tartalmazó GitHub-tárházban.</span><span class="sxs-lookup"><span data-stu-id="348dd-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="348dd-125">Ezenkívül a kód itt és a csatolt jegyzetfüzetekben általános és a Spark-fürt kell működnie.</span><span class="sxs-lookup"><span data-stu-id="348dd-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="348dd-126">Ha nem használja a HDInsight Spark, a fürt beállítása, és lehet, hogy a felügyeleti lépések némileg eltér az itt látható.</span><span class="sxs-lookup"><span data-stu-id="348dd-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="348dd-127">Kényelmi célokat szolgál az alábbiakban a hivatkozásokat a Jupyter notebookok Spark 1.6 (futtatásához a pySpark kernel a Jupyter Notebook kiszolgáló) és a Spark 2.0-s verzióját (a pySpark3 kernel a Jupyter Notebook kiszolgáló kell futtatni):</span><span class="sxs-lookup"><span data-stu-id="348dd-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="348dd-128">Spark 1.6-os notebookok</span><span class="sxs-lookup"><span data-stu-id="348dd-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="348dd-129">Ezek notebookok vannak a pySpark kernel Jupyter notebook kiszolgáló futtatásához.</span><span class="sxs-lookup"><span data-stu-id="348dd-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="348dd-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): információt biztosít az adatok feltárása, modellezéséhez, és számos különböző algoritmusok pontozási végrehajtásához.</span><span class="sxs-lookup"><span data-stu-id="348dd-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="348dd-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): #1 jegyzetfüzet és modell fejlesztési hyperparameter hangolása és kereszt-ellenőrzési témaköröket tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="348dd-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="348dd-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): bemutatja, hogyan azok egy mentett modell Python használata a HDInsight-fürtökön.</span><span class="sxs-lookup"><span data-stu-id="348dd-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="348dd-133">Spark 2.0 notebookok</span><span class="sxs-lookup"><span data-stu-id="348dd-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="348dd-134">Ezek notebookok vannak a Jupyter notebook kiszolgáló pySpark3 kernel futtatásához.</span><span class="sxs-lookup"><span data-stu-id="348dd-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="348dd-135">[Spark2.0-pySpark3-Machine-Learning-Data-Science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Ez a fájl hogyan hajthat végre az adatok feltárása, modellezési, és a Spark 2.0 pontozási fürtök NYC Taxi út és jegy ára adatkészlet leírt [Itt](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="348dd-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="348dd-136">A notebook gyorsan felfedezése a Spark 2.0 adtunk kódot az jó kiindulási pont lehet.</span><span class="sxs-lookup"><span data-stu-id="348dd-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="348dd-137">További részletes notebook elemzi az NYC Taxi adatokat, lásd: a következő notebook ezen a listán.</span><span class="sxs-lookup"><span data-stu-id="348dd-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="348dd-138">Tekintse meg a megjegyzéseket, a lista a következő, hasonlítsa össze ezeket a jegyzetfüzetek.</span><span class="sxs-lookup"><span data-stu-id="348dd-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="348dd-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): Ez a fájl bemutatja, hogyan végezhet wrangling (Spark SQL és dataframe műveletek), feltárása, modellezéséhez és a NYC Taxi út és a jegy ára adatkészlet leírt pontozási [Itt](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="348dd-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="348dd-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): Ez a fájl bemutatja, hogyan végezhet wrangling (Spark SQL és dataframe műveletek), feltárása, modellezéséhez és pontozási a jól ismert légitársaság időben indító adatkészlet 2011 és a 2012.</span><span class="sxs-lookup"><span data-stu-id="348dd-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="348dd-141">Azt integrálva az adatokkal repülőtéri időjárási (pl. szélsebesség, hőmérséklet, magasság stb.) a légitársaság dataset előtt modellezési, így időjárási felhasználásokhoz felvehetők a modell.</span><span class="sxs-lookup"><span data-stu-id="348dd-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="348dd-142">A légitársaság dataset lett hozzáadva, a Spark 2.0 jegyzetfüzeteihez jobban a besorolási algoritmusok használatát mutatja be.</span><span class="sxs-lookup"><span data-stu-id="348dd-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="348dd-143">Tekintse meg a következőket légitársaság kapcsolatos információk időben indító dataset és időjárási adatkészlet:</span><span class="sxs-lookup"><span data-stu-id="348dd-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="348dd-144">Légitársaság időben indító adatok: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="348dd-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="348dd-145">Repülőtéri időjárási adatok: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="348dd-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="348dd-146">A Spark 2.0 jegyzetfüzeteket az NYC taxi és légitársaság repülési késleltetés-készleteket is igénybe vehet, 10 perc vagy több (attól függően, hogy a HDI-fürtnek a mérete).</span><span class="sxs-lookup"><span data-stu-id="348dd-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="348dd-147">A fenti listában első notebook mutatja az adatok feltárása sok területén, a képi megjelenítés és ML minta egy jegyzetfüzetet le mintát NYC adatkészlet, amelyben a taxi és jegy ára fájlok voltak előre illesztett futtatásához kevesebb időt vesz igénybe, a képzési: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) jegyzetfüzet (2-3 perc) befejezéséhez sokkal rövidebb ideig tart, és előfordulhat, hogy lehet Jó kiindulópont gyorsan felfedezése a Spark 2.0 adtunk kódot.</span><span class="sxs-lookup"><span data-stu-id="348dd-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="348dd-148">A Spark 2.0 modell és a model felhasználás pontozó operationalization útmutatóért lásd: a [Spark 1.6-os dokumentum a felhasználás](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) egy példát, amely tartalmazza a szükséges lépéseket.</span><span class="sxs-lookup"><span data-stu-id="348dd-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="348dd-149">Ezzel a Spark 2.0, cserélje le a Python kódját fájl [ezt a fájlt](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="348dd-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="348dd-150">Előfeltételek</span><span class="sxs-lookup"><span data-stu-id="348dd-150">Prerequisites</span></span>
<span data-ttu-id="348dd-151">Az alábbi eljárások Spark 1.6 kapcsolódnak.</span><span class="sxs-lookup"><span data-stu-id="348dd-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="348dd-152">A Spark 2.0-s verziójához használja a notebookok leírt, és korábban csatolva.</span><span class="sxs-lookup"><span data-stu-id="348dd-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="348dd-153">1. rendelkeznie kell Azure-előfizetéssel.</span><span class="sxs-lookup"><span data-stu-id="348dd-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="348dd-154">Ha még nem rendelkezik egy, lásd: [beolvasása az Azure ingyenes próbaverzió](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="348dd-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="348dd-155">2 van szüksége a Spark 1.6-os-fürt forgatókönyv végrehajtásához.</span><span class="sxs-lookup"><span data-stu-id="348dd-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="348dd-156">Szeretne létrehozni egyet, tekintse meg a utasításokat [első lépések: Apache Spark on Azure HDInsight létrehozása](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="348dd-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="348dd-157">A fürt típusa és verzió van megadva a **fürt típusának kiválasztása** menü.</span><span class="sxs-lookup"><span data-stu-id="348dd-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Fürt konfigurálása](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="348dd-159">Ez a témakör bemutatja, hogyan használja a Python helyett a Scala az adatok végpontok közötti tudományos folyamat feladatok végrehajtásához, tekintse meg a [Azure Spark Scala használatával Adattudomány](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="348dd-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="348dd-160">A következőt: 2013 Taxi adatok</span><span class="sxs-lookup"><span data-stu-id="348dd-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="348dd-161">A következőt: Taxi út adatok körülbelül 20 GB tömörített vesszővel tagolt (CSV) fájl (tömörítetlen ~ 48 GB), több mint 173 millió egyedi való adatváltások számát és a vitel kifizette minden út.</span><span class="sxs-lookup"><span data-stu-id="348dd-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="348dd-162">Minden út rekord tartalmazza, a felvételével kapcsolatban és Gyűjtőtár hely és idő, anonimizált rejthetők el (illesztőprogram) licenc száma, és medallion (taxi tartozó egyedi azonosító) számát.</span><span class="sxs-lookup"><span data-stu-id="348dd-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="348dd-163">Az adatok minden való adatváltások számát ismerteti az év 2013, és minden hónap a következő két adatkészletet találhatók:</span><span class="sxs-lookup"><span data-stu-id="348dd-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="348dd-164">A "trip_data" CSV-fájlok tartalmazza út, például az utasok száma, átvételéhez és dropoff mutat, út időtartamát és út hossza.</span><span class="sxs-lookup"><span data-stu-id="348dd-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="348dd-165">Íme néhány példa rekordok:</span><span class="sxs-lookup"><span data-stu-id="348dd-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="348dd-166">A "trip_fare" CSV fájlok tartalmazzák a jegy ára kifizette minden út, például a fizetési mód, jegy ára összeg, emelt díjas és adókat, tippeket és autópályadíjak, és a teljes összeg fizetős részleteit.</span><span class="sxs-lookup"><span data-stu-id="348dd-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="348dd-167">Íme néhány példa rekordok:</span><span class="sxs-lookup"><span data-stu-id="348dd-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="348dd-168">A Microsoft ezeket a fájlokat 0,1 % mintát venni, és a út csatlakoztatott\_adatok és út\_csak egyet fájlok díjszabás be ez a forgatókönyv bemeneti adatkészlet használja egy adatkészlet.</span><span class="sxs-lookup"><span data-stu-id="348dd-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="348dd-169">Egyedi kulcs út csatlakozni\_adatok és út\_jegy ára tevődnek össze a mezők: medallion, rejthetők el\_engedély és a felvételi\_dátum és idő.</span><span class="sxs-lookup"><span data-stu-id="348dd-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="348dd-170">A DataSet adatkészlet egyes rekord a következő attribútumokat a következőt: Taxi út képviselő tartalmazza:</span><span class="sxs-lookup"><span data-stu-id="348dd-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="348dd-171">Mező</span><span class="sxs-lookup"><span data-stu-id="348dd-171">Field</span></span> | <span data-ttu-id="348dd-172">Rövid leírás</span><span class="sxs-lookup"><span data-stu-id="348dd-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="348dd-173">medallion</span><span class="sxs-lookup"><span data-stu-id="348dd-173">medallion</span></span> |<span data-ttu-id="348dd-174">Anonimizált taxi medallion (egyedi taxi azonosító)</span><span class="sxs-lookup"><span data-stu-id="348dd-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="348dd-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="348dd-175">hack_license</span></span> |<span data-ttu-id="348dd-176">Anonimizált Hackney kocsivissza licenc száma</span><span class="sxs-lookup"><span data-stu-id="348dd-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="348dd-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="348dd-177">vendor_id</span></span> |<span data-ttu-id="348dd-178">Taxi szállító azonosítója</span><span class="sxs-lookup"><span data-stu-id="348dd-178">Taxi vendor id</span></span> |
| <span data-ttu-id="348dd-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="348dd-179">rate_code</span></span> |<span data-ttu-id="348dd-180">Jegy ára taxi gyakorisága a következőt:</span><span class="sxs-lookup"><span data-stu-id="348dd-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="348dd-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="348dd-181">store_and_fwd_flag</span></span> |<span data-ttu-id="348dd-182">Tárolási és előre jelző</span><span class="sxs-lookup"><span data-stu-id="348dd-182">Store and forward flag</span></span> |
| <span data-ttu-id="348dd-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="348dd-183">pickup_datetime</span></span> |<span data-ttu-id="348dd-184">Dátum és idő átvételéhez</span><span class="sxs-lookup"><span data-stu-id="348dd-184">Pick up date & time</span></span> |
| <span data-ttu-id="348dd-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="348dd-185">dropoff_datetime</span></span> |<span data-ttu-id="348dd-186">Dropoff dátum és idő</span><span class="sxs-lookup"><span data-stu-id="348dd-186">Dropoff date & time</span></span> |
| <span data-ttu-id="348dd-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="348dd-187">pickup_hour</span></span> |<span data-ttu-id="348dd-188">Óra átvételéhez</span><span class="sxs-lookup"><span data-stu-id="348dd-188">Pick up hour</span></span> |
| <span data-ttu-id="348dd-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="348dd-189">pickup_week</span></span> |<span data-ttu-id="348dd-190">Az év hete átvételéhez</span><span class="sxs-lookup"><span data-stu-id="348dd-190">Pick up week of the year</span></span> |
| <span data-ttu-id="348dd-191">milyen napra esik</span><span class="sxs-lookup"><span data-stu-id="348dd-191">weekday</span></span> |<span data-ttu-id="348dd-192">Milyen napra esik (tartomány: 1-7)</span><span class="sxs-lookup"><span data-stu-id="348dd-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="348dd-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="348dd-193">passenger_count</span></span> |<span data-ttu-id="348dd-194">Egy taxi út az utasok száma</span><span class="sxs-lookup"><span data-stu-id="348dd-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="348dd-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="348dd-195">trip_time_in_secs</span></span> |<span data-ttu-id="348dd-196">Visszatérési ideje másodpercben</span><span class="sxs-lookup"><span data-stu-id="348dd-196">Trip time in seconds</span></span> |
| <span data-ttu-id="348dd-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="348dd-197">trip_distance</span></span> |<span data-ttu-id="348dd-198">Miles út távolság</span><span class="sxs-lookup"><span data-stu-id="348dd-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="348dd-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="348dd-199">pickup_longitude</span></span> |<span data-ttu-id="348dd-200">A földrajzi hosszúság értéke átvételéhez</span><span class="sxs-lookup"><span data-stu-id="348dd-200">Pick up longitude</span></span> |
| <span data-ttu-id="348dd-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="348dd-201">pickup_latitude</span></span> |<span data-ttu-id="348dd-202">A földrajzi hosszúság átvételéhez</span><span class="sxs-lookup"><span data-stu-id="348dd-202">Pick up latitude</span></span> |
| <span data-ttu-id="348dd-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="348dd-203">dropoff_longitude</span></span> |<span data-ttu-id="348dd-204">Dropoff hosszúság</span><span class="sxs-lookup"><span data-stu-id="348dd-204">Dropoff longitude</span></span> |
| <span data-ttu-id="348dd-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="348dd-205">dropoff_latitude</span></span> |<span data-ttu-id="348dd-206">Dropoff szélesség</span><span class="sxs-lookup"><span data-stu-id="348dd-206">Dropoff latitude</span></span> |
| <span data-ttu-id="348dd-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="348dd-207">direct_distance</span></span> |<span data-ttu-id="348dd-208">Közvetlen kivételezési közötti távolság fel és dropoff helye</span><span class="sxs-lookup"><span data-stu-id="348dd-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="348dd-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="348dd-209">payment_type</span></span> |<span data-ttu-id="348dd-210">A fizetési mód (cas, hitelkártya stb.)</span><span class="sxs-lookup"><span data-stu-id="348dd-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="348dd-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="348dd-211">fare_amount</span></span> |<span data-ttu-id="348dd-212">A jegy ára összeg</span><span class="sxs-lookup"><span data-stu-id="348dd-212">Fare amount in</span></span> |
| <span data-ttu-id="348dd-213">Emelt díjas</span><span class="sxs-lookup"><span data-stu-id="348dd-213">surcharge</span></span> |<span data-ttu-id="348dd-214">Emelt díjas</span><span class="sxs-lookup"><span data-stu-id="348dd-214">Surcharge</span></span> |
| <span data-ttu-id="348dd-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="348dd-215">mta_tax</span></span> |<span data-ttu-id="348dd-216">MTA adó</span><span class="sxs-lookup"><span data-stu-id="348dd-216">Mta tax</span></span> |
| <span data-ttu-id="348dd-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="348dd-217">tip_amount</span></span> |<span data-ttu-id="348dd-218">Tipp összeg</span><span class="sxs-lookup"><span data-stu-id="348dd-218">Tip amount</span></span> |
| <span data-ttu-id="348dd-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="348dd-219">tolls_amount</span></span> |<span data-ttu-id="348dd-220">Autópályadíjak összeg</span><span class="sxs-lookup"><span data-stu-id="348dd-220">Tolls amount</span></span> |
| <span data-ttu-id="348dd-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="348dd-221">total_amount</span></span> |<span data-ttu-id="348dd-222">Teljes összeg</span><span class="sxs-lookup"><span data-stu-id="348dd-222">Total amount</span></span> |
| <span data-ttu-id="348dd-223">Formabontó</span><span class="sxs-lookup"><span data-stu-id="348dd-223">tipped</span></span> |<span data-ttu-id="348dd-224">Formabontó (0 vagy 1. nem vagy Igen)</span><span class="sxs-lookup"><span data-stu-id="348dd-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="348dd-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="348dd-225">tip_class</span></span> |<span data-ttu-id="348dd-226">Tipp osztály (0: 0, 1: $0-5, 2: $6 – 10., 3: $11-20, 4: > $20)</span><span class="sxs-lookup"><span data-stu-id="348dd-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="348dd-227">Kód végrehajtása a Spark-fürt Jupyter notebook</span><span class="sxs-lookup"><span data-stu-id="348dd-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="348dd-228">Az Azure-portálon a Jupyter Notebook indíthatja el.</span><span class="sxs-lookup"><span data-stu-id="348dd-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="348dd-229">Keresse meg a Spark-fürt az irányítópulton, és kattintson rá a felügyelet lapon adja meg a fürt.</span><span class="sxs-lookup"><span data-stu-id="348dd-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="348dd-230">A Spark-fürt társított notebook megnyitásához kattintson **fürt irányítópultok** -> **Jupyter Notebook** .</span><span class="sxs-lookup"><span data-stu-id="348dd-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Fürt irányítópultok](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="348dd-232">Is tallózással megkereshet ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** a Jupyter notebookok eléréséhez.</span><span class="sxs-lookup"><span data-stu-id="348dd-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="348dd-233">Az URL-cím a FÜRTNÉV részét cserélje le a saját fürt nevét.</span><span class="sxs-lookup"><span data-stu-id="348dd-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="348dd-234">Szüksége van a notebookok eléréséhez a rendszergazdai fiók jelszavát.</span><span class="sxs-lookup"><span data-stu-id="348dd-234">You need the password for your admin account to access the notebooks.</span></span>

![Keresse meg a Jupyter notebookok](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="348dd-236">Válassza ki a PySpark néhány példa a PySpark API-t használó előcsomagolt jegyzetfüzetek tartalmazó könyvtár megjelenítéséhez. Ez a témakör a Spark Suite mintakódok tartalmazó jegyzetfüzet érhetők el [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="348dd-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="348dd-237">Feltöltheti közvetlenül a notebookok [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) a Jupyter notebook kiszolgálóra a Spark-fürtön.</span><span class="sxs-lookup"><span data-stu-id="348dd-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="348dd-238">A Jupyter kezdőlapján kattintson a **feltöltése** gomb a képernyő jobb oldalán.</span><span class="sxs-lookup"><span data-stu-id="348dd-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="348dd-239">A Fájlkezelőben nyílik meg.</span><span class="sxs-lookup"><span data-stu-id="348dd-239">It opens a file explorer.</span></span> <span data-ttu-id="348dd-240">Ide illessze be a Notebook, majd kattintson a GitHub (nyers tartalom) URL- **nyitott**.</span><span class="sxs-lookup"><span data-stu-id="348dd-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="348dd-241">A Jupyter fájl nevére, a fájlnév megjelenik egy **feltöltése** újra gombra.</span><span class="sxs-lookup"><span data-stu-id="348dd-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="348dd-242">Ide **feltöltése** gombra.</span><span class="sxs-lookup"><span data-stu-id="348dd-242">Click this **Upload** button.</span></span> <span data-ttu-id="348dd-243">Most már a notebook importálta.</span><span class="sxs-lookup"><span data-stu-id="348dd-243">Now you have imported the notebook.</span></span> <span data-ttu-id="348dd-244">Ismételje ezeket a lépéseket a Ez a forgatókönyv más notebookok feltöltéséhez.</span><span class="sxs-lookup"><span data-stu-id="348dd-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="348dd-245">Kattintson a jobb egérgombbal a a böngészőt, és válassza a hivatkozások **hivatkozás másolása** lekérni a githubon nyers tartalom URL-CÍMÉT.</span><span class="sxs-lookup"><span data-stu-id="348dd-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="348dd-246">Az URL-cím bemásolhatja a Jupyter feltöltése explorer párbeszédpanelt.</span><span class="sxs-lookup"><span data-stu-id="348dd-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="348dd-247">Most már a következőket teheti:</span><span class="sxs-lookup"><span data-stu-id="348dd-247">Now you can:</span></span>

* <span data-ttu-id="348dd-248">A notebook kattintva tekintse meg a kódot.</span><span class="sxs-lookup"><span data-stu-id="348dd-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="348dd-249">Minden cella végrehajtása billentyűkombináció lenyomásával **a SHIFT + ENTER**.</span><span class="sxs-lookup"><span data-stu-id="348dd-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="348dd-250">Futtassa a teljes jegyzetfüzet található kattintva **cella** -> **futtatása**.</span><span class="sxs-lookup"><span data-stu-id="348dd-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="348dd-251">Használja az automatikus képi megjelenítés lekérdezések.</span><span class="sxs-lookup"><span data-stu-id="348dd-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="348dd-252">A PySpark kernel automatikusan visualizes (HiveQL) az SQL-lekérdezések eredményének.</span><span class="sxs-lookup"><span data-stu-id="348dd-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="348dd-253">Lehetősége van több különböző típusú megjelenítések (táblázat, torta, vonal, terület vagy sáv) között használatával kiválaszthatja azokat a **típus** a notebook menü gombjai:</span><span class="sxs-lookup"><span data-stu-id="348dd-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Logisztikai regresszió: ROC-görbe általános módszer](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="348dd-255">A következő lépések</span><span class="sxs-lookup"><span data-stu-id="348dd-255">What's next?</span></span>
<span data-ttu-id="348dd-256">Most, hogy be vannak állítva a HDInsight Spark-fürt és a Jupyter notebookok feltöltött, készen áll a témakörök, amelyek megfelelnek a három PySpark notebookok keresztül működnek.</span><span class="sxs-lookup"><span data-stu-id="348dd-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="348dd-257">Hogyan feltérképezheti az adatokat, majd hogyan létrehozását és felhasználását a modellek mutatnak.</span><span class="sxs-lookup"><span data-stu-id="348dd-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="348dd-258">A speciális adatok feltárása és modellezési notebook bemutatja, hogyan kereszt-ellenőrzési, abszolút, a hyper-paramétert tartalmaz, és a modell kiértékelése.</span><span class="sxs-lookup"><span data-stu-id="348dd-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="348dd-259">**Az adatok feltárása és Spark modellezés:** megismerkedhet a DataSet adatkészlet és a létrehozása, a pontszám és a gépi tanulási modellek által feldolgozása révén kiértékelheti az [adatok bináris besorolási és regressziós modell létrehozása Spark MLlib eszközkészlete](machine-learning-data-science-spark-data-exploration-modeling.md) témakör.</span><span class="sxs-lookup"><span data-stu-id="348dd-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="348dd-260">**Modellhez tartozó felhasználás:** a létre ebben a témakörben besorolási és regressziós modell pontozása céljából, lásd: [pontszám és értékelje ki a Spark-beépített machine learning modellek](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="348dd-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="348dd-261">**Kereszt-ellenőrzési és hyperparameter abszolút**: lásd: [speciális adatok feltárása és Spark modellezés](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) meg, hogyan lehet a modellek betanítása a kereszt-ellenőrzési és a hyper-paraméter abszolút használatával</span><span class="sxs-lookup"><span data-stu-id="348dd-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

